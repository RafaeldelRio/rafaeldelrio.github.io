{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Ejercicios Prácticos - Módulo 4: Algoritmos de ML y Aplicaciones en Ciberseguridad"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Objetivo:** Aplicar algoritmos fundamentales de Machine Learning (Clasificación y Clustering) utilizando la librería Scikit-learn. Practicar el preprocesamiento de datos (escalado, codificación), el entrenamiento de modelos, la predicción y la evaluación de métricas en contextos simplificados de ciberseguridad."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Preparación: Importar Librerías y Crear Datos de Ejemplo"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Librerías básicas\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "\n",
       "# Scikit-learn: Preprocessing\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
       "from sklearn.compose import ColumnTransformer\n",
       "from sklearn.pipeline import Pipeline\n",
       "\n",
       "# Scikit-learn: Modelos\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.neighbors import KNeighborsClassifier\n",
       "from sklearn.tree import DecisionTreeClassifier\n",
       "from sklearn.ensemble import RandomForestClassifier\n",
       "from sklearn.cluster import KMeans\n",
       "\n",
       "# Scikit-learn: Métricas\n",
       "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, silhouette_score\n",
       "\n",
       "# Configuraciones opcionales\n",
       "%matplotlib inline\n",
       "sns.set_style('whitegrid')"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Dataset 1: Características Simplificadas de URLs (Phishing)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Creamos un DataFrame de ejemplo para clasificación de URLs\n",
       "data_url = {\n",
       "    'url_length': [15, 65, 25, 80, 40, 95, 30, 110, 20, 55, 70, 85], \n",
       "    'num_special_chars': [2, 5, 3, 8, 4, 9, 3, 10, 2, 4, 6, 7],\n",
       "    'has_ip_address': [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0], # 0: No, 1: Sí\n",
       "    'num_subdomains': [1, 3, 2, 1, 2, 4, 1, 2, 1, 3, 1, 2],\n",
       "    'is_phishing': [0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1] # 0: Legítima, 1: Phishing\n",
       "}\n",
       "df_url = pd.DataFrame(data_url)\n",
       "\n",
       "print(\"Dataset de URLs (Phishing):\")\n",
       "print(df_url.head())\n",
       "\n",
       "# Separamos features (X) y target (y)\n",
       "X_url = df_url[['url_length', 'num_special_chars', 'has_ip_address', 'num_subdomains']]\n",
       "y_url = df_url['is_phishing']"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Dataset 2: Características Simplificadas de Conexiones de Red (Anomalías)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Creamos un DataFrame de ejemplo para conexiones de red\n",
       "data_conn = {\n",
       "    'duration': [0.1, 0.5, 0.2, 60.0, 0.3, 0.6, 75.0, 0.4, 90.0, 0.2, 0.7, 0.1],\n",
       "    'num_packets': [10, 50, 20, 5000, 30, 60, 6000, 40, 7500, 25, 70, 15],\n",
       "    'num_bytes': [1000, 5000, 2000, 500000, 3000, 6000, 600000, 4000, 800000, 2500, 7000, 1500],\n",
       "    'is_anomaly': [0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0] # 0: Normal, 1: Anomalía\n",
       "}\n",
       "df_conn = pd.DataFrame(data_conn)\n",
       "\n",
       "print(\"\\nDataset de Conexiones de Red (Anomalías):\")\n",
       "print(df_conn.head())\n",
       "\n",
       "# Features (X) para clasificación y clustering\n",
       "X_conn = df_conn[['duration', 'num_packets', 'num_bytes']]\n",
       "# Target (y) solo para clasificación\n",
       "y_conn = df_conn['is_anomaly']"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Preprocesamiento de Datos con Scikit-learn"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 2.1: Escalado de Características (Scaling)**\n",
       "\n",
       "* Aplica `StandardScaler` a las características `X_conn` (Dataset 2). Guarda el resultado en `X_conn_scaled_standard`.\n",
       "* Aplica `MinMaxScaler` a las características `X_conn`. Guarda el resultado en `X_conn_scaled_minmax`.\n",
       "* Imprime las primeras 5 filas de ambos resultados escalados.\n",
       "* **Pregunta:** ¿Por qué es importante escalar características para algoritmos como KNN o Regresión Logística (y también para K-Means)?"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 1. StandardScaler\n",
       "scaler_standard = StandardScaler()\n",
       "X_conn_scaled_standard = scaler_standard.fit_transform(X_conn)\n",
       "\n",
       "print(\"X_conn escalado con StandardScaler (primeras 5 filas):\")\n",
       "print(X_conn_scaled_standard[:5])\n",
       "\n",
       "# 2. MinMaxScaler\n",
       "scaler_minmax = MinMaxScaler()\n",
       "X_conn_scaled_minmax = scaler_minmax.fit_transform(X_conn)\n",
       "\n",
       "print(\"\\nX_conn escalado con MinMaxScaler (primeras 5 filas):\")\n",
       "print(X_conn_scaled_minmax[:5])\n",
       "\n",
       "# 3. Responde a la pregunta en una celda de texto (Markdown) a continuación"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Respuesta a la Pregunta 2.1:**\n",
       "\n",
       "*Escribe tu respuesta aquí... (Considera cómo afectan las diferentes escalas de las features a los cálculos de distancia o a los coeficientes del modelo)*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 2.2: Codificación de Variables Categóricas (One-Hot Encoding)**\n",
       "\n",
       "* Imagina que tenemos una característica 'protocolo' con valores 'TCP', 'UDP', 'ICMP'.\n",
       "* Crea un pequeño DataFrame de ejemplo con esta columna.\n",
       "* Aplica `OneHotEncoder` a esta columna.\n",
       "* Muestra el resultado transformado (será una matriz dispersa o un array denso si usas `sparse_output=False`). ¿Cuántas columnas nuevas se crearon y por qué?\n",
       "\n",
       "*Nota: `OneHotEncoder` es útil cuando la variable categórica no tiene un orden intrínseco.*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# DataFrame de ejemplo\n",
       "df_protocol = pd.DataFrame({'protocolo': ['TCP', 'UDP', 'TCP', 'ICMP', 'UDP']})\n",
       "print(\"DataFrame Original:\")\n",
       "print(df_protocol)\n",
       "\n",
       "# Crear e aplicar OneHotEncoder\n",
       "# Usamos sparse_output=False para ver un array numpy normal como resultado\n",
       "encoder = OneHotEncoder(sparse_output=False)\n",
       "protocol_encoded = encoder.fit_transform(df_protocol[['protocolo']]) # Necesita doble corchete\n",
       "\n",
       "print(\"\\nResultado del One-Hot Encoding:\")\n",
       "print(protocol_encoded)\n",
       "\n",
       "print(\"\\nNombres de las nuevas características (columnas):\")\n",
       "print(encoder.get_feature_names_out(['protocolo']))\n",
       "\n",
       "# Pregunta: ¿Cuántas columnas nuevas se crearon y por qué? (Responde en celda Markdown)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Respuesta a la Pregunta 2.2:**\n",
       "\n",
       "*Escribe tu respuesta aquí...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Clasificación con Scikit-learn"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 3.1: Regresión Logística para Detección de Phishing**\n",
       "\n",
       "Pasos:\n",
       "1.  **Dividir Datos:** Divide `X_url` y `y_url` (Dataset 1) en conjuntos de entrenamiento (80%) y prueba (20%). Usa `random_state=42` para reproducibilidad.\n",
       "2.  **Preprocesar (Escalar):** Crea un `StandardScaler` y ajústalo **solo** con los datos de entrenamiento (`X_train`). Luego, transforma `X_train` y `X_test`.\n",
       "3.  **Entrenar Modelo:** Crea una instancia de `LogisticRegression` y entrénala con los datos de entrenamiento escalados (`X_train_scaled`) y las etiquetas de entrenamiento (`y_train`).\n",
       "4.  **Predecir:** Realiza predicciones sobre el conjunto de prueba escalado (`X_test_scaled`).\n",
       "5.  **Evaluar:** Calcula Accuracy, Precision, Recall y F1-score comparando las predicciones con `y_test`. Muestra también la Matriz de Confusión."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 1. Dividir Datos\n",
       "X_train_url, X_test_url, y_train_url, y_test_url = train_test_split(\n",
       "    X_url, y_url, test_size=0.2, random_state=42, stratify=y_url # stratify es bueno para clasificación\n",
       ")\n",
       "\n",
       "# 2. Preprocesar (Escalar)\n",
       "scaler_url = StandardScaler()\n",
       "X_train_url_scaled = scaler_url.fit_transform(X_train_url)\n",
       "X_test_url_scaled = scaler_url.transform(X_test_url) # ¡Importante: usar transform, no fit_transform!\n",
       "\n",
       "# 3. Entrenar Modelo\n",
       "log_reg = LogisticRegression(random_state=42)\n",
       "log_reg.fit(X_train_url_scaled, y_train_url)\n",
       "\n",
       "# 4. Predecir\n",
       "y_pred_log_reg = log_reg.predict(X_test_url_scaled)\n",
       "\n",
       "# 5. Evaluar\n",
       "print(\"--- Evaluación Regresión Logística (Phishing) ---\")\n",
       "accuracy_lr = accuracy_score(y_test_url, y_pred_log_reg)\n",
       "precision_lr = precision_score(y_test_url, y_pred_log_reg)\n",
       "recall_lr = recall_score(y_test_url, y_pred_log_reg)\n",
       "f1_lr = f1_score(y_test_url, y_pred_log_reg)\n",
       "cm_lr = confusion_matrix(y_test_url, y_pred_log_reg)\n",
       "\n",
       "print(f\"Accuracy: {accuracy_lr:.4f}\")\n",
       "print(f\"Precision: {precision_lr:.4f}\")\n",
       "print(f\"Recall: {recall_lr:.4f}\")\n",
       "print(f\"F1-score: {f1_lr:.4f}\")\n",
       "print(\"Matriz de Confusión:\")\n",
       "disp_lr = ConfusionMatrixDisplay(confusion_matrix=cm_lr)\n",
       "disp_lr.plot()\n",
       "plt.show()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 3.2: K-Nearest Neighbors (KNN) para Detección de Phishing**\n",
       "\n",
       "Repite los pasos del ejercicio 3.1, pero esta vez usando `KNeighborsClassifier`.\n",
       "1.  Usa los mismos datos divididos y **escalados** (`X_train_url_scaled`, `X_test_url_scaled`, `y_train_url`, `y_test_url`).\n",
       "2.  Crea una instancia de `KNeighborsClassifier` (puedes empezar con `n_neighbors=3`).\n",
       "3.  Entrena, predice y evalúa el modelo KNN.\n",
       "4.  **Pregunta:** Compara brevemente los resultados con la Regresión Logística. ¿Por qué es especialmente importante el escalado para KNN?"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 1. Usar datos divididos y escalados del ejercicio anterior\n",
       "\n",
       "# 2. Crear Modelo KNN\n",
       "knn = KNeighborsClassifier(n_neighbors=3) # Prueba con k=3 inicialmente\n",
       "\n",
       "# 3. Entrenar, Predecir y Evaluar\n",
       "knn.fit(X_train_url_scaled, y_train_url)\n",
       "y_pred_knn = knn.predict(X_test_url_scaled)\n",
       "\n",
       "print(\"--- Evaluación KNN (Phishing, k=3) ---\")\n",
       "accuracy_knn = accuracy_score(y_test_url, y_pred_knn)\n",
       "precision_knn = precision_score(y_test_url, y_pred_knn)\n",
       "recall_knn = recall_score(y_test_url, y_pred_knn)\n",
       "f1_knn = f1_score(y_test_url, y_pred_knn)\n",
       "cm_knn = confusion_matrix(y_test_url, y_pred_knn)\n",
       "\n",
       "print(f\"Accuracy: {accuracy_knn:.4f}\")\n",
       "print(f\"Precision: {precision_knn:.4f}\")\n",
       "print(f\"Recall: {recall_knn:.4f}\")\n",
       "print(f\"F1-score: {f1_knn:.4f}\")\n",
       "print(\"Matriz de Confusión:\")\n",
       "disp_knn = ConfusionMatrixDisplay(confusion_matrix=cm_knn)\n",
       "disp_knn.plot()\n",
       "plt.show()\n",
       "\n",
       "# 4. Responde a la pregunta en celda Markdown"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Respuesta a la Pregunta 3.2:**\n",
       "\n",
       "*Compara los resultados... El escalado es importante para KNN porque...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 3.3: Random Forest para Detección de Phishing**\n",
       "\n",
       "Ahora, usa un `RandomForestClassifier`.\n",
       "1.  Usa los mismos datos divididos (`X_train_url`, `X_test_url`, `y_train_url`, `y_test_url`). Nota: Los árboles y bosques **no siempre requieren escalado**, así que puedes probar a usar los datos *sin escalar* esta vez para comparar (o usar los escalados si prefieres).\n",
       "2.  Crea una instancia de `RandomForestClassifier` (puedes usar `n_estimators=100`, `random_state=42`).\n",
       "3.  Entrena, predice y evalúa el modelo Random Forest.\n",
       "4.  Compara los resultados con los modelos anteriores."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 1. Usar datos divididos (prueba con/sin escalar, aquí usamos sin escalar)\n",
       "\n",
       "# 2. Crear Modelo Random Forest\n",
       "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
       "\n",
       "# 3. Entrenar, Predecir y Evaluar (Usando datos NO escalados)\n",
       "rf.fit(X_train_url, y_train_url) # Entrenar con datos originales\n",
       "y_pred_rf = rf.predict(X_test_url)   # Predecir con datos originales\n",
       "\n",
       "print(\"--- Evaluación Random Forest (Phishing) ---\")\n",
       "accuracy_rf = accuracy_score(y_test_url, y_pred_rf)\n",
       "precision_rf = precision_score(y_test_url, y_pred_rf)\n",
       "recall_rf = recall_score(y_test_url, y_pred_rf)\n",
       "f1_rf = f1_score(y_test_url, y_pred_rf)\n",
       "cm_rf = confusion_matrix(y_test_url, y_pred_rf)\n",
       "\n",
       "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
       "print(f\"Precision: {precision_rf:.4f}\")\n",
       "print(f\"Recall: {recall_rf:.4f}\")\n",
       "print(f\"F1-score: {f1_rf:.4f}\")\n",
       "print(\"Matriz de Confusión:\")\n",
       "disp_rf = ConfusionMatrixDisplay(confusion_matrix=cm_rf)\n",
       "disp_rf.plot()\n",
       "plt.show()\n",
       "\n",
       "# 4. Compara mentalmente o añade una celda Markdown para comparar"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Clustering con Scikit-learn"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 4.1: K-Means para Agrupar Conexiones de Red**\n",
       "\n",
       "Usaremos `X_conn` (Dataset 2) *sin* las etiquetas `y_conn` para ver si K-Means puede agrupar conexiones similares (potencialmente separando normales de anómalas).\n",
       "\n",
       "1.  **Preprocesar (Escalar):** Es **muy importante** escalar los datos para K-Means. Usa el `X_conn_scaled_standard` (o `_minmax`) que calculaste en el Ejercicio 2.1.\n",
       "2.  **Entrenar Modelo:** Crea una instancia de `KMeans` con `n_clusters=2` (ya que sabemos que hay 2 tipos: normal/anomalía, aunque K-Means no lo sabe). Usa `random_state=42` y `n_init='auto'`.\n",
       "3.  Entrena el modelo con los datos escalados (`kmeans.fit()`).\n",
       "4.  **Obtener Etiquetas:** Obtén las etiquetas de cluster asignadas a cada punto (`kmeans.labels_`).\n",
       "5.  **Visualizar:** Crea un gráfico de dispersión (scatter plot) usando dos de las características originales (ej. 'duration' vs 'num_packets' de `X_conn`) y colorea los puntos según las etiquetas de cluster encontradas por K-Means. Añade los centroides al gráfico (`kmeans.cluster_centers_`, ¡pero recuerda que están en la escala transformada! Necesitarías `scaler.inverse_transform()` para ponerlos en la escala original si quieres superponerlos directamente al gráfico de datos originales).\n",
       "6.  **Pregunta:** Observando el gráfico y las características de los datos originales (Dataset 2), ¿parece que K-Means ha logrado separar (al menos parcialmente) las conexiones normales de las anómalas? ¿Cómo podría usarse esto para detectar anomalías?"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# 1. Usar datos escalados (X_conn_scaled_standard del Ejercicio 2.1)\n",
       "# Asegúrate de que X_conn_scaled_standard esté disponible\n",
       "if 'X_conn_scaled_standard' not in locals():\n",
       "    print(\"Ejecuta primero la celda del Ejercicio 2.1 para escalar X_conn\")\n",
       "    # O vuelve a calcularlo aquí:\n",
       "    # scaler_standard = StandardScaler()\n",
       "    # X_conn_scaled_standard = scaler_standard.fit_transform(X_conn)\n",
       "\n",
       "# 2. Crear Modelo K-Means\n",
       "kmeans = KMeans(n_clusters=2, random_state=42, n_init='auto')\n",
       "\n",
       "# 3. Entrenar Modelo\n",
       "kmeans.fit(X_conn_scaled_standard)\n",
       "\n",
       "# 4. Obtener Etiquetas\n",
       "cluster_labels = kmeans.labels_\n",
       "print(\"Etiquetas de Cluster asignadas:\", cluster_labels)\n",
       "\n",
       "# 5. Visualizar (usando datos originales para los ejes, coloreados por cluster)\n",
       "plt.figure(figsize=(8, 6))\n",
       "scatter = sns.scatterplot(x=X_conn['duration'], \n",
       "                          y=X_conn['num_packets'], \n",
       "                          hue=cluster_labels, \n",
       "                          palette='viridis', \n",
       "                          s=100, # Tamaño de los puntos\n",
       "                          alpha=0.7)\n",
       "\n",
       "plt.title('Clusters de Conexiones de Red encontrados por K-Means (k=2)')\n",
       "plt.xlabel('Duración')\n",
       "plt.ylabel('Número de Paquetes')\n",
       "plt.legend(title='Cluster ID')\n",
       "plt.show()\n",
       "\n",
       "# Opcional: Calcular Silhouette Score (una métrica de clustering)\n",
       "try:\n",
       "    silhouette_avg = silhouette_score(X_conn_scaled_standard, cluster_labels)\n",
       "    print(f\"\\nSilhouette Score: {silhouette_avg:.4f}\") \n",
       "    # Más cerca de 1 es mejor, más cerca de -1 es peor.\n",
       "except NameError: # En caso de que X_conn_scaled_standard no se haya creado\n",
       "    print(\"\\nNo se pudo calcular Silhouette Score porque los datos escalados no están definidos.\")\n",
       "\n",
       "# 6. Responde a la pregunta en celda Markdown"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Respuesta a la Pregunta 4.1:**\n",
       "\n",
       "*Observando el gráfico... ¿Separó los puntos con valores altos de duration/packets? Esto podría usarse para detectar anomalías si...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Ingeniería de Características (Ejercicio Conceptual)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 5.1: Creación de Features desde Logs**\n",
       "\n",
       "Imagina que tienes logs de firewall con líneas como esta:\n",
       "\n",
       "`Apr 15 20:45:10 firewall1 DENY TCP src=10.1.1.10 dst=192.168.1.5 sport=54321 dport=80 len=60`\n",
       "\n",
       "Si quisieras usar Machine Learning para analizar estos logs (por ejemplo, para detectar patrones de ataque):\n",
       "\n",
       "1.  Enumera al menos 5 **features** (características) que podrías extraer de una línea de log como esta.\n",
       "2.  Indica si cada feature que has enumerado sería probablemente **numérica** o **categórica**."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Respuesta a la Pregunta 5.1:**\n",
       "\n",
       "1.  *Feature 1: ... (Tipo: ...)*\n",
       "2.  *Feature 2: ... (Tipo: ...)*\n",
       "3.  *Feature 3: ... (Tipo: ...)*\n",
       "4.  *Feature 4: ... (Tipo: ...)*\n",
       "5.  *Feature 5: ... (Tipo: ...)*\n",
       "    *(Ejemplos: hora del día, día de la semana, acción (DENY/ALLOW), protocolo (TCP/UDP), IP origen/destino (podrían ser categóricas o procesadas), puerto origen/destino, longitud del paquete)*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- \n",
       "¡Gran trabajo! Has aplicado varios algoritmos de ML usando Scikit-learn, incluyendo pasos cruciales como el preprocesamiento y la evaluación. Ahora estás mucho más cerca de poder aplicar estas técnicas a problemas reales de ciberseguridad, como los que se exploran en el libro de referencia."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }