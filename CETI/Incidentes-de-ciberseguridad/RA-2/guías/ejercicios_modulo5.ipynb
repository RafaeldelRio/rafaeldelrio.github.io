{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Ejercicios Prácticos - Módulo 5: Implementación con Ejemplos del Libro/Repositorio Cylance"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Objetivo:** Interactuar con el código y los datos del repositorio `cylance/IntroductionToMachineLearningForSecurityPros`. Analizar, ejecutar (o replicar partes de) un ejemplo específico (Clasificación de archivos PE de Chapter 3), comprender su flujo de trabajo, interpretar sus resultados en el contexto de la ciberseguridad y experimentar con modificaciones."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Configuración del Entorno"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 1.1: Clonar el Repositorio**\n",
       "\n",
       "Utiliza `git clone` para descargar el contenido del repositorio de Cylance en tu entorno de Colab."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "!git clone https://github.com/cylance/IntroductionToMachineLearningForSecurityPros.git"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 1.2: Instalar Dependencias (Si es necesario)**\n",
       "\n",
       "El repositorio puede tener un archivo `requirements.txt`. Aunque no todos los scripts lo necesiten, es buena práctica intentar instalar las dependencias. Navega al directorio del repositorio y lista los archivos para encontrarlo. Si existe, instálalo usando `pip`.\n",
       "\n",
       "*Nota: La instalación puede tardar un poco. Puede que algunas dependencias muy antiguas no funcionen directamente en Colab actual, pero intentaremos trabajar con las librerías ya incluidas (Pandas, Scikit-learn) que son las más importantes para nuestro análisis.*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Navegar al directorio (si es necesario, aunque usualmente Colab clona en /content/)\n",
       "%cd IntroductionToMachineLearningForSecurityPros\n",
       "\n",
       "# Listar archivos para verificar si existe requirements.txt\n",
       "!ls\n",
       "\n",
       "# Si ves 'requirements.txt', descomenta e intenta instalarlo\n",
       "# !pip install -r requirements.txt\n",
       "\n",
       "# Volver al directorio /content/ por si acaso para mantener rutas consistentes\n",
       "%cd /content/"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Explorando el Ejemplo: Clasificación de Archivos PE (Chapter 3)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Referencia:** Nos centraremos en el ejemplo `pe_classify.py` dentro del directorio `IntroductionToMachineLearningForSecurityPros/Chapter3/`.\n",
       "\n",
       "**Ejercicio 2.1: Examinar el Script (Lectura)**\n",
       "\n",
       "1.  Navega (mentalmente o usando `!cat` o el explorador de archivos de Colab) al archivo `IntroductionToMachineLearningForSecurityPros/Chapter3/pe_classify.py`.\n",
       "2.  Léelo por encima. No necesitas entender cada línea perfectamente, pero intenta identificar:\n",
       "    * ¿Qué librerías principales importa (ej. pandas, sklearn)?\n",
       "    * ¿Qué archivo de datos parece cargar o utilizar? (Busca nombres de archivo como `.csv`).\n",
       "    * ¿Qué tipo de modelo de Machine Learning parece estar utilizando (ej. RandomForest, LogisticRegression, etc.)?\n",
       "    * ¿Cómo parece evaluar el modelo (qué métricas busca)?\n",
       "\n",
       "*Nota: Si ejecutar `!cat` produce demasiado texto, puedes abrir el archivo desde el panel izquierdo de Colab (pestaña \"Archivos\") navegando a la carpeta.*"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Puedes usar 'cat' para ver el contenido del script directamente aquí (puede ser largo)\n",
       "# !cat IntroductionToMachineLearningForSecurityPros/Chapter3/pe_classify.py\n",
       "\n",
       "# Alternativamente, usa el explorador de archivos de Colab para abrirlo y leerlo."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 2.2: Cargar los Datos**\n",
       "\n",
       "Basado en tu lectura del script (o explorando el directorio `Chapter3/data/`), el archivo de datos probablemente sea `pe_section_headers.csv`.\n",
       "\n",
       "1.  Define la ruta correcta a este archivo dentro de la estructura clonada.\n",
       "2.  Carga este archivo CSV en un DataFrame de Pandas llamado `df_pe`.\n",
       "3.  Muestra las primeras filas (`.head()`), información general (`.info()`) y las columnas (`.columns`)."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import pandas as pd\n",
       "\n",
       "# Define la ruta al archivo de datos\n",
       "# Ajusta si la estructura del repo cambia en el futuro\n",
       "data_path = \"IntroductionToMachineLearningForSecurityPros/Chapter3/data/pe_section_headers.csv\"\n",
       "\n",
       "try:\n",
       "    df_pe = pd.read_csv(data_path)\n",
       "    print(\"Datos cargados exitosamente.\")\n",
       "\n",
       "    print(\"\\n--- Primeras filas (head) ---\")\n",
       "    print(df_pe.head())\n",
       "    \n",
       "    print(\"\\n--- Información (.info) ---\")\n",
       "    df_pe.info()\n",
       "\n",
       "    print(\"\\n--- Columnas ---\")\n",
       "    print(df_pe.columns)\n",
       "\n",
       "except FileNotFoundError:\n",
       "    print(f\"Error: No se encontró el archivo en la ruta: {data_path}\")\n",
       "    print(\"Asegúrate de haber clonado el repositorio correctamente y que la ruta es correcta.\")\n",
       "    df_pe = None # Para evitar errores posteriores si falla la carga\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Comprendiendo el Código y los Datos"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 3.1: Identificar Features y Target**\n",
       "\n",
       "Observando las columnas del DataFrame `df_pe`:\n",
       "1.  ¿Cuál columna crees que es la **variable objetivo** (target) que el modelo intenta predecir (es decir, si es malware o no)?\n",
       "2.  Las otras columnas son las **features** (características) extraídas de las cabeceras de sección de los archivos PE. ¿Qué tipo de información parecen representar estas features (ej. nombres de secciones, tamaños, entropía, características virtuales/raw)?"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Escribe tu respuesta aquí:**\n",
       "\n",
       "1.  *La columna target probablemente es: ...*\n",
       "2.  *Las features representan: ...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 3.2: Preprocesamiento Aplicado**\n",
       "\n",
       "Revisando el script `pe_classify.py` (o asumiendo buenas prácticas):\n",
       "1.  ¿Crees que sería necesario aplicar **escalado** a estas features antes de entrenar un modelo como RandomForest o Logistic Regression? ¿Por qué sí o por qué no?\n",
       "2.  ¿Hay alguna feature очевидно **categórica** que necesite codificación (como One-Hot Encoding)? (Basado en los nombres y `df_pe.info()`)."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Escribe tu respuesta aquí:**\n",
       "\n",
       "1.  *Escalado: (Sí/No/Depende)... porque...*\n",
       "2.  *Codificación Categórica: (Sí/No)... Feature(s): ...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Replicando el Análisis Básico en Colab"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Objetivo:** Vamos a replicar los pasos clave de entrenar y evaluar un modelo similar al del script, pero directamente en nuestro notebook para mayor control y comprensión."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Importar librerías necesarias si no están ya importadas\n",
       "from sklearn.model_selection import train_test_split\n",
       "from sklearn.ensemble import RandomForestClassifier # Asumimos que el script usa RF, ajústalo si usa otro\n",
       "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
       "import matplotlib.pyplot as plt\n",
       "\n",
       "# Verificar si df_pe se cargó correctamente\n",
       "if df_pe is not None:\n",
       "    # 1. Separar Features (X) y Target (y)\n",
       "    # Asume que la columna target se llama 'malware' (ajusta si es diferente)\n",
       "    if 'malware' in df_pe.columns:\n",
       "        y = df_pe['malware']\n",
       "        # Usar todas las demás columnas como features (simple inicial)\n",
       "        # El script original podría seleccionar features específicas o excluir algunas\n",
       "        # Excluimos columnas no numéricas obvias si no se preprocesan (ej. 'name', 'hash')\n",
       "        potential_feature_cols = df_pe.select_dtypes(include=np.number).columns.tolist()\n",
       "        if 'malware' in potential_feature_cols:\n",
       "             potential_feature_cols.remove('malware') # Quitar la etiqueta de las features\n",
       "        \n",
       "        # Verifica si hay columnas no numéricas que deberías excluir o codificar\n",
       "        # Por simplicidad, aquí solo usamos las numéricas.\n",
       "        X = df_pe[potential_feature_cols]\n",
       "        print(f\"Usando {len(X.columns)} features numéricas.\")\n",
       "\n",
       "        # 2. Dividir en Train/Test\n",
       "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
       "        print(f\"Datos divididos: {X_train.shape[0]} entrenamiento, {X_test.shape[0]} prueba.\")\n",
       "        \n",
       "        # 3. Preprocesamiento (Opcional/Necesario)\n",
       "        # Si decidiste que escalar es necesario (ej. para LR, KNN), hazlo aquí.\n",
       "        # Para RandomForest, a menudo no es estrictamente necesario.\n",
       "        # scaler = StandardScaler()\n",
       "        # X_train_scaled = scaler.fit_transform(X_train)\n",
       "        # X_test_scaled = scaler.transform(X_test)\n",
       "        # Por ahora, usaremos los datos sin escalar con RandomForest\n",
       "        X_train_processed = X_train\n",
       "        X_test_processed = X_test\n",
       "        \n",
       "        # 4. Crear y Entrenar Modelo (ej. RandomForest)\n",
       "        # Usa parámetros similares a los que pudiste ver en el script si es posible\n",
       "        model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1) # n_jobs=-1 usa todos los cores\n",
       "        print(\"\\nEntrenando el modelo RandomForest...\")\n",
       "        model.fit(X_train_processed, y_train)\n",
       "        print(\"Entrenamiento completado.\")\n",
       "        \n",
       "        # 5. Predecir en el conjunto de prueba\n",
       "        y_pred = model.predict(X_test_processed)\n",
       "        \n",
       "        # 6. Evaluar\n",
       "        print(\"\\n--- Evaluación del Modelo Replicado (PE Classification) ---\")\n",
       "        accuracy = accuracy_score(y_test, y_pred)\n",
       "        precision = precision_score(y_test, y_pred) # Asume clase 1 (malware) es la positiva\n",
       "        recall = recall_score(y_test, y_pred)    # Asume clase 1 (malware) es la positiva\n",
       "        f1 = f1_score(y_test, y_pred)       # Asume clase 1 (malware) es la positiva\n",
       "        cm = confusion_matrix(y_test, y_pred)\n",
       "        \n",
       "        print(f\"Accuracy: {accuracy:.4f}\")\n",
       "        print(f\"Precision (para clase 1): {precision:.4f}\")\n",
       "        print(f\"Recall (para clase 1): {recall:.4f}\")\n",
       "        print(f\"F1-score (para clase 1): {f1:.4f}\")\n",
       "        print(\"Matriz de Confusión:\")\n",
       "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
       "        disp.plot()\n",
       "        plt.show()\n",
       "    else:\n",
       "        print(\"Error: La columna 'malware' no se encontró en el DataFrame.\")\n",
       "        print(\"Verifica el nombre correcto de la columna target en el Ejercicio 3.1.\")\n",
       "else:\n",
       "    print(\"Error: El DataFrame df_pe no fue cargado. No se puede continuar.\")\n"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 4.1: Interpretación de Resultados**\n",
       "\n",
       "Observa las métricas de evaluación obtenidas:\n",
       "1.  ¿Qué significa el valor de **Recall** obtenido en el contexto de la detección de malware? ¿Es un valor alto o bajo deseable para Recall en este caso? ¿Por qué?\n",
       "2.  ¿Qué significa el valor de **Precision**? ¿Qué representa un Falso Positivo en este contexto (columna FP de la matriz)?\n",
       "3.  Basado en las métricas, ¿considerarías que este modelo replicado es efectivo para detectar malware en este dataset?"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Escribe tu respuesta aquí:**\n",
       "\n",
       "1.  *Recall significa... Es deseable un Recall (alto/bajo)... porque...*\n",
       "2.  *Precision significa... Un Falso Positivo aquí es...*\n",
       "3.  *El modelo parece (efectivo/poco efectivo/etc.)... porque...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Experimentación"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 5.1: Cambiar Parámetros del Modelo**\n",
       "\n",
       "1.  Vuelve a entrenar el `RandomForestClassifier`, pero esta vez cambia un hiperparámetro, por ejemplo, `n_estimators` a `50` (menos árboles) o `max_depth` a `10` (limitar profundidad del árbol).\n",
       "2.  Re-evalúa el modelo con este cambio.\n",
       "3.  ¿Cómo afectó el cambio a las métricas de rendimiento (Accuracy, Precision, Recall, F1)? ¿Y al tiempo de entrenamiento (aunque no lo medimos explícitamente)?"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Verifica si los datos están disponibles\n",
       "if 'X_train_processed' in locals() and df_pe is not None and 'malware' in df_pe.columns:\n",
       "    # 1. Crear y Entrenar Modelo con parámetros cambiados\n",
       "    model_exp = RandomForestClassifier(n_estimators=50, # Cambiado de 100\n",
       "                                     max_depth=10,     # Añadido límite de profundidad\n",
       "                                     random_state=42, \n",
       "                                     n_jobs=-1)\n",
       "    print(\"\\nEntrenando el modelo RandomForest (Experimento)...\")\n",
       "    model_exp.fit(X_train_processed, y_train)\n",
       "    print(\"Entrenamiento completado.\")\n",
       "\n",
       "    # 2. Predecir y Evaluar\n",
       "    y_pred_exp = model_exp.predict(X_test_processed)\n",
       "    \n",
       "    print(\"\\n--- Evaluación del Modelo (Experimento) ---\")\n",
       "    accuracy_exp = accuracy_score(y_test, y_pred_exp)\n",
       "    precision_exp = precision_score(y_test, y_pred_exp)\n",
       "    recall_exp = recall_score(y_test, y_pred_exp)\n",
       "    f1_exp = f1_score(y_test, y_pred_exp)\n",
       "    cm_exp = confusion_matrix(y_test, y_pred_exp)\n",
       "    \n",
       "    print(f\"Accuracy: {accuracy_exp:.4f}\")\n",
       "    print(f\"Precision: {precision_exp:.4f}\")\n",
       "    print(f\"Recall: {recall_exp:.4f}\")\n",
       "    print(f\"F1-score: {f1_exp:.4f}\")\n",
       "    print(\"Matriz de Confusión:\")\n",
       "    disp_exp = ConfusionMatrixDisplay(confusion_matrix=cm_exp)\n",
       "    disp_exp.plot()\n",
       "    plt.show()\n",
       "    \n",
       "    # 3. Compara los resultados (responde en celda Markdown)\n",
       "else:\n",
       "    print(\"Error: Los datos procesados (X_train_processed, etc.) no están disponibles.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Respuesta a la Pregunta 5.1 (Comparación):**\n",
       "\n",
       "*El cambio en los parámetros (n_estimators/max_depth) resultó en... (métricas más altas/bajas/similares). El tiempo de entrenamiento probablemente fue... (mayor/menor/similar)*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 5.2: Probar un Modelo Diferente**\n",
       "\n",
       "1.  Ahora, en lugar de RandomForest, prueba con `LogisticRegression` (como hiciste en el Módulo 4). Recuerda que para Logistic Regression, **sí es recomendable escalar** los datos.\n",
       "2.  Aplica `StandardScaler` a `X_train` y `X_test` (asegúrate de hacer `fit_transform` en train y solo `transform` en test).\n",
       "3.  Entrena `LogisticRegression` con los datos escalados.\n",
       "4.  Evalúa el rendimiento y compáralo con los resultados del RandomForest original."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# Importar StandardScaler y LogisticRegression si no están ya\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "\n",
       "# Verificar si los datos originales están disponibles\n",
       "if 'X_train' in locals() and 'X_test' in locals():\n",
       "    # 2. Escalar Datos\n",
       "    print(\"\\nEscalando datos para Logistic Regression...\")\n",
       "    scaler_lr = StandardScaler()\n",
       "    X_train_lr_scaled = scaler_lr.fit_transform(X_train)\n",
       "    X_test_lr_scaled = scaler_lr.transform(X_test)\n",
       "    print(\"Datos escalados.\")\n",
       "    \n",
       "    # 3. Crear y Entrenar Logistic Regression\n",
       "    log_reg_model = LogisticRegression(random_state=42, max_iter=1000) # Aumentar max_iter si no converge\n",
       "    print(\"Entrenando Logistic Regression...\")\n",
       "    log_reg_model.fit(X_train_lr_scaled, y_train)\n",
       "    print(\"Entrenamiento completado.\")\n",
       "    \n",
       "    # 4. Predecir y Evaluar\n",
       "    y_pred_lr_exp = log_reg_model.predict(X_test_lr_scaled)\n",
       "    \n",
       "    print(\"\\n--- Evaluación del Modelo (Logistic Regression) ---\")\n",
       "    accuracy_lr_exp = accuracy_score(y_test, y_pred_lr_exp)\n",
       "    precision_lr_exp = precision_score(y_test, y_pred_lr_exp)\n",
       "    recall_lr_exp = recall_score(y_test, y_pred_lr_exp)\n",
       "    f1_lr_exp = f1_score(y_test, y_pred_lr_exp)\n",
       "    cm_lr_exp = confusion_matrix(y_test, y_pred_lr_exp)\n",
       "\n",
       "    print(f\"Accuracy: {accuracy_lr_exp:.4f}\")\n",
       "    print(f\"Precision: {precision_lr_exp:.4f}\")\n",
       "    print(f\"Recall: {recall_lr_exp:.4f}\")\n",
       "    print(f\"F1-score: {f1_lr_exp:.4f}\")\n",
       "    print(\"Matriz de Confusión:\")\n",
       "    disp_lr_exp = ConfusionMatrixDisplay(confusion_matrix=cm_lr_exp)\n",
       "    disp_lr_exp.plot()\n",
       "    plt.show()\n",
       "    \n",
       "    # Compara mentalmente con RandomForest original\n",
       "else:\n",
       "    print(\"Error: Los datos originales (X_train, X_test) no están disponibles.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 6. Reflexión Final"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Ejercicio 6.1: Desafíos y Aprendizajes**\n",
       "\n",
       "Reflexiona sobre el proceso de trabajar con este ejemplo del repositorio:\n",
       "1.  ¿Qué fue lo más desafiante: entender el código del script original, cargar/entender los datos, replicar el análisis, o interpretar los resultados?\n",
       "2.  ¿Qué concepto de los módulos anteriores (Python, Pandas, Scikit-learn básico, teoría de ML) te resultó más útil para abordar este ejercicio?\n",
       "3.  ¿Cómo difiere este ejemplo (datos, complejidad) de los ejercicios más simples de los módulos anteriores?"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "**Escribe tu reflexión aquí:**\n",
       "\n",
       "1.  *Lo más desafiante fue...*\n",
       "2.  *El concepto más útil fue...*\n",
       "3.  *Este ejemplo difiere en...*"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- \n",
       "¡Felicidades por completar este módulo! Has dado un paso importante al interactuar con código y datos más realistas de Machine Learning aplicado a ciberseguridad. Este proceso de analizar, replicar y experimentar con ejemplos existentes es una habilidad clave para seguir aprendiendo y aplicando estas técnicas."
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12" 
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }