{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 7: Clasificación MNIST con PyTorch\n",
    "\n",
    "**Objetivo:** Implementar el mismo problema de clasificación MNIST usando PyTorch para comparar la estructura y flujo de trabajo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerías:** `torch`, `torchvision`, `numpy`, `matplotlib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración para mostrar gráficos en el notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Carga el dataset MNIST usando `torchvision.datasets.MNIST`.**\n",
    "Aplica las transformaciones necesarias (`ToTensor`, `Normalize`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformaciones\n",
    "# ToTensor convierte la imagen PIL (rango [0, 255]) a un Tensor Float (rango [0.0, 1.0])\n",
    "# Normalize ajusta el rango a [-1.0, 1.0] para media 0.5 y std 0.5 (común para MNIST)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Media y Desviación Estándar para un canal (escala de grises)\n",
    "])\n",
    "\n",
    "# Descargar/Cargar datasets de entrenamiento y prueba\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(\"Datasets cargados.\")\n",
    "print(\"Tamaño del dataset de entrenamiento:\", len(train_dataset))\n",
    "print(\"Tamaño del dataset de prueba:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Crea DataLoaders para los conjuntos de entrenamiento y prueba.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir tamaño del batch\n",
    "batch_size = 128 # Puede ser el mismo que en Keras o diferente\n",
    "\n",
    "# Crear DataLoaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False) # No es necesario barajar para prueba\n",
    "\n",
    "print(\"DataLoaders creados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Define la arquitectura de la red neuronal.**\n",
    "Crea una clase que herede de `torch.nn.Module` con:\n",
    "* Entrada: 784 (imágenes aplanadas 28x28).\n",
    "* Capa oculta: 128 neuronas con activación ReLU.\n",
    "* Capa de salida: 10 neuronas (una por dígito)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        # ... Definir capa de entrada a oculta (nn.Linear)\n",
    "        # ... Definir capa oculta a salida (nn.Linear)\n",
    "        # ... (Opcional) Definir activación ReLU (nn.ReLU)\n",
    "        # ... (Opcional) Definir Dropout (nn.Dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aplanar la imagen de entrada (batch_size, 1, 28, 28) a (batch_size, 784)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        # ... Pasar x por la primera capa lineal\n",
    "        # ... Aplicar ReLU\n",
    "        # ... (Opcional) Aplicar Dropout\n",
    "        # ... Pasar por la capa de salida\n",
    "        return x # La salida son los logits (sin Softmax)\n",
    "\n",
    "# Instanciar el modelo\n",
    "model = MLP()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Define la función de pérdida y el optimizador.**\n",
    "* Pérdida: `CrossEntropyLoss` (combina LogSoftmax y NLLLoss).\n",
    "* Optimizador: `Adam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tu código aquí\n",
    "criterion = # ... instanciar nn.CrossEntropyLoss()\n",
    "optimizer = # ... instanciar optim.Adam(model.parameters(), lr=0.001) # lr es la tasa de aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Implementa el bucle de entrenamiento.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir número de épocas\n",
    "epochs = 10\n",
    "\n",
    "# Mover el modelo a la GPU si está disponible (opcional)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Entrenando en: {device}\")\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Poner el modelo en modo entrenamiento\n",
    "    running_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Mover datos a la GPU (opcional)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. Poner a cero los gradientes\n",
    "        # Tu código aquí\n",
    "        \n",
    "        # 2. Forward pass: pasar las imágenes por el modelo\n",
    "        # Tu código aquí\n",
    "        outputs = # ...\n",
    "        \n",
    "        # 3. Calcular la pérdida\n",
    "        # Tu código aquí\n",
    "        loss = # ... criterion(outputs, labels)\n",
    "        \n",
    "        # 4. Backward pass: calcular gradientes\n",
    "        # Tu código aquí\n",
    "        \n",
    "        # 5. Actualizar pesos\n",
    "        # Tu código aquí\n",
    "        \n",
    "        # Imprimir estadísticas cada cierto número de batches\n",
    "        running_loss += loss.item()\n",
    "        if (i+1) % 100 == 0: # Cada 100 batches\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "            \n",
    "    print(f'Epoch {epoch+1} completada. Loss promedio: {running_loss / len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Implementa el bucle de evaluación.**\n",
    "Calcula la precisión sobre el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poner el modelo en modo evaluación\n",
    "model.eval()\n",
    "\n",
    "# Desactivar cálculo de gradientes para evaluación\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Mover datos a la GPU (opcional)\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Pasar imágenes por el modelo\n",
    "        outputs = # Tu código aquí\n",
    "        \n",
    "        # Obtener la clase predicha (índice con el valor más alto)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Contar el número total de etiquetas\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        # Contar el número de predicciones correctas\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f'Precisión del modelo en el conjunto de prueba: {accuracy:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Entrena el modelo y muestra la precisión final.**\n",
    "(Ya se hizo en los pasos 5 y 6). Revisa la salida de las celdas anteriores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x.y"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}